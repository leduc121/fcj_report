[{"uri":"https://github.com/leduc121/fcj_report/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Tái Tưởng Tượng Chăm Sóc Sức Khỏe Tâm Thần: Công Nghệ Là Chất Xúc Tác Cho Sự Thay Đổi Tác giả: Jay Rajda | vào ngày: 23 tháng 5 năm 2025 | trong: Amazon Bedrock, Amazon Chime SDK, Amazon Connect, Amazon Lex, Chăm sóc sức khỏe, Ngành công nghiệp | Permalink | Comments | Share\nHãy tưởng tượng một thế giới nơi chăm sóc sức khỏe tâm thần không có nghĩa là danh sách chờ đợi vô tận cho bệnh nhân hay kiệt sức vì hồ sơ giấy tờ đối với các nhà trị liệu. Thế giới đó không chỉ là có thể—nó đã ở đây rồi.\nCông nghệ đang định hình lại bối cảnh chăm sóc sức khỏe tâm thần. Các trợ lý được hỗ trợ bởi AI hiện đang giúp giảm gánh nặng công việc giấy tờ cho các bác sĩ lâm sàng, phát hiện những hiểu biết đột phá và cải thiện hiệu quả. Trong khi đó, các nền tảng kỹ thuật số đang kết nối các cá nhân với dịch vụ chăm sóc từng có vẻ không thể tiếp cận. Điều chúng ta đang chứng kiến không chỉ là sự đổi mới—mà là một cuộc cách mạng, với tiềm năng chữa lành không chỉ bệnh nhân, mà cả một hệ thống y tế quá tải và quá sức.\nMột Hệ Thống Đang Ở Điểm Bùng Phá Hãy đối mặt với sự thật: hệ thống chăm sóc sức khỏe tâm thần đang đứng trước áp lực.\nGần một nửa số người Mỹ cần dịch vụ sức khỏe tâm thần không thể tiếp cận được chúng. Các nhà cung cấp dịch vụ được đặt lịch trong nhiều tháng—nếu họ vẫn đang nhận bệnh nhân mới. Các cá nhân tìm kiếm sự trợ giúp thường phải đối mặt với một quy trình kiệt sức khi gọi điện xuống danh sách các nhà trị liệu, chỉ để chấp nhận các cuộc hẹn xung đột với công việc hoặc đòi hỏi di chuyển xa.\nỞ phía bên kia của phương trình, các bác sĩ lâm sàng đang vật lộn. Họ đang chìm đắm trong công việc hành chính—hồ sơ, thanh toán, tuân thủ—điều này lấy đi thời gian cho việc chăm sóc trực tiếp. Đây là một yếu tố đóng góp chính vào tình trạng kiệt sức của nhà cung cấp, đẩy các chuyên gia đam mê ra khỏi lĩnh vực này hoàn toàn. Kết quả là một cơn bão hoàn hảo: bệnh nhân không thể tiếp cận dịch vụ chăm sóc, và các chuyên gia có thể giúp đỡ đang bị kéo dài vượt quá khả năng.\nGiải Pháp Kỹ Thuật Số: Giảm Bớt Áp Lực Các công nghệ kỹ thuật số, được xây dựng trên cơ sở hạ tầng an toàn và có khả năng mở rộng, cung cấp các giải pháp thực tế và bền vững cho những thách thức cấp bách nhất của ngành:\nNền tảng trị liệu từ xa và ứng dụng sức khỏe tâm thần di động: Mở rộng khả năng tiếp cận các lựa chọn chăm sóc thuận tiện. Trí tuệ nhân tạo và thuật toán học máy: Cải thiện độ chính xác và tính kịp thời của chẩn đoán, và cá nhân hóa điều trị—cải thiện chất lượng chăm sóc và kết quả. Hệ thống nhập liệu kỹ thuật số và hồ sơ tự động: Hợp lý hóa các nhiệm vụ hành chính—cho phép các nhà cung cấp dành nhiều thời gian hơn với bệnh nhân và giúp giảm tình trạng kiệt sức. Hỗ trợ và tư vấn từ đồng nghiệp trực tuyến: Thu hút các nhóm dân số bị thiệt thòi khó có khả năng sử dụng các dịch vụ sức khỏe tâm thần khác, đồng thời giảm bớt áp lực thiếu hụt nhà cung cấp. Những đổi mới công nghệ này tăng khả năng tiếp cận và khả năng chi trả của dịch vụ chăm sóc sức khỏe tâm thần. Chúng cũng trao quyền cho các cá nhân để đóng vai trò tích cực hơn trong việc quản lý sức khỏe tâm thần của họ thông qua các công cụ tự giúp đỡ và hỗ trợ liên tục.\nKết Nối Khoảng Cách Trong Chăm Sóc Với Dịch Vụ Ảo Khả năng tiếp cận chăm sóc sức khỏe tâm thần từ lâu đã bị cản trở bởi sự thiếu hụt nhà cung cấp, rào cản vận chuyển và sự kỳ thị. Đại dịch COVID-19 càng làm lộ rõ tính cấp thiết của việc vượt qua những trở ngại này—và dịch vụ chăm sóc ảo đã nổi lên như một cầu nối quan trọng.\nTalkspace, một nền tảng trị liệu kỹ thuật số có trụ sở tại Hoa Kỳ, minh họa cho sự chuyển đổi này. Được xây dựng trên Amazon Web Services (AWS), nó cung cấp quyền truy cập an toàn, có khả năng mở rộng đến các nhà trị liệu được cấp phép thông qua các ứng dụng web và di động. Talkspace cho phép giao tiếp đồng bộ và không đồng bộ, mang lại cho người dùng sự linh hoạt để tiếp cận dịch vụ chăm sóc theo cách và thời điểm họ cần.\nNgoài việc làm cho dịch vụ chăm sóc dễ tiếp cận hơn, Talkspace còn giảm bớt gánh nặng hành chính cho các nhà cung cấp của mình bằng cách giảm thời gian dành cho hồ sơ. Họ tạo điều kiện cho các ghi chú tiến trình mà các nhà cung cấp có thể xem xét lâm sàng trước khi sử dụng, cho phép họ nhanh chóng tạo báo cáo và tóm tắt phiên làm việc và dễ dàng hình dung tiến trình của bệnh nhân trong một khoảng thời gian cụ thể. Điều này đã tiết kiệm cho các nhà cung cấp trung bình 10 phút mỗi phiên hoặc khoảng ba đến bốn giờ mỗi tuần trong các nhiệm vụ hành chính khi sử dụng toàn thời gian.\nLàm Cho Việc Truy Cập Dễ Dàng Hơn Thông Qua Cổng Sức Khỏe Kỹ Thuật Số Quốc Gia Trên toàn cầu, các hệ thống y tế đang tận dụng các nền tảng kỹ thuật số dựa trên đám mây để mở rộng khả năng tiếp cận. Các quốc gia đã xây dựng “cổng sức khỏe kỹ thuật số”—các điểm nhập cảnh duy nhất mà công dân có thể sử dụng để dễ dàng truy cập thông tin và dịch vụ y tế kỹ thuật số hơn.\nHealthdirect Australia, được tài trợ bởi Chính phủ Liên bang, Bang và Lãnh thổ của Úc, cung cấp các nguồn lực và dịch vụ sức khỏe tâm thần qua điện thoại, web và ứng dụng di động, được thiết kế để giúp mọi người đưa ra quyết định sáng suốt về sức khỏe của họ và tiếp cận dịch vụ chăm sóc phù hợp. Các dịch vụ bao gồm đường dây trợ giúp có nhân viên y tá 24/7, thư mục các bác sĩ quốc gia, công cụ kiểm tra triệu chứng và phòng khám ảo—tất cả đều được hỗ trợ bởi AWS và các đối tác của nó. Dịch vụ Y tế Quốc gia của Anh (NHS) đã ra mắt NHS login, một nền tảng nhận dạng serverless cho phép công dân truy cập vào một loạt các dịch vụ y tế, bao gồm chăm sóc sức khỏe tâm thần, thông qua ứng dụng NHS. Được xây dựng trên AWS, nó cung cấp quyền truy cập an toàn, khả dụng cao vào các dịch vụ quan trọng cho hàng triệu người dùng. Con Đường Phía Trước Cho Các Chuyên Gia Y Tế Đối với các nhà cung cấp sức khỏe tâm thần, những đổi mới này mang lại nhiều hơn là hiệu quả hoạt động—chúng mang lại sự nhẹ nhõm. Các hệ thống tự động giảm gánh nặng công việc văn phòng. Các công cụ y tế từ xa mở rộng phạm vi tiếp cận. Các nền tảng an toàn bảo vệ quyền riêng tư của bệnh nhân và hợp lý hóa việc cung cấp dịch vụ. Và quan trọng nhất, các bác sĩ lâm sàng có thể tập trung trở lại vào điều quan trọng nhất: giúp các cá nhân chữa lành. Công nghệ không thay thế kết nối con người ở trung tâm của dịch vụ chăm sóc sức khỏe tâm thần—nó đang củng cố nó.\nLàm Cho Chăm Sóc Lâm Sàng Hiệu Quả Hơn Ngoài việc thúc đẩy khả năng tiếp cận dịch vụ chăm sóc, công nghệ cũng có thể đóng vai trò quan trọng trong việc cải thiện hiệu quả của điều trị. Hỗ trợ quyết định lâm sàng được hỗ trợ bởi AI và những hiểu biết dự đoán có thể cho phép các quyết định lâm sàng tốt hơn, và cuối cùng cải thiện kết quả lâm sàng.\nTalkspace sử dụng các dịch vụ AWS để xây dựng và triển khai các mô hình học máy (ML) để ghép nối mỗi người dùng với một chuyên gia sức khỏe tâm thần phù hợp nhất để đáp ứng nhu cầu cá nhân của họ—tối đa hóa xác suất thành công. Talkspace cũng cung cấp hồ sơ chẩn đoán của từng bệnh nhân và cung cấp những hiểu biết hữu ích, chẳng hạn như các tình trạng thứ phát tiềm ẩn.\nMột khía cạnh quan trọng của thành công lâm sàng là việc giữ chân bệnh nhân và tính đều đặn của các buổi theo dõi, vì ngưỡng cải thiện lâm sàng là vài buổi trị liệu. Các tính năng hỗ trợ bởi ML cung cấp cho các nhà trị liệu các mẹo và hành động được đề xuất để tránh bỏ cuộc sớm và giữ chân bệnh nhân. Các mô hình ML cũng được sử dụng để xác định các mẫu hành vi và rủi ro tổn hại tiềm ẩn, gửi thông báo đẩy đến các nhà trị liệu theo thời gian thực nếu phát hiện rủi ro gia tăng.\nCung Cấp Cho Các Cộng Đồng Cần Thiết Các mô hình dự đoán không chỉ dành cho bệnh nhân cá nhân. Chúng cũng có thể chủ động xác định rủi ro trong một cộng đồng và giúp phát triển các chương trình được thiết kế để cải thiện kết quả cho các nhóm dân số cụ thể.\nStop Soldier Suicide là một tổ chức phi lợi nhuận giải quyết vấn đề tự tử trong số các cựu chiến binh và quân nhân Hoa Kỳ. Để hiểu dữ liệu của mình tốt hơn và có được những hiểu biết mới, tổ chức đã làm việc với Đối tác AWS Pariveda để triển khai Nền tảng Trí tuệ Tự tử (SIP). Nền tảng này nhập dữ liệu thiết bị pháp y, tích hợp nó với dữ liệu đám mây y tế, và lưu trữ nó trong một hồ dữ liệu dựa trên AWS. Sử dụng giải pháp SIP, Stop Soldier Suicide có thể nhập và làm phong phú dữ liệu từ nhiều nguồn để dự đoán tốt hơn rủi ro tự tử của cựu chiến binh và giúp các bác sĩ lâm sàng giảm thiểu rủi ro đó.\nTổ chức đã bắt đầu Dự án Hộp Đen (Black Box Project), sử dụng pháp y kỹ thuật số để thu thập và xử lý dữ liệu từ điện thoại thông minh, máy tính bảng, máy tính xách tay và các thiết bị tương tự của Cựu chiến binh đã chết vì tự tử. Nó cũng bổ sung thông tin đó với trí tuệ nguồn mở từ năm cuối cùng của cuộc đời Cựu chiến binh. Các thuật toán học máy, xử lý ngôn ngữ tự nhiên và kỹ thuật trích xuất thực thể (được hỗ trợ bởi AWS) sau đó được sử dụng để xây dựng các mô hình về hành vi tiền tự tử có tương quan cao với tự tử. Điều này phát hiện những hiểu biết mới lạ có thể được chia sẻ với cộng đồng phục vụ cựu chiến binh để cứu sống nhiều người ở quy mô lớn.\nGaggle, một công ty công nghệ giáo dục và Đối tác AWS, phấn đấu để giữ an toàn cho học sinh K-12 và giảm rủi ro tự tử của học sinh bằng cách xác định học sinh có nguy cơ và cung cấp cho họ các nguồn lực cần thiết. Gaggle Safety sử dụng học máy để đánh dấu nội dung đáng lo ngại trong các tài khoản do trường cấp cho học sinh để xem xét và chặn nội dung có khả năng gây hại. Điều này giúp các học khu K-12 giám sát các dấu hiệu cảnh báo sớm để họ có thể hành động để bảo vệ học sinh khỏi tự làm hại bản thân hoặc người khác.\nGaggle cũng đã phát triển ReachOut, một đường dây nóng sức khỏe tâm thần 24/7 được xây dựng trên AWS, kết nối học sinh K-12 với các tư vấn viên hỗ trợ Gaggle được đào tạo, bất cứ đâu, bất cứ lúc nào. Hỗ trợ liên tục được thực hiện bằng cách sử dụng Amazon Connect, một trung tâm liên hệ tích hợp AI từ AWS. ReachOut cũng sử dụng Amazon Lex, một Trình Xây dựng Trò chuyện AI với các mô hình ngôn ngữ tự nhiên tiên tiến có thể hỗ trợ Người Phản hồi ReachOut bằng nhiều ngôn ngữ khác nhau.\nThúc Đẩy Hiệu Quả Lớn Hơn Cho Các Nhà Cung Cấp Dịch Vụ Công nghệ có thể giúp thúc đẩy hiệu quả cho các nhà cung cấp dịch vụ bằng cách tự động hóa các nhiệm vụ không khác biệt—cho phép các nhà cung cấp tập trung vào việc chăm sóc bệnh nhân. Các công cụ tự động hóa đang hợp lý hóa các quy trình hồ sơ, cho phép các bác sĩ lâm sàng dành ít thời gian hơn cho công việc giấy tờ. Các công cụ chẩn đoán được hỗ trợ bởi AI cũng đang hỗ trợ trong việc đánh giá nhanh chóng, chính xác, và mô hình dự đoán tiên tiến đang cho phép can thiệp lâm sàng kịp thời trước khi tình trạng xấu đi.\nNetsmart là nhà cung cấp hàng đầu các giải pháp công nghệ thông tin y tế, bao gồm hồ sơ y tế điện tử (EHRs), trí tuệ tăng cường và tự động hóa cho các nhà cung cấp dịch vụ chăm sóc sức khỏe hành vi và chăm sóc sau cấp tính. Nhận thức được tầm quan trọng của việc cho phép các nhà cung cấp dành nhiều thời gian hơn để chăm sóc các cá nhân, Netsmart đã phát triển các giải pháp với khả năng tiên tiến được thiết kế để giảm bớt gánh nặng hồ sơ. Sử dụng các dịch vụ AWS như Amazon Chime SDK, AWS HealthScribe và các mô hình ngôn ngữ lớn (LLMs) có sẵn thông qua Amazon Bedrock, Netsmart có thể lấy các cuộc trò chuyện mà các nhà cung cấp có với các cá nhân và chuyển đổi câu chuyện và nội dung phi cấu trúc thành ghi chú tiến trình lâm sàng.\nViệc sử dụng khả năng AI tạo sinh, thông qua Amazon Bedrock, đã cho phép Netsmart xây dựng các giải pháp của họ nhanh hơn. Tận dụng các mô hình nền tảng tiên tiến, như Claude của Anthropic, và làm phong phú chúng với các bộ dữ liệu độc quyền cho phép Netsmart cung cấp một cách an toàn các bản tóm tắt và ghi chú tiến trình, giảm gánh nặng hồ sơ cho các nhà cung cấp.\nNgoài ra, Bells Quality Coach cung cấp điểm đánh giá kiểm toán cho các ghi chú đã hoàn thành, trao quyền cho các nhóm đảm bảo chất lượng và cải tiến (QA/QI) để xác định khoảng trống và rủi ro tiềm ẩn. Nó tự động hóa các đánh giá, cung cấp những hiểu biết có thể hành động để hỗ trợ các tổ chức trong việc cung cấp dịch vụ chăm sóc chất lượng cao, tuân thủ. Bằng cách áp dụng cách tiếp cận có ý nghĩa đối với các công nghệ AI và tự động hóa, Netsmart nhằm mục đích trao quyền cho nhân viên, tối ưu hóa quy trình và đơn giản hóa hoàn trả.\nHơn nữa, Netsmart đã hợp tác với AWS để xây dựng Phòng thí nghiệm Dữ liệu AI đầu tiên thuộc loại này giúp tăng tốc đổi mới, cho phép Netsmart triển khai nhanh chóng công nghệ và khả năng mới. Sử dụng dữ liệu được tích lũy từ EHRs và yêu cầu bảo hiểm y tế, thuật toán có thể xác định các yếu tố rủi ro của một cá nhân, với mục tiêu giảm nhập viện.\nPhòng thí nghiệm Dữ liệu AI cũng đang thực hiện một dự án xử lý ngôn ngữ tự nhiên (NLP) bắt đầu với dịch theo thời gian thực cho các quản lý trường hợp không nói tiếng Anh. Nó cũng sẽ xử lý việc tự động hóa hồ sơ giấy thành dữ liệu có cấu trúc có thể giúp xác định nhu cầu cá nhân.\nNền tảng quản lý sức khỏe dân số Netsmart CareManager™ cho phép truy cập dữ liệu thời gian thực từ nhiều nguồn, chẳng hạn như EHRs, dữ liệu yêu cầu bồi thường và nhiều hơn nữa. Nó được hỗ trợ bởi AWS để có khả năng mở rộng và phân tích gần thời gian thực, bao gồm học máy. Điều này tạo điều kiện cho mô hình dự đoán để ưu tiên cả các hành động phản ứng và chủ động, cho phép các nhà cung cấp nhắm mục tiêu các cá nhân có nguy cơ dựa trên dữ liệu các yếu tố quyết định xã hội về sức khỏe và điều chỉnh các can thiệp theo nhu cầu của họ. Nó cung cấp cảnh báo thời gian thực được thúc đẩy bởi phân tích dự đoán, bao gồm mọi thứ từ nhập viện tiềm ẩn đến chi phí Medicaid.\nCác Lựa Chọn Thay Thế Cho Dịch Vụ Nhà Cung Cấp Trực Tiếp Một cách khác mà công nghệ có thể giải quyết khoảng cách giữa nhu cầu ngày càng tăng và nguồn cung hạn chế của các nhà cung cấp sức khỏe tâm thần đủ điều kiện, là cung cấp các lựa chọn thay thế kỹ thuật số cho các dịch vụ nhà cung cấp trực tiếp. Chúng có thể bao gồm các buổi trị liệu kỹ thuật số tự hướng dẫn dựa trên bằng chứng, cũng như quyền truy cập vào các cộng đồng ảo tạo ra không gian an toàn để kết nối với sự hỗ trợ từ đồng nghiệp.\nTheo Hiệp hội Tâm lý Hoa Kỳ, các liệu pháp điều trị dựa trên bằng chứng và được quản lý bằng kỹ thuật số bao gồm Liệu pháp Hành vi Nhận thức Kỹ thuật số có thể tạo thành một lựa chọn thay thế hoặc bổ sung quan trọng cho các dịch vụ trực tiếp để điều trị một số tình trạng sức khỏe tâm thần. Ngoài việc giảm nhu cầu đối với các nhà cung cấp, các dịch vụ như vậy cũng có thể cung cấp thêm sự thuận tiện cho người dùng có thể truy cập dịch vụ theo yêu cầu. Điều này có thể giúp giải quyết các thách thức liên quan đến sự kỳ thị được cảm nhận trong việc tiếp cận các dịch vụ này.\nTalkspace cung cấp một lựa chọn cho trị liệu tự hướng dẫn trong đó một chương trình kỹ thuật số được cá nhân hóa được tạo ra cho người dùng dựa trên đầu vào của họ và sử dụng nội dung từ hơn 60 chương trình tư vấn hướng dẫn được chứng minh lâm sàng của Talkspace. Mỗi chương trình được cung cấp trong vài phiên dài năm phút được thiết kế để đạt được tiến bộ trong các lĩnh vực lâm sàng quan trọng được xác định cho người dùng cá nhân cụ thể.\nSupportiv kết nối người dùng với những người khác chia sẻ khó khăn của họ trong các nhóm hỗ trợ ngang hàng nhỏ để trò chuyện trực tiếp, mỗi nhóm được hướng dẫn bởi một người điều phối được đào tạo. Một hệ thống ghép nối được điều khiển bởi AI đảm bảo người dùng được đặt trong nhóm phù hợp nhất dựa trên các mối quan tâm cụ thể của họ. Ngoài ra, Supportiv cung cấp các nguồn lực sức khỏe tâm thần được cá nhân hóa thông qua một công cụ đề xuất được hỗ trợ bởi AI. Một thuật toán AI chuyên dụng liên tục giám sát các cuộc trò chuyện để tìm tín hiệu khủng hoảng. Nếu phát hiện một khủng hoảng tiềm ẩn, hệ thống cảnh báo người điều phối để can thiệp theo một giao thức lâm sàng được xác định trước.\nĐể tạo điều kiện cho tính toàn diện, Supportiv tận dụng các dịch vụ dịch thuật AWS làm nền tảng cho hỗ trợ đa ngôn ngữ tiên tiến của mình, cho phép thích ứng ngôn ngữ theo thời gian thực. Các dịch vụ AWS Cloud cũng giúp Supportiv mở rộng quy mô một cách linh hoạt dựa trên nhu cầu của người dùng, cung cấp tính khả dụng cao và trải nghiệm người dùng liền mạch. Độ tin cậy và khả năng phục hồi của cơ sở hạ tầng AWS đặc biệt quan trọng đối với giám sát khủng hoảng, nơi bất kỳ sự chậm trễ nào trong việc phát hiện hoặc phản hồi có thể có hậu quả nghiêm trọng.\nChăm Sóc Phòng Ngừa Các công cụ sức khỏe kỹ thuật số có triển vọng lớn trong khả năng chuyển đổi chăm sóc sức khỏe tâm thần từ phản ứng sang chủ động bằng cách trao quyền cho các cá nhân quản lý sức khỏe tâm lý của họ với sự chú ý có chủ ý giống như đối với sức khỏe thể chất. Dân chủ hóa quyền truy cập vào các ứng dụng chánh niệm với các thuật toán thích ứng phản ứng với tiến trình và sở thích cá nhân đặt sức khỏe tâm thần trong tầm tay của mọi cá nhân được kết nối kỹ thuật số.\nĐể giúp tạo ra một tương lai về nhận thức sức khỏe tâm thần không bị kỳ thị, Headspace đã xây dựng công nghệ để đưa thiền định và các công cụ sức khỏe tâm thần vào lòng bàn tay của công chúng. Headspace là một ứng dụng giúp người dùng của nó học cách thiền và sống chánh niệm hơn. Với hàng nghìn bài tập thiền và chánh niệm theo chủ đề tập trung vào mọi thứ từ căng thẳng và giấc ngủ đến nỗi sợ bay và tập trung, mục tiêu của ứng dụng là giúp người dùng của nó sống trong khoảnh khắc hiện tại mà không phán xét. Với hàng triệu người dùng trên ứng dụng cùng một lúc, Headspace, với sự giúp đỡ của AWS, được giải phóng khỏi việc bảo trì ứng dụng, bỏ qua “hệ thống ống nước công nghệ”, và cho phép họ dành thời gian cho công việc kinh doanh và sứ mệnh. Ngay cả trong các sự kiện khi việc sử dụng Headspace cao hơn bình thường, người dùng vẫn tiếp tục có được trải nghiệm tuyệt vời trên ứng dụng vì khả năng mở rộng quy mô của nó để đáp ứng nhu cầu của một lượng lớn khách truy cập. Headspace cũng sử dụng các dịch vụ từ Đối tác AWS – Auth0 của Okta – để cung cấp giải pháp nhận dạng an toàn và có khả năng mở rộng để phát triển và hỗ trợ hàng triệu thuê bao của mình trên 200 quốc gia và khu vực.\nCalm, một ứng dụng ngủ, thiền và thư giãn được đánh giá cao, có hơn 100 triệu lượt tải xuống toàn cầu. Ứng dụng sử dụng học máy và API của AWS để giúp truyền đạt các yêu cầu và phản hồi, cho phép Calm tạo ra các đề xuất chất lượng, phù hợp cho người dùng. Calm thúc đẩy sự thư giãn bằng cách cung cấp các video về chuyển động chánh niệm và kéo giãn nhẹ nhàng, các hướng dẫn âm thanh do các chuyên gia chánh niệm dẫn dắt, và các cảnh âm thanh và hình ảnh từ thiên nhiên. Các nhân vật nổi tiếng cũng tham gia, với Lebron James, Harry Styles và Ariana Grande đóng góp vào thư viện nội dung của Calm. Ứng dụng sử dụng Amazon Personalize—một dịch vụ cho phép các nhà phát triển xây dựng các ứng dụng bằng công nghệ ML để tạo ra các đề xuất cung cấp nội dung mà khách hàng ưu tiên. Nội dung được tạo bởi Amazon Personalize đã dẫn đến mức tăng 3,4% trong thực hành chánh niệm hàng ngày trong số các thành viên của cộng đồng Calm.\nKết Luận Sự tích hợp công nghệ vào các dịch vụ sức khỏe tâm thần đại diện cho một sự thay đổi mô hình trong cách chúng ta tiếp cận và cung cấp dịch vụ chăm sóc tâm lý. Những tiến bộ sâu sắc nhất có thể sẽ xuất hiện từ các mô hình lai kết hợp một cách chu đáo giữa hiệu quả công nghệ với sự đồng cảm của con người. Tương lai của chăm sóc sức khỏe tâm thần nằm giữa các cách tiếp cận kỹ thuật số và truyền thống, trong sự tích hợp chiến lược của chúng—tạo ra một hệ thống dễ tiếp cận và hiệu quả hơn đáp ứng nhu cầu đa dạng của một xã hội toàn cầu ngày càng phức tạp.\nBằng cách vượt qua các rào cản truyền thống về địa lý, sự kỳ thị và hạn chế nguồn lực, các đổi mới kỹ thuật số đang dân chủ hóa quyền truy cập vào dịch vụ chăm sóc sức khỏe tâm thần trong khi duy trì hiệu quả trị liệu.\nTìm hiểu thêm về AWS Partners hoặc liên hệ với AWS Representative để khám phá cách bạn có thể tạo ra các đổi mới y tế nhằm thúc đẩy kết quả tốt hơn.\nĐọc thêm\nTeleHealth on AWS AWS HealthScribe Amazon Lex – AI Chat Builder Về tác giả Jay Rajda, Bác sĩ Y khoa, là Giám đốc Điều hành Y tế Toàn cầu tại AWS, nơi ông chịu trách nhiệm giúp các cơ quan y tế chính phủ toàn cầu và các tổ chức chi trả y tế áp dụng các giải pháp công nghệ để đáp ứng các mục tiêu chiến lược của họ. Trước đây, ông từng làm việc tại Amazon Health Services, CVS Health và Aetna, nơi ông đảm nhiệm các vai trò lãnh đạo trong lĩnh vực y tế số, phân tích lâm sàng, y tế cộng đồng và chăm sóc dựa trên giá trị. Ông có nền tảng là bác sĩ, được chứng nhận hội đồng chuyên khoa nội và tin học lâm sàng, và có giấy phép hành nghề tại New York. Ông cũng từng là Phó Giáo sư Lâm sàng Y khoa tại Đại học Rochester. Ngoài bằng y khoa, ông còn có bằng Thạc sĩ Quản trị Kinh doanh (MBA) từ Đại học Rochester.\n"},{"uri":"https://github.com/leduc121/fcj_report/vi/4-eventparticipated/4.1-event1/","title":"AWS CLOUD DAY","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud, AI \u0026amp; Innovation Summit” Mục Tiêu Sự Kiện Giới thiệu chiến lược quốc gia của Việt Nam về phát triển điện toán đám mây và chuyển đổi số Tăng cường hợp tác công nghệ và đổi mới sáng tạo giữa Hoa Kỳ – Việt Nam Chia sẻ góc nhìn về AI, blockchain, và phát triển hệ sinh thái định hình tương lai Việt Nam Nêu bật các chương trình của AWS trong phát triển nhân lực, mở rộng khả năng tiếp cận cloud và sáng kiến AI có trách nhiệm Cung cấp kiến thức kỹ thuật thực hành về phát triển ứng dụng dùng AI và bảo mật AI Diễn Giả Đại diện Chính phủ Việt Nam Đại sứ Hoa Kỳ tại Việt Nam Eric Elock – CEO phụ trách Việt Nam, Lào, Campuchia \u0026amp; Myanmar Chloe Phung – CEO, U2U Erik – Lãnh đạo AWS Jaime Valless – Lãnh đạo AWS Chuyên gia kỹ thuật AWS – Dẫn dắt các phiên chuyên sâu buổi chiều Những Điểm Nổi Bật Chiến lược quốc gia về hạ tầng cloud và chuyển đổi số Chính phủ nhấn mạnh việc mở rộng dịch vụ cloud và hệ thống số làm nền tảng cho Công nghiệp 4.0 Đảm bảo an ninh, an toàn và bảo vệ thông tin trên các hệ sinh thái số quốc gia Khuyến khích hợp tác mở giữa cơ quan nhà nước, doanh nghiệp tư nhân và nhà đầu tư quốc tế Định vị công nghệ cloud như động lực thúc đẩy phát triển kinh tế và hiện đại hóa Quan hệ Hoa Kỳ – Việt Nam và phát triển công nghệ Đại sứ Hoa Kỳ nhìn lại ba thập kỷ hợp tác giữa hai quốc gia Các doanh nghiệp công nghệ như AWS đóng vai trò đối tác chủ lực thúc đẩy đồng phát triển Tập trung vào tăng trưởng kinh tế chung và hợp tác bền vững lâu dài Đổi mới qua hiện đại hóa ngân hàng \u0026amp; hệ sinh thái blockchain – Eric Elock Ngành ngân hàng tiếp tục giữ vai trò chính trong thúc đẩy hiện đại hóa CNTT U2U đang xây dựng hệ sinh thái blockchain hỗ trợ tương tác liền mạch giữa doanh nghiệp và người dùng Nhấn mạnh sự kết hợp giữa cloud và blockchain đang định hình mô hình kinh tế số mới AI định hình tương lai Việt Nam – Chloe Phung Những khái niệm từng bị xem là “không thể” với U2U cách đây hai năm nay đã trở thành hiện thực Việt Nam không chỉ bắt kịp xu hướng AI toàn cầu mà còn đang định hình kỷ nguyên AI Tác động thực tế của AI tại Việt Nam Giáo dục:\n60% học sinh, sinh viên Việt Nam sử dụng công cụ học tập EdTech AI cải thiện khả năng tiếp cận, giảm rào cản ngôn ngữ và tăng mức độ tương tác Kinh tế:\nHơn 765 startup AI, đưa Việt Nam đứng thứ 2 ASEAN AI dự kiến đóng góp 120–130 tỷ USD vào GDP Tác động xã hội:\nCác bệnh viện ứng dụng AI giảm thời gian xử lý bệnh nhân còn 5 phút AI hỗ trợ tối ưu giao thông, giám sát năng lượng, và bảo vệ bờ biển Ví dụ công nghệ Nubila – Dự báo thời tiết dựa trên AI Staex – Triển khai thành công 1.000+ thiết bị IoT tại châu Á và châu Âu Sự kết hợp giữa AI \u0026amp; blockchain Generative AI rút ngắn chu kỳ phát triển từ vài tuần xuống còn vài giờ hoặc vài ngày Blockchain trở nên dễ tiếp cận hơn cho cả người mới khi kết hợp với AI AI cải thiện ra quyết định cho doanh nghiệp và nhà hoạch định chính sách Ghi nhận vai trò của AWS trong việc hỗ trợ hệ sinh thái công nghệ này Các sáng kiến của AWS tại Việt Nam – Erik AWS đã đào tạo hơn 100.000 chuyên gia cloud tại Việt Nam Tiếp tục mở rộng khả năng tiếp cận dịch vụ cloud trên toàn quốc Ra mắt chương trình FJC kéo dài 6 tháng, mang đến lộ trình nghề nghiệp trong lĩnh vực công nghệ Nhấn mạnh giá trị văn hóa vững mạnh của AWS như một lợi thế cốt lõi Khi văn hóa gặp gỡ đổi mới – Jaime Valless Nhân loại đang bước vào thời đại trọng yếu nơi AI sẽ định hình lại mọi ngành Chuyển đổi AI không chỉ cần công nghệ mà còn cần kỹ năng, con người, văn hóa và trách nhiệm Khuyến khích học tập liên tục và sử dụng AI một cách đạo đức AWS hỗ trợ triển khai AI an toàn với khả năng truy cập đa mô hình và nhiều lớp bảo vệ Ví dụ sử dụng thực tế Nearmap: Sử dụng mô hình AI để tăng tốc ra quyết định bằng cách tự động hóa các tác vụ lặp lại, giúp con người tập trung vào sáng tạo và chiến lược Những Điểm Rút Ra Tư Duy Thiết Kế (Design Mindset) Cloud, AI và blockchain cùng nhau mở ra các cơ hội đổi mới lớn Hợp tác giữa chính phủ, doanh nghiệp và đối tác quốc tế thúc đẩy tiến bộ số nhanh chóng Triển khai AI phải đặt ưu tiên trách nhiệm, an ninh và sự giám sát của con người Kiến Trúc Kỹ Thuật (Technical Architecture) AI tăng tốc phát triển phần mềm thông qua tự động hóa coding, testing và tối ưu hóa Các bài toán IoT và mô hình thời tiết cho thấy khả năng mở rộng AI đa ngành Generative AI giảm rào cản khi tiếp cận công nghệ phức tạp như blockchain Chiến Lược Hiện Đại Hóa (Modernization Strategy) Ứng dụng cloud + AI + blockchain để tạo nên chuyển đổi có tác động Đầu tư vào đào tạo kỹ năng số liên tục Duy trì AI có trách nhiệm: kiểm soát truy cập, bảo mật prompt, giảm thiểu hallucination, bảo vệ dữ liệu Ứng Dụng Vào Công Việc Áp dụng quy trình phát triển tập trung AI với công cụ AWS Tích hợp nguyên tắc AI có trách nhiệm: theo dõi người dùng, human-in-the-loop, bảo mật prompt, xác thực dữ liệu Xem xét kiến trúc RAG để đảm bảo AI doanh nghiệp chính xác và an toàn Thử nghiệm các dịch vụ như Amazon Q và QuickSight để prototype nhanh và xây dashboard trực quan Trải Nghiệm Sự Kiện Tham dự “AWS Cloud, AI \u0026amp; Innovation Summit” mang lại góc nhìn toàn diện về cách cloud, AI và blockchain đang thúc đẩy chuyển đổi số tại Việt Nam.\nHọc hỏi từ các lãnh đạo ngành Lãnh đạo chính phủ, đại diện quốc tế và lãnh đạo AWS chia sẻ tầm nhìn chiến lược Các ví dụ thực tế minh họa tác động của AI lên giáo dục, tăng trưởng kinh tế và dịch vụ công Trải nghiệm kỹ thuật thực tế Các phiên buổi chiều bao gồm AWS SageMaker, AI-driven SDLC, và bảo mật ứng dụng AI\nTrình diễn toàn bộ quy trình phát triển phần mềm có hỗ trợ AI:\nKhởi tạo (Inception): tạo ý tưởng, thu thập yêu cầu Xây dựng (Construction): mô hình hóa, sinh code, testing, triển khai IaC Vận hành (Operation): triển khai sản phẩm và xử lý sự cố Thực hành bảo mật cho ứng dụng AI Thảo luận các rủi ro như hallucination, nhiễm độc dữ liệu, lỗ hổng prompt, và kiểm soát truy cập Cung cấp mô hình kiến trúc an toàn cho triển khai AI, bảo vệ chuỗi cung ứng, sử dụng RAG, và giám sát người dùng Tận dụng công cụ AWS Amazon Q và QuickSight giúp xây dashboard và tự động hóa workflow nhanh chóng AI hỗ trợ coding, viết tài liệu, refactor và nhiều hơn nữa—tăng năng suất nhưng vẫn giữ sự giám sát của con người Bài học rút ra AI và cloud mang lại hiệu suất và đổi mới trên nhiều lĩnh vực An ninh vững chắc, thực hành có trách nhiệm và sự giám sát của con người là không thể thiếu Việt Nam đang có đà phát triển mạnh mẽ trong ứng dụng AI và chuyển đổi số Một số hình ảnh sự kiện Hình 1 Hình 2 Hình 3 Tóm lại, sự kiện mang đến góc nhìn chiến lược, chiều sâu kỹ thuật và các ví dụ thực tế cho thấy AI, cloud và blockchain đang định hình tương lai số của Việt Nam.\n"},{"uri":"https://github.com/leduc121/fcj_report/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Văn A\nSố điện thoại: 0989888999\nEmail: Anguyenvan@gmail.com\nTrường: Đại học Sư phạm Kỹ thuật TP.HCM\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://github.com/leduc121/fcj_report/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"WEBSITE TRỰC TUYẾN THEO DÕI VÀ DỰ BÁO QUỸ ĐẠO BÃO Trong workshop này, nhóm chúng em trình bày cách xây dựng một nền tảng trực tuyến cho phép người dùng truy cập Internet có thể tự do kiểm tra, theo dõi và thậm chí dự đoán đường đi của các cơn bão đang hoạt động tại khu vực Tây Thái Bình Dương. Nền tảng này giúp người dùng chủ động chuẩn bị cho các thảm họa tự nhiên sắp xảy ra và giảm thiểu thiệt hại tiềm tàng.\nNền tảng cung cấp hai chức năng chính:\nHiển thị các cơn bão gần nhất – Cho phép người dùng xem đường đi, cường độ, tốc độ gió và các đặc điểm khác của bão gần đây trong khu vực Tây Thái Bình Dương.\nDự đoán quỹ đạo bão – Cho phép người dùng nhập dữ liệu vị trí bão trong quá khứ (vĩ độ và kinh độ; tối thiểu 9 điểm dữ liệu) để hệ thống dự đoán hướng di chuyển trong tương lai.\nPhân chia theo tiến độ, chúng em sẽ lần lượt trình bày về bộ dữ liệu, quá trình tiền xử lý, pipeline huấn luyện mô hình, và quá trình xây dựng nền tảng trực tuyến bằng các dịch vụ AWS. Chúng em cũng sẽ perform kỹ thuật tăng cường dữ liệu được đề xuất — Stepwise Temporal Fading Augmentation (STFA) cùng với việc ứng dụng machine learning dựa trên các quy tắc vật lý (physics-informed ML). Những phương pháp này giúp dữ liệu huấn luyện trở nên chân thực hơn và cải thiện đáng kể độ chính xác trong dự đoán đường đi bão, tuổi thọ bão và tổng quãng đường di chuyển.\nHình 1 : Pipeline mô hình Sau khi hoàn thành quá trình huấn luyện mô hình, chúng em triển khai xây dựng nền tảng trực tuyến bằng kiến trúc serverless. Đây là kiến trúc tiết kiệm chi phí, có khả năng mở rộng tốt, và dễ dàng bảo trì/triển khai — rất phù hợp cho mục tiêu dự án. Dưới đây là các dịch vụ AWS chính được sử dụng:\nAWS Lambda – Chạy các mô hình ML và xử lý logic phía backend Amazon S3 – Lưu trữ file tĩnh, mô hình ML và dữ liệu bão Amazon API Gateway – Định tuyến và phần luồng các yêu cầu của người dùng đến Lambda phù hợp, tùy theo việc họ xem dữ liệu bão gần đây hay chạy dự đoán Amazon CloudFront – Tăng tốc phân phối nội dung thông qua các edge location AWS Secrets Manager – Lưu trữ khóa API và các thông tin nhạy cảm … – Các dịch vụ hỗ trợ bổ sung khác khi cần Hình 2 : Kiến trúc nền tảng "},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Làm công việc A\u0026hellip;\nTuần 3: Làm công việc B\u0026hellip;\nTuần 4: Làm công việc C\u0026hellip;\nTuần 5: Làm công việc D\u0026hellip;\nTuần 6: Làm công việc E\u0026hellip;\nTuần 7: Làm công việc G\u0026hellip;\nTuần 8: Làm công việc H\u0026hellip;\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Làm quen với việc tạo tài khoản AWS và thiết lập cơ bản Học về quản lý ngân sách AWS Budget Hiểu về IAM (Identity and Access Management) cơ bản Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Làm quen với chương trình thực tập AWS - Đọc và hiểu hướng dẫn thực tập 08/09/2024 08/09/2024 2 - Tìm hiểu về cách tạo tài khoản AWS - Hiểu về lợi ích AWS Free Tier - Thực hành: Tạo tài khoản AWS 09/09/2024 09/09/2024 https://000001.awsstudygroup.com/ 3 - Tìm hiểu về AWS Budgets - Hiểu về quản lý và giám sát chi phí - Thực hành: Thiết lập cảnh báo ngân sách 10/09/2024 10/09/2024 https://000007.awsstudygroup.com/ 4 - Tìm hiểu IAM cơ bản: + Users, Groups, Roles + Policies và Permissions + MFA (Multi-Factor Authentication) - Thực hành: + Tạo IAM users + Gán policies + Bật MFA 11/09/2024 12/09/2024 https://000002.awsstudygroup.com/ 5 - Ôn tập và củng cố kiến thức tuần 1 - Hoàn thành các bài tập thực hành 13/09/2024 13/09/2024 Kết quả đạt được tuần 1: Đã tạo và cấu hình thành công tài khoản AWS với Free Tier Hiểu được tầm quan trọng của quản lý ngân sách và thiết lập cảnh báo giám sát chi phí Nắm vững các khái niệm IAM bao gồm users, groups, roles và policies Triển khai các phương pháp bảo mật tốt nhất bằng cách bật MFA cho tài khoản AWS Học được cách quản lý kiểm soát truy cập và phân quyền trong môi trường AWS "},{"uri":"https://github.com/leduc121/fcj_report/vi/4-eventparticipated/4.2-event2/","title":"Cloud Mastery 1","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud Mastery Series #1” Mục Đích Của Sự Kiện Cung cấp kiến thức thực tiễn về AWS Bedrock và quy trình phát triển AI hiện đại Giới thiệu các khái niệm cốt lõi về foundation models và kỹ thuật prompt engineering hiệu quả Trình diễn quy trình RAG và các kỹ thuật tìm kiếm dựa trên embedding Giới thiệu các dịch vụ AI phổ biến của AWS dành cho các giải pháp thực tế Giải thích AgentCore và cách xây dựng kiến trúc ứng dụng GenAI sẵn sàng cho sản xuất Diễn Giả Lâm Tuấn Kiệt – Senior DevOps Engineer, FPT Software Đặng Hoàng Hiếu Nghi – AI Engineer, Reonova Cloud Đinh Lê Hoàng Anh – Cloud Engineer Trainee, FCJ Kha – Chia sẻ định hướng xây dựng các dự án thiên về sản phẩm để tăng sức mạnh cho CV Đại diện FPT – Chia sẻ ví dụ về các doanh nghiệp ứng dụng AI dựa trên cloud để tối ưu chi phí và hiệu suất Những Điểm Nổi Bật Foundation Models \u0026amp; Xu Hướng Ngành Các mô hình ML truyền thống chỉ phù hợp với từng tác vụ cụ thể và phụ thuộc nhiều vào dữ liệu gán nhãn. Foundation models trong GenAI được huấn luyện trên lượng lớn dữ liệu không gán nhãn, cho phép xử lý linh hoạt nhiều tác vụ. AWS Bedrock hiện hỗ trợ các mô hình như OpenAI và DeepSeek. Ngày càng nhiều doanh nghiệp chuyển workload AI lên cloud để giảm chi phí vận hành. Góc Nhìn từ Lâm Tuấn Kiệt Giới thiệu tổng quan về sự chuyển dịch từ ML truyền thống → foundation models. Nhấn mạnh vai trò của prompt engineering trong việc tạo ra kết quả chất lượng cao. Trình bày cách Bedrock loại bỏ phức tạp DevOps khi truy cập các mô hình tiên tiến. Nhấn mạnh việc xây dựng sản phẩm AI đòi hỏi lặp lại liên tục, kỹ năng, và thực hành có trách nhiệm. Prompt Engineering Zero-shot prompting – Ít ngữ cảnh; kết quả có thể chung chung. Few-shot prompting – Thêm ví dụ giúp mô hình trả lời rõ hơn và chính xác hơn. Chain-of-thought prompting – Khuyến khích lý luận từng bước để tăng độ chi tiết và đúng đắn. Retrieval-Augmented Generation (RAG) Truy xuất thông tin liên quan từ nguồn dữ liệu bên ngoài. Kết hợp ngữ cảnh truy xuất với prompt ban đầu một cách tự động. Tạo ra câu trả lời chính xác và phù hợp ngữ cảnh hơn. Embeddings Chuyển đổi văn bản thành vector biểu diễn ý nghĩa ngữ nghĩa. Các khái niệm tương tự nằm gần nhau trong không gian vector. AWS Titan Text Embeddings hỗ trợ đa ngôn ngữ hơn 100+ ngôn ngữ. Dịch Vụ AI của AWS Rekognition – Phân tích hình ảnh/video Translate – Dịch đa ngôn ngữ Textract – Trích xuất văn bản và bố cục Transcribe – Chuyển giọng nói thành văn bản, hỗ trợ phân biệt người nói Polly – Chuyển văn bản thành giọng nói tự nhiên Comprehend – NLP, trích xuất thực thể và phát hiện quan hệ Kendra – Tìm kiếm thông minh cho doanh nghiệp Lookout Family – Phát hiện bất thường cho dữ liệu chỉ số, thiết bị và hình ảnh Personalize – Gợi ý theo thời gian thực Pipecat – Framework xây dựng pipeline AI agent Tất cả dịch vụ đều có thể tích hợp thông qua API.\nAmazon Bedrock AgentCore Cho phép xây dựng ứng dụng AI mà không cần hạ tầng hoặc DevOps phức tạp. Tương thích với các framework agent hiện đại như LangGraph và LangChain. Giúp đội ngũ chuyển từ prototype → production nhanh chóng và an toàn. Các thành phần cốt lõi\nRuntime Memory Identity Gateway Code Interpreter Browser Tool Observability Những Điểm Rút Ra Tư Duy Phát Triển AI Xây dựng sản phẩm thực tế mang lại giá trị lớn hơn nhiều so với chỉ hoàn thành bài tập lý thuyết. Foundation models hỗ trợ thử nghiệm nhanh, lặp lại và triển khai dễ dàng. Prompt engineering vẫn là chìa khóa để đạt chất lượng đầu ra cao. Tác Động Kỹ Thuật RAG tăng độ chính xác bằng cách dựa trên tài liệu thật. Embeddings nâng cao tìm kiếm ngữ nghĩa và truy xuất thông minh. Dịch vụ AI của AWS hỗ trợ toàn bộ quy trình AI – từ giọng nói, hình ảnh đến văn bản và phân tích. Tính Thực Tiễn Các tổ chức đang áp dụng AI dựa trên cloud để giảm chi phí và mở rộng nhanh hơn. Kỹ năng về prompt engineering, embeddings và Bedrock đang trở nên rất cần thiết. Trải Nghiệm Sự Kiện Tham dự AWS Cloud Mastery Series #1 giúp tôi có thêm trải nghiệm thực hành trong xây dựng hệ thống AI trên AWS.\n1. Học trực tiếp từ các kỹ sư Diễn giả chia sẻ kinh nghiệm thực tế từ DevOps, AI và cloud engineering. 2. Kiến thức kỹ thuật thực hành Trình diễn kỹ thuật prompting Ví dụ về quy trình RAG Trường hợp thực tế của từng dịch vụ AI trong AWS 3. Xây dựng cho tương lai Khuyến khích tập trung xây dựng sản phẩm thực tế có thể triển khai Kỹ năng Cloud + AI được nhấn mạnh là quan trọng cho nghề nghiệp hiện đại Tập trung mạnh vào ứng dụng thực tế hơn lý thuyết Một số hình ảnh sự kiện Hình 1 Hình 2 Hình 3 Tóm lại, tôi đã học được rất nhiều về AI và Amazon Bedrock, và tôi sẽ áp dụng vào dự án của mình để cải thiện tốt hơn.\n"},{"uri":"https://github.com/leduc121/fcj_report/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"CrazyGames nâng cấp nền tảng với hệ thống bạn bè thời gian thực sử dụng AWS AppSync Tác giả: Emily McKinzie | vào ngày: 08 tháng 10 năm 2024 | trong: Amazon EC2, Amazon MemoryDB, AWS AppSync, Compute, Customer Solutions, Database, Front-End Web \u0026amp; Mobile, Game Development, Industries, Top Posts | Permalink | Comments | Share\nNền tảng game nhiều người chơi CrazyGames thu hút hơn 35 triệu người chơi trên toàn thế giới với các tựa game trên trình duyệt như Ludo King và Paper Delivery Boy bằng 24 ngôn ngữ khác nhau. Dù chơi qua thiết bị máy tính để bàn hay di động, tất cả game thủ giờ đây đều có thể tận hưởng trải nghiệm xã hội được nâng cao với hệ thống bạn bè thời gian thực mới được xây dựng bằng Amazon Web Services (AWS) AppSync.\nCrazyGames đã all-in với AWS ngay từ ngày đầu tiên, chạy trên một instance Amazon Elastic Compute Cloud (Amazon EC2) duy nhất khi được xây dựng ban đầu vào năm 2014. Kể từ đó, nền tảng đã phát triển một cách tự nhiên và hiện tại lưu trữ hơn 3.000 game thuộc nhiều thể loại khác nhau. Nhìn lại vai trò mà AWS đã đóng trong quá trình phát triển liên tục của công ty, Nhà sáng lập và CEO của CrazyGames Raf Mertens nhận xét:\n\u0026ldquo;AWS cung cấp một loạt các dịch vụ có tính khả dụng cao, có thể mở rộng mà chúng tôi có thể thử nghiệm, kiểm tra và sử dụng một cách dễ dàng trong một khoảng thời gian rất ngắn. Bằng cách sử dụng AWS AppSync, chúng tôi đã giảm thời gian phát triển từ tám tháng xuống còn tám tuần.\u0026rdquo;\nNâng cao trải nghiệm xã hội Chơi game cùng bạn bè thú vị hơn vô cùng so với chơi đơn độc và có thể giúp người chơi nâng cao kỹ năng của họ. May mắn thay, các game xã hội cung cấp cơ hội để tạo dựng tình bạn mới với những người có chung sở thích đồng thời củng cố các mối quan hệ hiện có. Các game nhiều người chơi với các yếu tố xã hội mạnh mẽ cũng mang lại lợi ích. Chúng có xu hướng thu hút người chơi tốt hơn, tăng khả năng giữ chân lâu dài và thu hút người dùng mới khi người chơi mời bạn bè của họ.\nCho đến gần đây, khách truy cập CrazyGames không phải lúc nào cũng có thể dễ dàng chơi cùng bạn bè. Họ phải đối mặt với trải nghiệm rời rạc, điều này đã truyền cảm hứng cho công ty thiết kế và triển khai hệ thống bạn bè mới. Giờ đây, người dùng có thể kết bạn với nhau, xem khi nào bạn bè của họ trực tuyến, xem các game họ đang chơi và gửi lời mời chơi game theo thời gian thực.\nĐể phát triển tính năng bạn bè, CrazyGames đã sử dụng phương pháp \u0026lsquo;shape up\u0026rsquo;, bao gồm việc thành lập một nhóm nhỏ, chuyên trách tập trung hoàn toàn vào việc tạo ra hệ thống bạn bè sẵn sàng cho sản xuất. Các nhà phát triển đã xây dựng chức năng mới bằng AWS AppSync, công cụ điều phối trạng thái của nhiều người dùng gần như theo thời gian thực. Người chơi có thể thấy ngay lập tức khi bạn bè của họ đăng nhập hoặc đăng xuất.\nKhi bắt đầu phát triển, nhóm cũng đã tìm hiểu một framework mã nguồn mở và một giải pháp tùy chỉnh được xây dựng bằng WebSocket API trước khi lựa chọn AWS AppSync.\n\u0026ldquo;Người dùng ngày nay mong đợi sự hài lòng ngay lập tức, vì vậy các hoạt động thời gian thực là điều cần thiết. AWS AppSync nổi lên như giải pháp lý tưởng cho hệ thống bạn bè của chúng tôi. Nó yêu cầu ít nỗ lực phát triển hơn do sự trừu tượng hóa trên WebSocket API, hiệu quả về chi phí hơn so với các lựa chọn khác và tích hợp liền mạch với GraphQL client hiện có của chúng tôi,\u0026rdquo; Mertens giải thích. \u0026ldquo;AWS AppSync bao phủ tất cả những gì chúng tôi cần, vì vậy việc thiết lập rất dễ dàng và nó tiếp tục hoạt động tốt khi xử lý hàng chục nghìn người dùng đồng thời với các cập nhật trạng thái thời gian thực.\u0026rdquo;\nNgoài AWS AppSync, CrazyGames sử dụng Amazon Aurora để quản lý dữ liệu tồn tại lâu dài, chẳng hạn như thông báo, trong hệ thống bạn bè mới. Đối với dữ liệu tạm thời hơn đòi hỏi cập nhật nhanh chóng, như lời mời và trạng thái người dùng, công ty sử dụng Redis Cloud on AWS, với Amazon MemoryDB.\nXây dựng với AWS Với một thập kỷ lịch sử làm việc với AWS, CrazyGames đã phát triển hệ sinh thái công nghệ của mình để bao gồm một loạt các giải pháp và dịch vụ AWS. Điều này giúp nhóm của họ tập trung vào phát triển phần mềm thay vì xây dựng, cấu hình và bảo trì máy chủ. Năm ngoái, công ty đã triển khai một hệ thống phân tích mới để có thêm hiểu biết về hành vi và nhu cầu của người dùng. Hệ thống phân tích theo dõi hiệu quả hàng triệu sự kiện hàng ngày trên hơn hai triệu người dùng hàng ngày của nền tảng khi họ tương tác với các tính năng phức tạp.\n\u0026ldquo;Hầu hết các dịch vụ AWS mà chúng tôi đã chọn đều xử lý các trách nhiệm vận hành như tính khả dụng và bảo trì. Điều này có nghĩa là nhóm của chúng tôi có thể dành nhiều thời gian hơn cho việc phát triển phần mềm,\u0026rdquo; Mertens cho biết. \u0026ldquo;Hơn nữa, nền tảng của chúng tôi chịu các đợt tăng đột biến lưu lượng truy cập, và vì sức mạnh tính toán của chúng tôi có thể mở rộng, những đợt tăng đột biến này được backend tự động hấp thụ mà không có thời gian chết hoặc độ trễ.\u0026rdquo;\nHiện tại, CrazyGames đã tích hợp hệ thống bạn bè mới vào 30 game trên nền tảng của họ, từ game bắn súng góc nhìn thứ nhất như Kour.io đến các game kinh điển như 8 Ball Pool Billiards. Khi họ có kế hoạch triển khai hệ thống bạn bè rộng rãi hơn trong 12 tháng tới, công ty đang tìm cách đơn giản hóa trải nghiệm onboarding. Mertens chia sẻ: \u0026ldquo;Một khi người dùng biết tính năng bạn bè mới tồn tại, họ thực sự yêu thích nó, nhưng chúng tôi vẫn phải hướng dẫn họ qua các bước cụ thể để bắt đầu. Chúng tôi muốn làm cho quy trình đó dễ dàng hơn cho họ.\u0026rdquo;\nLên kế hoạch cho tính năng mới tiếp theo Bằng cách tận dụng AWS, các nhà phát triển CrazyGames có thể nhanh chóng và hiệu quả về chi phí trải nghiệm các tính năng mới, giúp công ty duy trì danh tiếng là điểm đến hàng đầu cho các game xã hội hấp dẫn dựa trên web. Mertens kết luận:\n\u0026ldquo;Với các dịch vụ được quản lý của AWS, chúng tôi có thể xây dựng nhiều tính năng hơn với thời gian của mình, thay vì phải đối phó với việc quản lý cơ sở hạ tầng. Thêm vào đó, có sự giảm thiểu rủi ro rất lớn. Bạn có thể thử nghiệm và đưa các tính năng mới lên nhanh hơn để tìm hiểu xem chúng có hoạt động hay không, thay vì lãng phí tài nguyên kỹ thuật.\u0026rdquo;\nTìm hiểu thêm về việc xây dựng các trải nghiệm giải trí, có thể mở rộng với tốc độ và sự linh hoạt. Liên hệ với Đại diện AWS để biết cách chúng tôi có thể giúp đẩy nhanh doanh nghiệp của bạn.\nEmily McKinzie Emily McKinzie là Quản lý Marketing Ngành tại Amazon Web Services.\n"},{"uri":"https://github.com/leduc121/fcj_report/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại phần này, bạn cần tóm tắt các nội dung trong workshop mà bạn dự tính sẽ làm.\nIoT Weather Platform for Lab Research Giải pháp AWS Serverless hợp nhất cho giám sát thời tiết thời gian thực 1. Tóm tắt điều hành IoT Weather Platform được thiết kế dành cho nhóm ITea Lab tại TP. Hồ Chí Minh nhằm nâng cao khả năng thu thập và phân tích dữ liệu thời tiết. Nền tảng hỗ trợ tối đa 5 trạm thời tiết, có khả năng mở rộng lên 10–15 trạm, sử dụng thiết bị biên Raspberry Pi kết hợp cảm biến ESP32 để truyền dữ liệu qua MQTT. Nền tảng tận dụng các dịch vụ AWS Serverless để cung cấp giám sát thời gian thực, phân tích dự đoán và tiết kiệm chi phí, với quyền truy cập giới hạn cho 5 thành viên phòng lab thông qua Amazon Cognito.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác trạm thời tiết hiện tại yêu cầu thu thập dữ liệu thủ công, khó quản lý khi có nhiều trạm. Không có hệ thống tập trung cho dữ liệu hoặc phân tích thời gian thực, và các nền tảng bên thứ ba thường tốn kém và quá phức tạp.\nGiải pháp\nNền tảng sử dụng AWS IoT Core để tiếp nhận dữ liệu MQTT, AWS Lambda và API Gateway để xử lý, Amazon S3 để lưu trữ (bao gồm data lake), và AWS Glue Crawlers cùng các tác vụ ETL để trích xuất, chuyển đổi, tải dữ liệu từ S3 data lake sang một S3 bucket khác để phân tích. AWS Amplify với Next.js cung cấp giao diện web, và Amazon Cognito đảm bảo quyền truy cập an toàn. Tương tự như Thingsboard và CoreIoT, người dùng có thể đăng ký thiết bị mới và quản lý kết nối, nhưng nền tảng này hoạt động ở quy mô nhỏ hơn và phục vụ mục đích sử dụng nội bộ. Các tính năng chính bao gồm bảng điều khiển thời gian thực, phân tích xu hướng và chi phí vận hành thấp.\nLợi ích và hoàn vốn đầu tư (ROI)\nGiải pháp tạo nền tảng cơ bản để các thành viên phòng lab phát triển một nền tảng IoT lớn hơn, đồng thời cung cấp nguồn dữ liệu cho những người nghiên cứu AI phục vụ huấn luyện mô hình hoặc phân tích. Nền tảng giảm bớt báo cáo thủ công cho từng trạm thông qua hệ thống tập trung, đơn giản hóa quản lý và bảo trì, đồng thời cải thiện độ tin cậy dữ liệu. Chi phí hàng tháng ước tính 0,66 USD (theo AWS Pricing Calculator), tổng cộng 7,92 USD cho 12 tháng. Tất cả thiết bị IoT đã được trang bị từ hệ thống trạm thời tiết hiện tại, không phát sinh chi phí phát triển thêm. Thời gian hoàn vốn 6–12 tháng nhờ tiết kiệm đáng kể thời gian thao tác thủ công.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.\nDịch vụ AWS sử dụng\nAWS IoT Core: Tiếp nhận dữ liệu MQTT từ 5 trạm, mở rộng lên 15. AWS Lambda: Xử lý dữ liệu và kích hoạt Glue jobs (2 hàm). Amazon API Gateway: Giao tiếp với ứng dụng web. Amazon S3: Lưu trữ dữ liệu thô (data lake) và dữ liệu đã xử lý (2 bucket). AWS Glue: Crawlers lập chỉ mục dữ liệu, ETL jobs chuyển đổi và tải dữ liệu. AWS Amplify: Lưu trữ giao diện web Next.js. Amazon Cognito: Quản lý quyền truy cập cho người dùng phòng lab. Thiết kế thành phần\nThiết bị biên: Raspberry Pi thu thập và lọc dữ liệu cảm biến, gửi tới IoT Core. Tiếp nhận dữ liệu: AWS IoT Core nhận tin nhắn MQTT từ thiết bị biên. Lưu trữ dữ liệu: Dữ liệu thô lưu trong S3 data lake; dữ liệu đã xử lý lưu ở một S3 bucket khác. Xử lý dữ liệu: AWS Glue Crawlers lập chỉ mục dữ liệu; ETL jobs chuyển đổi để phân tích. Giao diện web: AWS Amplify lưu trữ ứng dụng Next.js cho bảng điều khiển và phân tích thời gian thực. Quản lý người dùng: Amazon Cognito giới hạn 5 tài khoản hoạt động. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần — thiết lập trạm thời tiết biên và xây dựng nền tảng thời tiết — mỗi phần trải qua 4 giai đoạn:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu Raspberry Pi với cảm biến ESP32 và thiết kế kiến trúc AWS Serverless (1 tháng trước kỳ thực tập). Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính và điều chỉnh (Tháng 1). Điều chỉnh kiến trúc để tối ưu chi phí/giải pháp: Tinh chỉnh (ví dụ tối ưu Lambda với Next.js) để đảm bảo hiệu quả (Tháng 2). Phát triển, kiểm thử, triển khai: Lập trình Raspberry Pi, AWS services với CDK/SDK và ứng dụng Next.js, sau đó kiểm thử và đưa vào vận hành (Tháng 2–3). Yêu cầu kỹ thuật\nTrạm thời tiết biên: Cảm biến (nhiệt độ, độ ẩm, lượng mưa, tốc độ gió), vi điều khiển ESP32, Raspberry Pi làm thiết bị biên. Raspberry Pi chạy Raspbian, sử dụng Docker để lọc dữ liệu và gửi 1 MB/ngày/trạm qua MQTT qua Wi-Fi. Nền tảng thời tiết: Kiến thức thực tế về AWS Amplify (lưu trữ Next.js), Lambda (giảm thiểu do Next.js xử lý), AWS Glue (ETL), S3 (2 bucket), IoT Core (gateway và rules), và Cognito (5 người dùng). Sử dụng AWS CDK/SDK để lập trình (ví dụ IoT Core rules tới S3). Next.js giúp giảm tải Lambda cho ứng dụng web fullstack. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp phần cứng. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm trong vòng 1 năm. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS Lambda: 0,00 USD/tháng (1.000 request, 512 MB lưu trữ). S3 Standard: 0,15 USD/tháng (6 GB, 2.100 request, 1 GB quét). Truyền dữ liệu: 0,02 USD/tháng (1 GB vào, 1 GB ra). AWS Amplify: 0,35 USD/tháng (256 MB, request 500 ms). Amazon API Gateway: 0,01 USD/tháng (2.000 request). AWS Glue ETL Jobs: 0,02 USD/tháng (2 DPU). AWS Glue Crawlers: 0,07 USD/tháng (1 crawler). MQTT (IoT Core): 0,08 USD/tháng (5 thiết bị, 45.000 tin nhắn). Tổng: 0,7 USD/tháng, 8,40 USD/12 tháng\nPhần cứng: 265 USD một lần (Raspberry Pi 5 và cảm biến). 7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng trung bình, xác suất trung bình. Hỏng cảm biến: Ảnh hưởng cao, xác suất thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nMạng: Lưu trữ cục bộ trên Raspberry Pi với Docker. Cảm biến: Kiểm tra định kỳ, dự phòng linh kiện. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Dữ liệu và phân tích thời gian thực thay thế quy trình thủ công. Có thể mở rộng tới 10–15 trạm.\nGiá trị dài hạn: Nền tảng dữ liệu 1 năm cho nghiên cứu AI, có thể tái sử dụng cho các dự án tương lai.\n"},{"uri":"https://github.com/leduc121/fcj_report/vi/5-workshop/5.2-data-preparation/","title":"Chuẩn Bị Dữ Liệu","tags":[],"description":"","content":"Thu Thập và Xử Lý Dữ Liệu Dữ liệu là một thành phần quan trọng trong dự án. Nó không chỉ cung cấp nguồn kiến thức cho mô hình machine learning mà còn được hiển thị trực tiếp cho người dùng cuối để theo dõi các cơn bão mới nhất tại khu vực Tây Thái Bình Dương. Vì dữ liệu có mục đích kép — huấn luyện mô hình và trực quan hóa theo thời gian thực — chúng em đã xem xét kỹ lưỡng nhiều nguồn data source đáng tin cậy và có thẩm quyền trước khi chọn một bộ dữ liệu đáp ứng đầy đủ các yêu cầu, đó là: Dữ liệu bão của NOAA.\nNOAA (National Oceanic and Atmospheric Administration) là cơ quan khoa học thuộc Bộ Thương mại Hoa Kỳ. NOAA cung cấp dữ liệu môi trường có độ chính xác cao phục vụ nghiên cứu, bao gồm quan sát thời tiết toàn cầu, ảnh vệ tinh và thông tin về các xoáy thuận nhiệt đới. Với nhiều thập kỷ đầu tư vào công nghệ tiên tiến như vệ tinh địa tĩnh, hệ thống radar và mạng lưới giám sát khí hậu, NOAA được xem là một trong những nguồn cung cấp dữ liệu bão đáng tin cậy nhất trên thế giới.\nTrong dự án này, chúng em sử dụng dữ liệu từ International Best Track Archive for Climate Stewardship (IBTrACS) — một dự án do NOAA khởi xướng và là bộ dữ liệu xoáy thuận nhiệt đới toàn diện nhất thế giới. IBTrACS tổng hợp dữ liệu đường đi của bão trong lịch sử từ nhiều cơ quan khí tượng (ví dụ: JTWC, JMA, CMA, NHC). Bằng cách hợp nhất các nguồn vào một định dạng thống nhất, IBTrACS cải thiện khả năng so sánh giữa các cơ quan và đảm bảo các nhà nghiên cứu trên toàn thế giới có quyền truy cập dữ liệu chất lượng cao nhất.\nPhiên bản mới nhất của bộ dữ liệu này chứa 226.153 dòng ghi nhận quan sát bão. Mỗi dòng bao gồm nhiều thuộc tính giá trị như:\nsid – mã cơn bão number – số thứ tự bão basin / subbasin – phân loại khu vực nature – loại bão (ví dụ: áp thấp, bão nhiệt đới, siêu bão) iso_time – thời gian lat / lon – tọa độ tâm bão … và nhiều thông số khí tượng học khác Tuy nhiên, đối với mô hình machine learning, chúng em chỉ tập trung vào bốn cột chính: sid, iso_time, lat, và lon. Đây là chuỗi thời gian cơ bản dùng để dự đoán quỹ đạo di chuyển của bão.\nBộ dữ liệu bao gồm các cơn bão từ 1870 đến 2025, được lọc chỉ giữ lại các cơn bão trong khu vực Tây Thái Bình Dương — phạm vi địa lý mà dự án hướng đến. Bộ dữ liệu gốc được công khai tại: https://data.humdata.org/dataset/vnm-ibtracs-tropical-storm-tracks#\nLàm sạch dữ liệu và Trích xuất đặc trưng dựa trên quy luật vật lý Một ưu điểm của IBTrACS là dữ liệu đã được bảo trì tốt và có tính nhất quán cao. Việc tiền xử lý chỉ yêu cầu các bước tối thiểu, chủ yếu là loại bỏ giá trị thiếu.\nSau khi làm sạch, chúng em áp dụng bước đầu tiên của machine learning dựa trên vật lý (physics-informed ML) — kỹ thuật đưa kiến thức vật lý trực tiếp vào pipeline dữ liệu. Từ tọa độ vĩ độ – kinh độ, nhóm tính thêm hai đặc trưng bằng công thức Haversine:\nKhoảng cách giữa hai điểm bão liên tiếp Góc phương vị (bearing) — hướng di chuyển Các đặc trưng này mang ý nghĩa vật lý: chúng phản ánh quy luật chuyển động thực tế, thay vì những biến đổi tùy ý. Nhờ đó, chúng tăng cường bối cảnh về quán tính và hướng di chuyển của bão, giúp mô hình học hiệu quả hơn và dự đoán chính xác hơn.\nHình 1 : Mô tả dữ liệu Dữ Liệu Hiển Thị Trên Nền Tảng Dữ liệu dùng để hiển thị trên nền tảng khác với dữ liệu dùng để huấn luyện, dù cả hai đều xuất phát từ NOAA. Dữ liệu huấn luyện là tĩnh, còn dữ liệu hiển thị phải cập nhật theo tình hình bão hiện tại.\nĐể xử lý yêu cầu này, nhóm đã triển khai một AWS Lambda chạy theo lịch, tự động lấy dữ liệu đường đi bão mới nhất vào cuối mỗi ngày. Điều này đảm bảo nền tảng luôn hiển thị thông tin mới, chính xác và kịp thời cho người dùng.\nDữ liệu hiển thị sau xử lý được lưu dưới dạng file JSON trong S3. Khi người dùng truy cập website:\nFrontend gửi yêu cầu tới API Gateway API Gateway kích hoạt Lambda tương ứng Lambda lấy file JSON từ S3 Dữ liệu được trả về cho người dùng để hiển thị trực quan Pipeline này đảm bảo khả năng cập nhật thời gian thực, serverless và tiết kiệm chi phí.\nBộ dữ liệu bão có thể truy cập tại: https://ncics.org/ibtracs/\nHình 2 : Web để crawl dữ liệu "},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Học về VPC (Virtual Private Cloud) cơ bản và các khái niệm mạng Hiểu về dịch vụ EC2 (Elastic Compute Cloud) và quản lý instance Nghiên cứu React framework cho phát triển frontend Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Học VPC cơ bản: + Khái niệm và kiến trúc VPC + Subnets (Public và Private) + Route Tables + Internet Gateway 15/09/2024 15/09/2024 https://000003.awsstudygroup.com/ 2 - Tiếp tục học VPC: + NAT Gateway + Security Groups + Network ACLs - Thực hành: Tạo VPC với public và private subnets 16/09/2024 16/09/2024 https://000003.awsstudygroup.com/ 3 - Học EC2 cơ bản: + Các loại và họ instance + AMI (Amazon Machine Images) + EBS (Elastic Block Store) + Security Groups cho EC2 17/09/2024 17/09/2024 https://000004.awsstudygroup.com/ 4 - Tiếp tục học EC2: + Các phương thức kết nối SSH + Elastic IP + EC2 User Data - Thực hành: Khởi chạy EC2 instances trong VPC 18/09/2024 18/09/2024 https://000004.awsstudygroup.com/ 5 - Bắt đầu học React: + React cơ bản + Components và Props + State và Lifecycle + Hooks (useState, useEffect) - Thực hành: Xây dựng React components đơn giản 19/09/2024 20/09/2024 Tài liệu React Kết quả đạt được tuần 2: Kiến thức VPC:\nHiểu kiến trúc VPC và cách thiết kế topology mạng trong AWS Học được sự khác biệt giữa public và private subnets Nắm vững khái niệm routing với Route Tables và Internet Gateway Hiểu NAT Gateway cho truy cập internet từ private subnets Học về bảo mật mạng với Security Groups và Network ACLs Tạo thành công VPC với cấu hình subnet phù hợp Kiến thức EC2:\nHiểu được các loại EC2 instance và trường hợp sử dụng Học về AMI và cách chọn image phù hợp Hiểu về EBS volumes và các tùy chọn lưu trữ Nắm vững các phương thức kết nối SSH đến EC2 instances Học về Elastic IP cho địa chỉ IP tĩnh Khởi chạy và quản lý thành công EC2 instances trong VPC Phát triển React:\nHiểu React cơ bản và kiến trúc dựa trên component Học về cú pháp JSX và composition component Nắm vững quản lý state với useState hook Hiểu lifecycle component và useEffect hook Xây dựng ứng dụng React đơn giản với functional components Có nền tảng cho phát triển frontend hiện đại "},{"uri":"https://github.com/leduc121/fcj_report/vi/4-eventparticipated/4.3-event3/","title":"AWS Cloud Mastery Series #2","tags":[],"description":"","content":"Bài thu hoạch “Devops on aws” Mục đích của sự kiện Giới thiệu các nguyên tắc cốt lõi của DevOps và tư duy văn hóa thúc đẩy quy trình phát triển phần mềm hiện đại Trình diễn cách xây dựng pipeline CI/CD tự động bằng các dịch vụ AWS Hướng dẫn triển khai Infrastructure as Code (IaC) So sánh các nền tảng container của AWS cho ứng dụng cloud-native Chia sẻ best practices về monitoring, observability và khả năng quan sát vận hành Diễn Giả Bảo Huỳnh – AWS Community Builder Thịnh Nguyễn – AWS Community Builder Vi Trần – AWS Community Builder Những Điểm Nổi Bật Hiểu về Tư Duy DevOps Sự hợp tác chặt chẽ giữa team phát triển và vận hành giúp tăng tốc độ release Tự động hóa giảm công việc lặp lại và tăng tính nhất quán Vòng phản hồi liên tục tạo ra hệ thống ổn định và bền vững hơn Pipeline CI/CD trên AWS Một pipeline tự động hoàn chỉnh được mô phỏng qua bốn giai đoạn:\nSource Control: CodeCommit để lưu trữ và quản lý phiên bản mã Build \u0026amp; Test: CodeBuild để biên dịch, kiểm thử và đóng gói Deployment: CodeDeploy hỗ trợ rolling, canary, và blue/green Orchestration: CodePipeline kết nối và tự động hóa toàn bộ các giai đoạn Demo trực tiếp cho thấy mỗi lần commit code sẽ tự động kích hoạt build → test → deploy → rollback khi cần.\nInfrastructure as Code (IaC) Chuyển từ cấu hình thủ công sang hạ tầng nhất quán và có kiểm soát phiên bản.\nAWS CloudFormation\nTemplate YAML/JSON dạng khai báo Hỗ trợ parameters, conditions, outputs và định nghĩa tài nguyên Drift detection đảm bảo hạ tầng thực tế trùng khớp với template AWS CDK (Cloud Development Kit)\nTạo hạ tầng bằng TypeScript, Python, Java, và nhiều ngôn ngữ khác Các construct L1/L2/L3 hỗ trợ mẫu tái sử dụng CLI hỗ trợ synth, diff, deploy Ví dụ cho thấy kiến trúc giống nhau có thể tái tạo hoàn toàn bằng IaC thay vì “ClickOps.”\nContainers trên AWS Giới thiệu kiến thức cơ bản về Docker và các tùy chọn container trên AWS:\nAmazon ECR: Registry bảo mật, có quét lỗ hổng Amazon ECS: Orchestration thuần AWS, lựa chọn EC2 hoặc Fargate Amazon EKS: Kubernetes được quản lý AWS App Runner: Hosting container đơn giản, ít vận hành Phần so sánh giúp chọn đúng dịch vụ tùy theo kỹ năng, nhu cầu mở rộng và mô hình ứng dụng.\nObservability và Monitoring Các thực hành quan trọng để đảm bảo sức khỏe ứng dụng:\nAmazon CloudWatch\nMetrics, logs, dashboards và alarms AWS X-Ray\nTracing phân tán trong microservices để phát hiện độ trễ và bottleneck Nhấn mạnh xây dựng dashboard hữu ích, cảnh báo có hành động, và chiến lược giám sát chủ động.\nNhững Điểm Rút Ra DevOps Practices Tự động hóa tăng tốc độ và độ tin cậy Sự đồng bộ giữa dev và ops là yếu tố then chốt Sử dụng DORA metrics để cải tiến liên tục Tích hợp vòng phản hồi xuyên suốt phát triển Infrastructure as Code Giảm cấu hình thủ công trong môi trường production CloudFormation mạnh về mô hình khai báo CDK linh hoạt nhờ định nghĩa hạ tầng bằng code Xem hạ tầng như phần mềm: test, version, automate Application Delivery CI/CD giảm lỗi con người và tăng tốc release Chọn chiến lược triển khai dựa trên mức độ rủi ro Tự động kiểm thử cần có trong mọi giai đoạn pipeline Chiến Lược Container Container tăng tính portable, nhất quán và module hóa ECS → mô hình vận hành đơn giản EKS → hệ sinh thái Kubernetes linh hoạt App Runner → mô hình ít vận hành nhất ECR là kho trung tâm cho container images Observability Kết hợp logs, metrics và traces để có cái nhìn toàn diện CloudWatch dashboards + X-Ray service maps giúp troubleshooting dễ dàng hơn Xây dựng cảnh báo chủ động thay vì chờ lỗi xảy ra Ứng Dụng Vào Công Việc Tự động hóa CI/CD bằng CodePipeline, CodeBuild, CodeDeploy Triển khai IaC với CloudFormation hoặc CDK cho môi trường nhất quán Containerize ứng dụng và chọn ECS, EKS hoặc App Runner tùy theo nhu cầu Tăng cường observability với CloudWatch metrics, logs, dashboards, alarms Dùng AWS X-Ray để trace và debug hệ thống phân tán Áp dụng DORA metrics để đo hiệu suất và cải tiến DevOps Trải Nghiệm Sự Kiện Tham dự “Cloud Mastery Series #2 – DevOps on AWS” mang lại cả góc nhìn chiến lược lẫn kiến thức thực tiễn để áp dụng DevOps hiệu quả trên môi trường cloud.\nHọc từ các diễn giả có chuyên môn cao Giải thích rõ ràng và chi tiết về CI/CD, container, IaC và monitoring Các ví dụ thực tế cho thấy DevOps vận hành trong hệ thống production như thế nào Thực hành kỹ thuật Quan sát CI/CD end-to-end từ commit → build → deploy Hiểu cách CloudFormation và CDK đảm bảo hạ tầng nhất quán Hiểu trade-offs giữa ECS, EKS và App Runner Tận dụng công cụ hiện đại IaC đảm bảo tính nhất quán và loại bỏ sai lệch cấu hình CloudWatch và X-Ray là nền tảng cho vận hành xuất sắc Networking và thảo luận Gặp gỡ các chuyên gia và cộng đồng Trao đổi sâu về văn hóa DevOps, tự động hóa và cải tiến liên tục Bài học rút ra Tự động hóa là yếu tố sống còn khi mở rộng hệ thống Observability là nền tảng cho độ tin cậy Chọn đúng nền tảng container giúp giảm gánh nặng vận hành Một số hình ảnh sự kiện Hình 1 Hình 2 Hình 3 Nhìn chung, workshop mang lại sự hiểu biết rõ ràng và thực tiễn về văn hóa DevOps, quy trình CI/CD, IaC, triển khai container và observability — tất cả đều là những thành phần quan trọng của phát triển ứng dụng cloud-native hiện đại.\n"},{"uri":"https://github.com/leduc121/fcj_report/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Xử lý tài liệu thông minh quy mô lớn với AI sinh tạo và Amazon Bedrock Data Automation Tác giả: Nikita Kozodoi, Aiham Taleb, Francesco Cerizzi, Liza (Elizaveta) Zinovyeva, Nuno Castro, Ozioma Uzoegwu, Eren Tuncer và Zainab Afolabi | vào ngày: 11 tháng 07 năm 2025 | trong: Amazon Bedrock, Amazon Bedrock Data Automation, Generative AI, Intermediate (200), Technical How-to | Permalink | Comments | Share\nTrích xuất thông tin từ các tài liệu phi cấu trúc quy mô lớn là một nhiệm vụ kinh doanh thường xuyên. Các trường hợp sử dụng phổ biến bao gồm tạo bảng tính năng sản phẩm từ mô tả, trích xuất metadata từ tài liệu, và phân tích hợp đồng pháp lý, đánh giá của khách hàng, bài báo tin tức và nhiều hơn nữa. Một phương pháp cổ điển để trích xuất thông tin từ văn bản là nhận dạng thực thể có tên (NER). NER xác định các thực thể từ các danh mục được xác định trước, chẳng hạn như con người và tổ chức. Mặc dù nhiều dịch vụ và giải pháp AI hỗ trợ NER, phương pháp này bị giới hạn ở các tài liệu văn bản và chỉ hỗ trợ một tập hợp thực thể cố định. Hơn nữa, các mô hình NER cổ điển không thể xử lý các loại dữ liệu khác như điểm số (chẳng hạn như sentiment) hoặc văn bản tự do (chẳng hạn như tóm tắt). AI sinh tạo mở khóa những khả năng này mà không cần chú thích dữ liệu tốn kém hoặc huấn luyện mô hình, cho phép xử lý tài liệu thông minh (IDP) toàn diện hơn.\nAWS gần đây đã công bố tính khả dụng chung của Amazon Bedrock Data Automation, một tính năng của Amazon Bedrock tự động hóa việc tạo ra những thông tin có giá trị từ nội dung đa phương thức phi cấu trúc như tài liệu, hình ảnh, video và âm thanh. Dịch vụ này cung cấp các khả năng được xây dựng sẵn cho IDP và trích xuất thông tin thông qua một API thống nhất, loại bỏ nhu cầu về kỹ thuật prompt phức tạp hoặc fine-tuning, và làm cho nó trở thành một lựa chọn tuyệt vời cho quy trình xử lý tài liệu quy mô lớn. Để tìm hiểu thêm về Amazon Bedrock Data Automation, tham khảo Đơn giản hóa AI sinh tạo đa phương thức với Amazon Bedrock Data Automation.\nAmazon Bedrock Data Automation là phương pháp được khuyến nghị cho trường hợp sử dụng IDP do tính đơn giản, độ chính xác hàng đầu trong ngành và khả năng dịch vụ được quản lý. Nó xử lý độ phức tạp của việc phân tích tài liệu, quản lý ngữ cảnh và lựa chọn mô hình tự động, vì vậy các nhà phát triển có thể tập trung vào logic kinh doanh của họ thay vì các chi tiết triển khai IDP.\nMặc dù Amazon Bedrock Data Automation đáp ứng hầu hết nhu cầu IDP, một số tổ chức yêu cầu tùy chỉnh bổ sung trong các pipeline IDP của họ. Ví dụ, các công ty có thể cần sử dụng các foundation models (FMs) tự lưu trữ cho IDP do yêu cầu quy định. Một số khách hàng có các nhóm builder có thể thích duy trì toàn quyền kiểm soát đối với pipeline IDP thay vì sử dụng dịch vụ được quản lý. Cuối cùng, các tổ chức có thể hoạt động tại các AWS Regions nơi Amazon Bedrock Data Automation không khả dụng (khả dụng tại us-west-2 và us-east-1 tính đến tháng 6 năm 2025). Trong những trường hợp như vậy, các builder có thể sử dụng trực tiếp Amazon Bedrock FMs hoặc thực hiện nhận dạng ký tự quang học (OCR) với Amazon Textract.\nBài viết này trình bày một ứng dụng IDP end-to-end được hỗ trợ bởi Amazon Bedrock Data Automation và các dịch vụ AWS khác. Nó cung cấp một infrastructure as code (IaC) AWS có thể tái sử dụng để triển khai một pipeline IDP và cung cấp một giao diện người dùng trực quan để chuyển đổi tài liệu thành các bảng có cấu trúc quy mô lớn. Ứng dụng chỉ yêu cầu người dùng cung cấp các tài liệu đầu vào (như hợp đồng hoặc email) và một danh sách các thuộc tính cần được trích xuất. Sau đó nó thực hiện IDP với AI sinh tạo.\nMã ứng dụng và hướng dẫn triển khai có sẵn trên GitHub theo giấy phép MIT.\nTổng quan giải pháp Giải pháp IDP được trình bày trong bài viết này được triển khai dưới dạng IaC sử dụng AWS Cloud Development Kit (AWS CDK). Amazon Bedrock Data Automation phục vụ như công cụ chính cho việc trích xuất thông tin. Đối với các trường hợp yêu cầu tùy chỉnh thêm, giải pháp cũng cung cấp các đường xử lý thay thế sử dụng Amazon Bedrock FMs và tích hợp Amazon Textract.\nChúng tôi sử dụng AWS Step Functions để orchestrate quy trình IDP và song song hóa xử lý cho nhiều tài liệu. Như một phần của quy trình, chúng tôi sử dụng các hàm AWS Lambda để gọi Amazon Bedrock Data Automation hoặc Amazon Textract và Amazon Bedrock (tùy thuộc vào chế độ phân tích đã chọn). Các tài liệu đã xử lý và các thuộc tính được trích xuất được lưu trữ trong Amazon Simple Storage Service (Amazon S3).\nMột quy trình Step Functions với logic kinh doanh được gọi thông qua một cuộc gọi API được thực hiện bằng cách sử dụng AWS SDK. Chúng tôi cũng xây dựng một ứng dụng web được đóng gói trong container chạy trên Amazon Elastic Container Service (Amazon ECS) có sẵn cho người dùng cuối thông qua Amazon CloudFront để đơn giản hóa tương tác của họ với giải pháp. Chúng tôi sử dụng Amazon Cognito cho xác thực và truy cập an toàn vào các API.\nSơ đồ sau minh họa kiến trúc và quy trình của giải pháp IDP.\nQuy trình IDP bao gồm các bước sau:\nNgười dùng đăng nhập vào ứng dụng web bằng thông tin xác thực được quản lý bởi Amazon Cognito, chọn các tài liệu đầu vào và xác định các trường cần được trích xuất từ chúng trong UI. Tùy chọn, người dùng có thể chỉ định chế độ phân tích, LLM để sử dụng và các cài đặt khác. Người dùng khởi động pipeline IDP. Ứng dụng tạo một pre-signed S3 URL cho các tài liệu và tải chúng lên Amazon S3. Ứng dụng kích hoạt Step Functions để khởi động state machine với các S3 URIs và cài đặt IDP làm đầu vào. Map state bắt đầu xử lý các tài liệu đồng thời. Tùy thuộc vào loại tài liệu và chế độ phân tích, nó phân nhánh đến các hàm Lambda khác nhau thực hiện IDP, lưu kết quả vào Amazon S3 và gửi chúng trở lại UI: Amazon Bedrock Data Automation – Các tài liệu được chuyển đến hàm Lambda \u0026ldquo;Run Data Automation\u0026rdquo;. Hàm Lambda tạo một blueprint với lược đồ các trường do người dùng xác định và khởi chạy một tác vụ Amazon Bedrock Data Automation không đồng bộ. Amazon Bedrock Data Automation xử lý độ phức tạp của việc xử lý tài liệu và trích xuất thuộc tính sử dụng các prompts và mô hình được tối ưu hóa. Khi kết quả tác vụ đã sẵn sàng, chúng được lưu vào Amazon S3 và gửi trở lại UI. Phương pháp này cung cấp sự cân bằng tốt nhất về độ chính xác, dễ sử dụng và khả năng mở rộng cho hầu hết các trường hợp sử dụng IDP. Amazon Textract – Nếu người dùng chỉ định Amazon Textract làm chế độ phân tích, pipeline IDP chia thành hai bước. Đầu tiên, hàm Lambda \u0026ldquo;Perform OCR\u0026rdquo; được gọi để chạy một tác vụ phân tích tài liệu không đồng bộ. Các đầu ra OCR được xử lý bằng cách sử dụng thư viện amazon-textract-textractor và được định dạng dưới dạng Markdown. Thứ hai, văn bản được chuyển đến hàm Lambda \u0026ldquo;Extract attributes\u0026rdquo; (Bước 6), hàm này gọi một Amazon Bedrock FM với văn bản và lược đồ thuộc tính. Các đầu ra được lưu vào Amazon S3 và gửi đến UI. Xử lý tài liệu văn phòng – Các tài liệu có hậu tố như .doc, .ppt và .xls được xử lý bởi hàm Lambda \u0026ldquo;Parse office\u0026rdquo;, hàm này sử dụng các document loaders của LangChain để trích xuất nội dung văn bản. Các đầu ra được chuyển đến hàm Lambda \u0026ldquo;Extract attributes\u0026rdquo; (Bước 6) để tiếp tục với pipeline IDP. Nếu người dùng chọn một Amazon Bedrock FM cho IDP, tài liệu được gửi đến hàm Lambda \u0026ldquo;Extract attributes\u0026rdquo;. Nó chuyển đổi một tài liệu thành một tập hợp các hình ảnh, được gửi đến một multimodal FM với lược đồ thuộc tính như một phần của prompt tùy chỉnh. Nó phân tích phản hồi LLM để trích xuất các đầu ra JSON, lưu chúng vào Amazon S3 và gửi nó trở lại UI. Luồng này hỗ trợ các tài liệu .pdf, .png và .jpg. Ứng dụng web kiểm tra kết quả thực thi state machine định kỳ và trả về các thuộc tính được trích xuất cho người dùng khi chúng có sẵn. Điều kiện tiên quyết Bạn có thể triển khai giải pháp IDP từ máy tính local của mình hoặc từ một notebook instance của Amazon SageMaker. Các bước triển khai được mô tả chi tiết trong tệp README của giải pháp.\nNếu bạn chọn triển khai bằng SageMaker notebook, điều này được khuyến nghị, bạn sẽ cần truy cập vào tài khoản AWS với quyền tạo và khởi chạy một notebook instance SageMaker.\nTriển khai giải pháp Để triển khai giải pháp vào tài khoản AWS của bạn, hoàn thành các bước sau:\nMở AWS Management Console và chọn Region mà bạn muốn triển khai giải pháp IDP.\nKhởi chạy một notebook instance SageMaker. Cung cấp tên notebook instance và kiểu notebook instance, bạn có thể đặt thành ml.m5.large. Để các tùy chọn khác là mặc định.\nĐiều hướng đến Notebook instance và mở IAM role được đính kèm với notebook. Mở role trên bảng điều khiển AWS Identity and Access Management (IAM).\nĐính kèm một inline policy vào role và chèn policy JSON sau:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;s3:*\u0026#34;, \u0026#34;iam:*\u0026#34;, \u0026#34;sts:AssumeRole\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ssm:GetParameter\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:ssm:*:*:parameter/cdk-bootstrap/*\u0026#34; } ] } Khi trạng thái notebook instance được đánh dấu là InService, chọn Open JupyterLab.\nTrong môi trường JupyterLab, chọn File, New, và Terminal.\nClone repository giải pháp bằng cách chạy các lệnh sau:\ncd SageMaker git clone [https://github.com/aws-samples/intelligent-document-processing-with-amazon-bedrock.git](https://github.com/aws-samples/intelligent-document-processing-with-amazon-bedrock.git) Điều hướng đến thư mục repository và chạy script để cài đặt requirements:\ncd intelligent-document-processing-with-amazon-bedrock sh install_deps.sh Chạy script để tạo một virtual environment và cài đặt dependencies:\nsh install_env.sh source .venv/bin/activate Trong thư mục repository, sao chép config-example.yml thành config.yml để chỉ định tên stack của bạn. Tùy chọn, cấu hình các dịch vụ và chỉ định các modules bạn muốn triển khai (ví dụ, để vô hiệu hóa việc triển khai UI, thay đổi deploy_streamlit thành False). Đảm bảo bạn thêm email người dùng của mình vào danh sách người dùng Amazon Cognito.\nCấu hình truy cập mô hình Amazon Bedrock bằng cách mở bảng điều khiển Amazon Bedrock trong Region được chỉ định trong tệp config.yml. Trong ngăn điều hướng, chọn Model Access và đảm bảo kích hoạt truy cập cho các model IDs được chỉ định trong config.yml.\nBootstrap và triển khai AWS CDK trong tài khoản của bạn:\ncdk bootstrap cdk deploy Lưu ý rằng bước này có thể mất một chút thời gian, đặc biệt là trong lần triển khai đầu tiên. Khi triển khai hoàn tất, bạn sẽ thấy thông báo như trong ảnh chụp màn hình sau. Bạn có thể truy cập Streamlit frontend bằng cách sử dụng URL phân phối CloudFront được cung cấp trong các đầu ra của AWS CloudFormation. Thông tin đăng nhập tạm thời sẽ được gửi đến email được chỉ định trong config.yml trong quá trình triển khai.\nSử dụng giải pháp Phần này hướng dẫn bạn qua hai ví dụ để giới thiệu các khả năng IDP.\nVí dụ 1: Phân tích tài liệu tài chính Trong kịch bản này, chúng tôi trích xuất các tính năng chính từ một báo cáo tài chính nhiều trang bằng cách sử dụng Amazon Bedrock Data Automation. Chúng tôi sử dụng một tài liệu mẫu ở định dạng PDF với sự kết hợp của bảng, hình ảnh và văn bản, và trích xuất một số chỉ số tài chính. Hoàn thành các bước sau:\nTải lên một tài liệu bằng cách đính kèm một tệp thông qua UI của giải pháp.\nTrên tab Describe Attributes, liệt kê thủ công tên và mô tả của các thuộc tính hoặc tải lên các trường này ở định dạng JSON. Chúng tôi muốn tìm các chỉ số sau:\nCurrent cash in assets in 2018 Current cash in assets in 2019 Operating profit in 2018 Operating profit in 2019 Chọn Extract attributes để khởi động pipeline IDP.\nCác thuộc tính được cung cấp được tích hợp vào một blueprint tùy chỉnh với danh sách thuộc tính được suy luận, sau đó được sử dụng để gọi một tác vụ data automation trên các tài liệu đã tải lên. Sau khi pipeline IDP hoàn tất, bạn sẽ thấy một bảng kết quả trong UI. Nó bao gồm một chỉ số cho mỗi tài liệu trong cột _doc, một cột cho mỗi thuộc tính bạn xác định và một cột file_name chứa tên tài liệu.\nTừ các đoạn trích báo cáo sau, chúng ta có thể thấy rằng Amazon Bedrock Data Automation đã có thể trích xuất chính xác các giá trị cho tài sản hiện tại và lợi nhuận hoạt động.\nGiải pháp IDP cũng có thể thực hiện các phép tính phức tạp vượt ra ngoài các thực thể được xác định rõ ràng. Giả sử chúng ta muốn tính toán các chỉ số kế toán sau:\nTỷ lệ thanh khoản (Tài sản hiện tại/Nợ phải trả hiện tại) Vốn lưu động (Tài sản hiện tại – Nợ phải trả hiện tại) Tăng doanh thu ((Doanh thu năm 2/Doanh thu năm 1) – 1) Chúng tôi xác định các thuộc tính và công thức của chúng như các phần của lược đồ thuộc tính. Lần này, chúng tôi chọn một Amazon Bedrock LLM làm chế độ phân tích để minh họa cách ứng dụng có thể sử dụng một multimodal FM cho IDP. Khi sử dụng một Amazon Bedrock LLM, việc khởi động pipeline IDP bây giờ sẽ kết hợp các thuộc tính và mô tả của chúng thành một template prompt tùy chỉnh, được gửi đến LLM với các tài liệu được chuyển đổi thành hình ảnh. Là người dùng, bạn có thể chỉ định LLM hỗ trợ việc trích xuất và các tham số suy luận của nó, chẳng hạn như temperature.\nĐầu ra, bao gồm các kết quả đầy đủ, được hiển thị trong ảnh chụp màn hình sau.\nVí dụ 2: Xử lý email khách hàng Trong kịch bản này, chúng tôi muốn trích xuất nhiều tính năng từ một danh sách email có khiếu nại của khách hàng do chậm trễ trong việc vận chuyển sản phẩm bằng cách sử dụng Amazon Bedrock Data Automation. Đối với mỗi email, chúng tôi muốn tìm những điều sau:\nTên khách hàng ID vận chuyển Ngôn ngữ email Sentiment email Chậm trễ vận chuyển (tính bằng ngày) Tóm tắt vấn đề Phản hồi đề xuất Hoàn thành các bước sau:\nTải lên các email đầu vào dưới dạng các tệp .txt. Bạn có thể tải xuống các email mẫu từ GitHub.\nTrên tab Describe Attributes, liệt kê tên và mô tả của các thuộc tính.\nBạn có thể thêm các ví dụ few-shot cho một số trường (chẳng hạn như delay) để giải thích cho LLM cách các giá trị của các trường này nên được trích xuất. Bạn có thể làm điều này bằng cách thêm một đầu vào ví dụ và đầu ra dự kiến cho thuộc tính vào mô tả.\nChọn Extract attributes để khởi động pipeline IDP.\nCác thuộc tính được cung cấp và mô tả của chúng sẽ được tích hợp vào một blueprint tùy chỉnh với danh sách thuộc tính được suy luận, sau đó được sử dụng để gọi một tác vụ data automation trên các tài liệu đã tải lên. Khi pipeline IDP hoàn tất, bạn sẽ thấy các kết quả.\nỨng dụng cho phép tải xuống các kết quả trích xuất dưới dạng tệp CSV hoặc tệp JSON. Điều này làm cho nó trở nên đơn giản để sử dụng các kết quả cho các tác vụ downstream, chẳng hạn như tổng hợp các điểm sentiment của khách hàng.\nChi phí Trong phần này, chúng tôi tính toán ước tính chi phí để thực hiện IDP trên AWS với giải pháp của chúng tôi.\nAmazon Bedrock Data Automation cung cấp một lược đồ định giá minh bạch tùy thuộc vào kích thước tài liệu đầu vào (số lượng trang, hình ảnh hoặc phút). Khi sử dụng Amazon Bedrock FMs, giá phụ thuộc vào số lượng input và output tokens được sử dụng như một phần của cuộc gọi trích xuất thông tin. Cuối cùng, khi sử dụng Amazon Textract, OCR được thực hiện và được định giá riêng dựa trên số lượng trang trong tài liệu.\nSử dụng các kịch bản trước đó làm ví dụ, chúng tôi có thể xấp xỉ chi phí tùy thuộc vào chế độ phân tích đã chọn. Trong bảng sau, chúng tôi hiển thị chi phí sử dụng hai bộ dữ liệu: 100 tài liệu tài chính 20 trang và 100 email khách hàng 1 trang. Chúng tôi bỏ qua chi phí của Amazon ECS và Lambda.\nAWS service Use case 1 (100 20-page financial documents) Use case 2 (100 1-page customer emails) IDP option 1: Amazon Bedrock Data Automation Amazon Bedrock Data Automation (custom output) $20.00 $1.00 IDP option 2: Amazon Bedrock FM Amazon Bedrock (FM invocation, Anthropic\u0026rsquo;s Claude 4 Sonnet) $1.79 $0.09 IDP option 3: Amazon Textract and Amazon Bedrock FM Amazon Textract (document analysis job with layout) $30.00 $1.50 Amazon Bedrock (FM invocation, Anthropic\u0026rsquo;s Claude 3.7 Sonnet) $1.25 $0.06 Orchestration and storage (shared costs) Amazon S3 $0.02 $0.02 AWS CloudFront $0.09 $0.09 Amazon ECS – – AWS Lambda – – Total cost: Amazon Bedrock Data Automation $20.11 $1.11 Total cost: Amazon Bedrock FM $1.90 $0.20 Total cost: Amazon Textract and Amazon Bedrock FM $31.36 $1.67 Phân tích chi phí cho thấy rằng sử dụng Amazon Bedrock FMs với template prompt tùy chỉnh là một phương pháp hiệu quả về chi phí cho IDP. Tuy nhiên, phương pháp này yêu cầu chi phí vận hành lớn hơn, bởi vì pipeline cần được tối ưu hóa tùy thuộc vào LLM và yêu cầu quản lý bảo mật và quyền riêng tư thủ công. Amazon Bedrock Data Automation cung cấp một dịch vụ được quản lý sử dụng lựa chọn các FMs có hiệu suất cao thông qua một API duy nhất.\nDọn dẹp Để xóa các tài nguyên đã triển khai, hoàn thành các bước sau:\nTrên bảng điều khiển AWS CloudFormation, xóa stack đã tạo. Ngoài ra, chạy lệnh sau: cdk destroy --region \u0026lt;YOUR_DEPLOY_REGION\u0026gt; Trên bảng điều khiển Amazon Cognito, xóa user pool. Kết luận Trích xuất thông tin từ các tài liệu phi cấu trúc quy mô lớn là một nhiệm vụ kinh doanh thường xuyên. Bài viết này thảo luận về một ứng dụng IDP end-to-end thực hiện trích xuất thông tin bằng cách sử dụng nhiều dịch vụ AWS. Giải pháp được hỗ trợ bởi Amazon Bedrock Data Automation, cung cấp một dịch vụ được quản lý đầy đủ để tạo ra thông tin chi tiết từ tài liệu, hình ảnh, âm thanh và video. Amazon Bedrock Data Automation xử lý độ phức tạp của việc xử lý tài liệu và trích xuất thông tin, tối ưu hóa cả hiệu suất và độ chính xác mà không yêu cầu chuyên môn về kỹ thuật prompt. Để có tính linh hoạt mở rộng và khả năng tùy chỉnh trong các kịch bản cụ thể, giải pháp của chúng tôi cũng hỗ trợ IDP bằng cách sử dụng các cuộc gọi LLM tùy chỉnh Amazon Bedrock và Amazon Textract cho OCR.\nGiải pháp hỗ trợ nhiều loại tài liệu, bao gồm văn bản, hình ảnh, PDF và tài liệu Microsoft Office. Tại thời điểm viết bài, việc hiểu chính xác thông tin trong các tài liệu có nhiều hình ảnh, bảng và các yếu tố trực quan khác chỉ có sẵn cho PDF và hình ảnh. Chúng tôi khuyến nghị chuyển đổi các tài liệu Office phức tạp sang PDF hoặc hình ảnh để có hiệu suất tốt nhất. Một giới hạn giải pháp khác là kích thước tài liệu. Tính đến tháng 6 năm 2025, Amazon Bedrock Data Automation hỗ trợ các tài liệu lên đến 20 trang để trích xuất thuộc tính tùy chỉnh. Khi sử dụng các LLM tùy chỉnh Amazon Bedrock cho IDP, cửa sổ ngữ cảnh 300.000 token của Amazon Nova LLMs cho phép xử lý các tài liệu có tối đa khoảng 225.000 từ. Để trích xuất thông tin từ các tài liệu lớn hơn, hiện tại bạn sẽ cần phải chia tệp thành nhiều tài liệu.\nTrong các phiên bản tiếp theo của giải pháp IDP, chúng tôi dự định tiếp tục thêm hỗ trợ cho các language models tiên tiến nhất có sẵn thông qua Amazon Bedrock và lặp lại về kỹ thuật prompt để cải thiện thêm độ chính xác trích xuất. Chúng tôi cũng dự định triển khai các kỹ thuật để mở rộng kích thước của các tài liệu được hỗ trợ và cung cấp cho người dùng một chỉ dẫn chính xác về vị trí chính xác trong tài liệu nơi thông tin được trích xuất đến từ đâu.\nĐể bắt đầu với IDP với giải pháp được mô tả, tham khảo kho lưu trữ GitHub. Để tìm hiểu thêm về Amazon Bedrock, tham khảo tài liệu.\nVề các tác giả Nikita Kozodoi, Tiến sĩ, là Nhà Khoa học Ứng dụng Cấp cao tại Trung tâm Đổi mới AI Tạo sinh của AWS, nơi ông làm việc ở tiên phong của nghiên cứu AI và kinh doanh. Với kinh nghiệm phong phú trong AI Tạo sinh và các lĩnh vực đa dạng của ML, Nikita đầy nhiệt huyết trong việc sử dụng AI để giải quyết các vấn đề kinh doanh thực tế đầy thách thức trên nhiều ngành công nghiệp.\nZainab Afolabi là Nhà Khoa học Dữ liệu Cấp cao tại Trung tâm Đổi mới AI Tạo sinh ở London, nơi cô tận dụng chuyên môn sâu rộng của mình để phát triển các giải pháp AI mang tính chuyển đổi trên nhiều ngành công nghiệp khác nhau. Cô có hơn tám năm kinh nghiệm chuyên môn trong trí tuệ nhân tạo và học máy, cùng với niềm đam mê chuyển đổi các khái niệm kỹ thuật phức tạp thành các ứng dụng kinh doanh thực tế.\nAiham Taleb, Tiến sĩ, là Nhà Khoa học Ứng dụng Cấp cao tại Trung tâm Đổi mới AI Tạo sinh, làm việc trực tiếp với các khách hàng doanh nghiệp của AWS để tận dụng Gen AI trên nhiều trường hợp sử dụng có tác động cao. Aiham có bằng Tiến sĩ về học biểu diễn không giám sát, và có kinh nghiệm trong ngành trải rộng trên nhiều ứng dụng học máy khác nhau, bao gồm thị giác máy tính, xử lý ngôn ngữ tự nhiên và hình ảnh y tế.\nLiza (Elizaveta) Zinovyeva là Nhà Khoa học Ứng dụng tại Trung tâm Đổi mới AI Tạo sinh của AWS và đang làm việc tại Berlin. Cô giúp đỡ khách hàng trên nhiều ngành công nghiệp khác nhau để tích hợp AI Tạo sinh vào các ứng dụng và quy trình làm việc hiện có của họ. Cô đam mê các chủ đề về AI/ML, tài chính và bảo mật phần mềm. Trong thời gian rảnh, cô thích dành thời gian với gia đình, thể thao, học các công nghệ mới và các cuộc thi đố vui.\nNuno Castro là Giám đốc Khoa học Ứng dụng Cấp cao tại Trung tâm Đổi mới AI Tạo sinh của AWS. Ông lãnh đạo các dự án hợp tác với khách hàng về AI Tạo sinh, giúp hàng trăm khách hàng AWS tìm ra trường hợp sử dụng có tác động lớn nhất từ ý tưởng, nguyên mẫu cho đến sản xuất. Ông có 19 năm kinh nghiệm trong AI tại các ngành như tài chính, sản xuất và du lịch, lãnh đạo các đội AI/ML trong 12 năm.\nOzioma Uzoegwu là Kiến trúc sư Giải pháp Chính tại Amazon Web Services. Trong vai trò của mình, ông giúp các khách hàng dịch vụ tài chính trên khắp EMEA chuyển đổi và hiện đại hóa trên AWS Cloud, cung cấp hướng dẫn kiến trúc và các thực tiễn tốt nhất trong ngành. Ozioma có nhiều năm kinh nghiệm với phát triển web, kiến trúc, đám mây và quản lý CNTT. Trước khi gia nhập AWS, Ozioma đã làm việc với một Đối tác Tư vấn Nâng cao của AWS với vai trò Kiến trúc sư Trưởng cho Bộ phận AWS. Ông đam mê sử dụng các công nghệ mới nhất để xây dựng một hệ thống CNTT dịch vụ tài chính hiện đại trên các lĩnh vực ngân hàng, thanh toán, bảo hiểm và thị trường vốn.\nEren Tuncer là Kiến trúc sư Giải pháp tại Amazon Web Services tập trung vào Serverless và xây dựng các ứng dụng AI Tạo sinh. Với hơn mười lăm năm kinh nghiệm trong phát triển và kiến trúc phần mềm, ông giúp khách hàng trên nhiều ngành công nghiệp khác nhau đạt được mục tiêu kinh doanh của họ bằng cách sử dụng các công nghệ đám mây với các thực tiễn tốt nhất. Là một người xây dựng, ông đam mê tạo ra các giải pháp với các công nghệ tiên tiến nhất, chia sẻ kiến thức và giúp các tổ chức điều hướng việc áp dụng đám mây.\nFrancesco Cerizzi là Kiến trúc sư Giải pháp tại Amazon Web Services khám phá các biên giới công nghệ đồng thời lan tỏa kiến thức về AI tạo sinh và xây dựng các ứng dụng. Với nền tảng là một nhà phát triển full stack, ông giúp khách hàng trên nhiều ngành công nghiệp khác nhau trong hành trình lên đám mây của họ, chia sẻ những hiểu biết sâu sắc về tiềm năng chuyển đổi của AI trên đường đi. Ông đam mê Serverless, kiến trúc hướng sự kiện và microservices nói chung. Khi không đắm mình trong công nghệ, ông là một fan hâm mộ cuồng nhiệt của F1 và yêu thích quần vợt.\n"},{"uri":"https://github.com/leduc121/fcj_report/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 -Tái Tưởng Tượng Chăm Sóc Sức Khỏe Tâm Thần: Công Nghệ Là Chất Xúc Tác Cho Sự Thay Đổi Bài blog khẳng định hệ thống chăm sóc sức khỏe tâm thần đang khủng hoảng vì thiếu hụt nghiêm trọng và bác sĩ kiệt sức vì giấy tờ. Công nghệ AWS (AI, cloud, generative AI) đang tạo bước ngoặt thực sự: giúp hàng triệu người tiếp cận dịch vụ nhanh hơn, giảm hàng giờ hành chính mỗi tuần cho bác sĩ, tự động ghi chú buổi trị liệu, phát hiện sớm nguy cơ, chuyển từ điều trị thụ động sang phòng ngừa chủ động, đồng thời vẫn giữ được sự kết nối con người – yếu tố cốt lõi của liệu pháp tâm lý.\nBlog 2 - CrazyGames nâng cấp nền tảng với hệ thống bạn bè thời gian thực sử dụng AWS AppSync Bài blog kể về việc CrazyGames (nền tảng game browser với hơn 35 triệu người chơi mỗi tháng) đã nâng cấp trải nghiệm xã hội bằng hệ thống bạn bè thời gian thực, xây dựng hoàn toàn trên AWS AppSync. Thời gian phát triển rút từ 8 tháng xuống chỉ còn 8 tuần. Người chơi giờ có thể kết bạn, thấy ngay bạn online/offline, đang chơi game gì và mời chơi cùng tức thì. Hệ thống dùng AppSync để xử lý real-time, kết hợp MemoryDB for Redis (dữ liệu tạm) và Aurora (dữ liệu lâu dài), chịu được hàng chục ngàn người dùng đồng thời mà gần như không cần quản lý hạ tầng.\nBlog 3 - Xử lý tài liệu thông minh quy mô lớn với AI sinh tạo và Amazon Bedrock Data Automation Bài blog giới thiệu một giải pháp Intelligent Document Processing (IDP) hoàn toàn mã nguồn mở, sẵn sàng đưa vào production, được cung cấp sức mạnh bởi Amazon Bedrock Data Automation – dịch vụ managed mới của AWS giúp trích xuất thông tin có cấu trúc từ tài liệu không cấu trúc, hình ảnh và nội dung đa phương thức ở quy mô lớn. Giải pháp cung cấp pipeline end-to-end trọn vẹn (giao diện web trực quan, điều phối bằng Step Functions, triển khai bằng CDK), người dùng chỉ cần upload tài liệu và khai báo các trường muốn lấy là nhận ngay bảng dữ liệu có cấu trúc với độ chính xác cao, gần như không cần viết prompt hay can thiệp gì thêm..\n"},{"uri":"https://github.com/leduc121/fcj_report/vi/5-workshop/5.3-ml-model/","title":"Mô Hình Học Máy","tags":[],"description":"","content":"HUẤN LUYỆN MÔ HÌNH Mục sau đây trình bày về quá trình phát triển mô hình dự đoán được thiết kế để dự đoán vị trí địa lý tiếp theo của một cơn bão, dựa trên dữ liệu quan sát từ quỹ đạo di chuyển trước đó. Nói cách đơn giản, nhóm sử dụng chuỗi các giá trị vĩ độ và kinh độ trong quá khứ để dự đoán vĩ độ và kinh độ tại bước thời gian kế tiếp.\nTrích Xuất Đặc Trưng Sau khi hoàn tất bước tiền xử lý dữ liệu, nhóm tiến hành chia bộ dữ liệu thành 70% để huấn luyện, 10% để kiểm định, và 20% để kiểm tra. Việc chia này được thực hiện theo mã định danh cơn bão (storm ID), đảm bảo không có cơn bão nào xuất hiện đồng thời trong cả tập huấn luyện và tập kiểm định/kiểm tra. Điều này giúp ngăn rò rỉ dữ liệu và đảm bảo độ tin cậy của quá trình đánh giá.\nTrong quá trình huấn luyện mô hình, mỗi mẫu đầu vào bao gồm chuỗi 4 bước thời gian liên tiếp, trong đó mỗi bước cách nhau 3 giờ. Như vậy, một chuỗi đầu vào tương ứng với quãng di chuyển 9 giờ của cơn bão.\nFigure 1 : Dataset Distribution Áp dụng Kỹ thuật Stepwise Temporal Fading Augmentation (STFA) Để tăng độ đa dạng của dữ liệu huấn luyện, nhóm áp dụng phương pháp tự đề xuất — Stepwise Temporal Fading Augmentation (STFA) — lên 50% tập huấn luyện, được lựa chọn dựa trên từng storm ID riêng biệt. Các chuỗi gốc của những cơn bão này sẽ được thay thế bằng chuỗi đã được tăng cường, đảm bảo kích thước tập huấn luyện cuối cùng vẫn giữ nguyên (xấp xỉ 100% kích thước ban đầu).\nNhư đã đề cập trong phần đề xuất mô hình, STFA thay đổi các điểm cũ hơn trong chuỗi, trong khi giữ các quan sát mới nhất không đổi. Với mỗi chuỗi 4 bước:\n2 bước mới nhất được giữ nguyên 2 bước cũ hơn được nhân với hệ số giảm dần: [0.98, 0.99] Mặc dù những giá trị này có vẻ nhỏ, nhưng vĩ độ và kinh độ cực kỳ nhạy cảm. Một thay đổi nhỏ — ví dụ từ 6.7 lên 6.8 — có thể tương ứng với hàng chục kilomet dịch chuyển ngoài thực tế. Do đó, mức điều chỉnh nhỏ như vậy là hợp lý và phù hợp với quy luật vật lý, giúp dữ liệu tăng cường vẫn mang tính chân thực.\nVí dụ STFA trên một chuỗi 4 bước thời gian Row Original (lat, lon) Augmented (lat, lon) Operation 1 [-6.8, 107.5] [-6.66, 105.35] nhân với 0.98 2 [-7.0, 107.1] [-6.93, 106.03] nhân với 0.99 3 [-7.3, 106.7] [-7.3, 106.7] giữ nguyên 4 [-7.5, 106.4] [-7.5, 106.4] giữ nguyên Quy trình trên làm giảm giá trị của các quan sát cũ, đồng thời giữ nguyên các bước mới. Việc tăng cường này giúp mô hình có thêm biến thiên có kiểm soát, cải thiện khả năng tổng quát hóa trong dự báo quỹ đạo.\nTrước đó, nhóm đã sử dụng machine learning dựa trên quy luật vật lý để tính khoảng cách và góc phương vị bằng công thức Haversine. Sau khi STFA được áp dụng, các giá trị này sẽ được tính lại dựa trên tọa độ đã tăng cường để đảm bảo các đặc trưng vật lý vẫn chính xác và nhất quán.\nFigure 2 : Comparison of Augmentation Techniques on Storm Trajectories Thiết lập Mô hình 1. Hàm Loss dựa trên quy luật vật lý Việc ứng dụng công thức Haversine không chỉ dừng lại ở bước trích xuất đặc trưng. Ngoài việc tạo ra các giá trị khoảng cách và hướng, nhóm còn tích hợp Công thức Haversine như một hàm loss tùy chỉnh, sử dụng cùng với các hàm loss truyền thống như MSE, RMSE và MAPE.\nCông thức Haversine đo khoảng cách địa lý thực giữa hai điểm, nên đây là metric tự nhiên để đánh giá sai số dự đoán vị trí bão. Khoảng cách Haversine càng lớn nghĩa là dự đoán càng sai; ngược lại, giá trị gần 0 km cho thấy mô hình hoạt động tốt.\nVí dụ:\nDự đoán: [-6.72, 107.1] Giá trị thật: [-6.8, 107.5] Haversine loss: 45.06 km Giá trị 45.06 km phản ánh chính xác sai số vị trí ngoài thực tế, giúp việc giải thích mô hình dễ dàng và ý nghĩa hơn.\n2. Kiến trúc mô hình Các bài toán mô hình hóa chuỗi thường được xử lý bằng RNN, LSTM hoặc GRU, nhưng các nghiên cứu gần đây cho thấy mô hình dựa trên tích chập (CNN) có thể vượt trội hơn trong nhiều tác vụ time-series.\nDo đó, nhóm sử dụng kiến trúc CNN — cụ thể là Temporal Convolutional Network (TCN).\nTCN sử dụng tích chập giãn (dilated convolution), giúp mô hình có receptive field rộng mà không cần dùng mạng hồi quy.\nTCN kết hợp được cả:\nkhả năng học phụ thuộc dài hạn tốc độ huấn luyện nhanh gradient ổn định Nên rất phù hợp cho bài toán dự báo quỹ đạo bão.\n3. Các siêu tham số mô hình Input: 4 đặc trưng (lat, lon, distance, bearing) Hidden units: 1024 Số lớp TCN: 2 Learning rate: 1e-4 Epochs: 80 Optimizer: Adam Early stopping: patience = 6 4. Hàm Loss tổng hợp Loss chính của mô hình được kết hợp từ:\nMSE của lat/lon MSE của distance/bearing Haversine loss (dựa trên vật lý) Trong đó:\nλ_aux = 0.5 λ_hav = 0.3 Cách thiết kế này giúp mô hình:\ngiảm sai số tọa độ tôn trọng quy luật dịch chuyển vật lý tránh overfit vào một loại đặc trưng cụ thể Figure 3 : Training Process Evaluation Đánh giá mô hình Sau khi mô hình hoàn tất quá trình huấn luyện và dừng sớm (early stopping), nhóm tiến hành đánh giá trên tập kiểm tra để xác định khả năng tổng quát hóa và mức độ sẵn sàng triển khai thực tế.\nKết quả đánh giá:\nTotal Loss: 74.3849 MSE: 0.0832 RMSE: 0.2772 MAPE: 0.60% Haversine: 30.75 km Sai số vị trí trung bình khoảng 30 km — mức hoàn toàn chấp nhận được đối với hệ thống có quy mô hàng trăm đến hàng nghìn kilomet như bão nhiệt đới. MSE nhỏ (0.08) cho thấy khả năng dự đoán tốt và ổn định.\nKết quả này cũng chứng minh rằng các mô hình convolution có thể hoạt động xuất sắc trong bài toán mô hình hóa chuỗi, không chỉ trong xử lý ảnh.\nSau khi xác thực mô hình, bước tiếp theo là tải mô hình lên Amazon S3 và sử dụng AWS Lambda để thực thi mô hình khi người dùng gửi yêu cầu dự đoán.\nFigure 4 : Evaluation Metrics "},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Học về Amazon S3 (Simple Storage Service) cơ bản Hiểu về CloudWatch monitoring và logging Nghiên cứu dịch vụ Route 53 DNS Học về ElastiCache cho giải pháp caching Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Học S3 cơ bản: + Buckets và objects + Storage classes + Versioning + Lifecycle policies - Thực hành: Tạo S3 buckets và upload objects 22/09/2024 22/09/2024 https://000057.awsstudygroup.com/ 2 - Tiếp tục học S3: + Kiểm soát truy cập và permissions + Bucket policies + Static website hosting - Thực hành: Cấu hình S3 bucket policies 23/09/2024 23/09/2024 https://000057.awsstudygroup.com/ 3 - Học CloudWatch: + Metrics và monitoring + CloudWatch Logs + Alarms và notifications - Thực hành: Thiết lập CloudWatch alarms 24/09/2024 24/09/2024 https://000008.awsstudygroup.com/ 4 - Học Route 53: + DNS cơ bản + Hosted zones + Routing policies - Thực hành: Tạo hosted zone và cấu hình DNS records 25/09/2024 25/09/2024 https://000010.awsstudygroup.com/ 5 - Học ElastiCache: + Redis và Memcached + Caching strategies + Use cases - Thực hành: Thiết lập ElastiCache cluster 26/09/2024 27/09/2024 https://000061.awsstudygroup.com/ Kết quả đạt được tuần 3: Kiến thức S3:\nNắm vững cách tạo S3 bucket và quản lý objects Hiểu các storage classes khác nhau và trường hợp sử dụng Học về versioning và lifecycle management Cấu hình bucket policies và access controls Host thành công static websites trên S3 Hiểu về giá cả S3 và chiến lược tối ưu chi phí CloudWatch Monitoring:\nHiểu về CloudWatch metrics và monitoring Học cách tạo và cấu hình CloudWatch alarms Hiểu CloudWatch Logs cho centralized logging Thiết lập notifications sử dụng SNS với CloudWatch Giám sát EC2 và các AWS resources hiệu quả Route 53 DNS:\nHiểu DNS cơ bản và cách Route 53 hoạt động Học về hosted zones và các loại records Nắm vững các routing policies khác nhau (simple, weighted, latency-based, failover) Cấu hình thành công DNS records cho applications Hiểu về health checks và DNS failover ElastiCache:\nHọc về khái niệm caching và lợi ích Hiểu sự khác biệt giữa Redis và Memcached Học các caching strategies (lazy loading, write-through) Thiết lập ElastiCache clusters Hiểu use cases để cải thiện hiệu suất ứng dụng "},{"uri":"https://github.com/leduc121/fcj_report/vi/4-eventparticipated/4.4-event4/","title":"AWS Cloud Mastery Series #1","tags":[],"description":"","content":"Bào thu hoạch: “BUILDING AGENTIC AI - Context Optimization with Amazon Bedrock” Mục tiêu Sự kiện Cung cấp phần giới thiệu rõ ràng về Agentic AI và sự chuyển dịch sang các hệ thống AI tự động Trình bày Amazon Bedrock AgentCore cùng hệ sinh thái agentic mở rộng của AWS Minh họa các ví dụ thực tế về thiết kế Agentic Workflow trên AWS Làm nổi bật cách tiếp cận orchestration của CloudThinker và các phương pháp tối ưu hóa ngữ cảnh Cung cấp trải nghiệm thực hành xây dựng ứng dụng dựa trên agent bằng AWS Bedrock Tạo cơ hội kết nối với các chuyên gia trong cộng đồng AI và điện toán đám mây Diễn giả Nguyễn Gia Hưng – Head of Solutions Architect, AWS Kiên Nguyễn – Solutions Architect, AWS Việt Phạm – Founder \u0026amp; CEO, Diaflow Thắng Tôn – Co-founder \u0026amp; COO, CloudThinker Henry Bùi – Head of Engineering, CloudThinker Kha Văn – Community Leader, AWS Những Điểm Nổi Bật Sự Phát Triển của Agentic AI ML Truyền thống / AI Cổ điển\nNhiệm vụ được định nghĩa hẹp, khả năng giới hạn Phụ thuộc mạnh vào dữ liệu có cấu trúc và xử lý tiền đề Khó mở rộng hoặc thích nghi với các trường hợp sử dụng mới Agentic AI Hiện Đại\nĐược vận hành bởi Foundation Models với khả năng suy luận đa bước Tự động phân rã nhiệm vụ và sử dụng công cụ Tích hợp API, thực thi workflow và truy cập tri thức Trở nên linh hoạt và sẵn sàng cho môi trường sản xuất khi kết hợp với AWS Thách Thức Khi Triển Khai Agentic AI Các vấn đề hiệu năng như độ trễ, suy luận song song, thông lượng Mở rộng cho multi-agent và xử lý ngữ cảnh phức tạp Yêu cầu bảo mật như kiểm soát dữ liệu, luồng định danh, phân quyền truy cập Nhu cầu governance như logging, khả năng truy vết, giới hạn workflow Danh Mục Agentic AI của AWS Amazon Bedrock AgentCore cho identity, memory, runtime, truy cập tools và workflows Agent Gateway cho tích hợp công cụ và API thống nhất Hỗ trợ nhiều mô hình như Anthropic, Meta Llama, Amazon Titan và nhiều hơn nữa Thiết kế hướng doanh nghiệp với guardrails, observability và khả năng mở rộng Amazon Bedrock AgentCore Runtime để điều phối các nhiệm vụ đa bước Memory cho ngữ cảnh ngắn hạn và dài hạn Identity Flow để quản lý quyền và bảo mật Agent Gateway để kết nối tới công cụ, API và hệ thống doanh nghiệp Code Interpreter cho môi trường thực thi mã an toàn Browser Tool để thu thập thông tin từ nguồn bên ngoài Các tính năng quan sát gồm logs, traces và metrics Xây Dựng Agentic Workflow trên AWS (Use Case từ Diaflow) Phối hợp giữa nhiều agent Truy xuất ngữ cảnh và function calling Tích hợp agent với hệ thống dữ liệu doanh nghiệp Thực thi logic kinh doanh bằng Bedrock và công cụ Diaflow Chiến lược thiết kế thực tế phù hợp với startup và SME Orchestration \u0026amp; Tối Ưu Ngữ Cảnh của CloudThinker Các mô hình điều phối cấp cao cho hệ thống agent Lọc ngữ cảnh để cải thiện hiệu suất mô hình Workflow thích ứng thay đổi dựa trên thông tin từ agent Kỹ thuật đánh giá và tăng độ tin cậy trong suy luận Tích hợp workflow CloudThinker với Amazon Bedrock AgentCore CloudThinker Hack: Phiên Thực Hành Thiết lập ban đầu Bedrock agents Xây dựng workflow agent đơn giản Thêm công cụ bên ngoài vào pipeline Khắc phục lỗi và tối ưu hành vi agent Triển khai bản proof-of-concept hoàn chỉnh Những Điểm Rút Ra Quan Trọng Tư Duy Agentic AI AI đang chuyển từ phản hồi thụ động sang hành động tự chủ Agent hiệu quả cần kết hợp memory, tools, identity và orchestration Foundation Models + điều phối workflow = thế hệ ứng dụng AI tiếp theo AWS hiện là một trong những môi trường sẵn sàng sản xuất mạnh mẽ nhất cho agentic AI Hiểu Biết Kỹ Thuật Vì sao tối ưu hóa ngữ cảnh quan trọng Cách công cụ và quản lý định danh ảnh hưởng đến độ tin cậy Cách AgentCore đơn giản hóa reasoning đa bước Vai trò của các mô hình orchestrator thực tế Phương pháp kết nối mô hình với API, tầng logic và nguồn dữ liệu Kỹ Năng Phát Triển Thực Tế Thiết kế workflow AI hoàn chỉnh từ đầu đến cuối Tích hợp công cụ bên ngoài vào pipeline agent Điều phối đa agent hiệu quả Quản lý độ trễ, khả năng mở rộng và bảo mật Triển khai agent với đầy đủ guardrails và hệ thống giám sát Ứng Dụng Vào Công Việc Người tham dự có thể áp dụng trực tiếp:\nXây dựng assistant, quy trình tự động hóa hoặc copilots nội bộ Kết nối mô hình Bedrock với nền tảng doanh nghiệp Phát triển workflow đa bước có cấu trúc với AgentCore Tạo prototype nhanh mà không cần hạ tầng DevOps phức tạp Ứng dụng phương pháp orchestration của CloudThinker để tăng hiệu suất Áp dụng mô hình thiết kế agentic cho cả startup và doanh nghiệp lớn Trải Nghiệm Sự Kiện Workshop “Agentic Build AI – Optimization with Amazon Bedrock” đã mang đến góc nhìn toàn diện về phát triển Agentic AI hiện đại.\nKiến Thức Từ Chuyên Gia Các diễn giả từ AWS, CloudThinker và Diaflow chia sẻ trải nghiệm triển khai thực tế Hướng dẫn rõ ràng về cách mở rộng và vận hành giải pháp GenAI Ví dụ cụ thể về tự động hóa quy trình doanh nghiệp bằng Agentic AI Trải Nghiệm Thực Hành Xây dựng workflow agent hoàn chỉnh trong workshop Hiểu rõ cách memory, identity và tool tương tác Trải nghiệm thực tế với API và các thành phần orchestration của Bedrock Cơ Hội Kết Nối Gặp gỡ kiến trúc sư AWS, kỹ sư, founder và các thành viên cộng đồng Tìm hiểu các hướng phát triển sự nghiệp và thảo luận về sản phẩm AI Trao đổi ý tưởng về hệ thống AI cloud-native Bài Học Rút Ra Agentic AI vượt xa chatbot và ứng dụng LLM truyền thống Triển khai thực tế yêu cầu identity, observability và khả năng mở rộng Bedrock và CloudThinker cung cấp lộ trình mạnh mẽ từ prototype đến sản xuất Dự án thực tế mang lại giá trị rõ ràng hơn so với các bài tập học thuật rời rạc Một số hình ảnh sự kiện Hình 1 Hình 2 Hình 3 Tóm lại, workshop đã mang đến sự kết hợp hài hòa giữa kiến thức chiến lược và kỹ năng thực hành. Người tham gia rời sự kiện với khả năng thiết kế workflow, tinh chỉnh ngữ cảnh, tích hợp công cụ và xây dựng hệ thống agentic mở rộng, an toàn trên AWS.\n"},{"uri":"https://github.com/leduc121/fcj_report/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong thời gian thực tập, tôi có cơ hội tham gia bốn sự kiện chuyên môn. Mỗi sự kiện đều mang lại những góc nhìn hữu ích, kiến thức thực tiễn và trải nghiệm giá trị, góp phần vào sự phát triển học thuật và nghề nghiệp của tôi.\nSự kiện 1 Tên sự kiện: Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders\nThời gian: 09:00, ngày 18 tháng 9 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, 02 đường Hải Triều, phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Người tham dự\nHoạt động chính: Tham gia các buổi thảo luận xoay quanh chuyển đổi công nghệ trong kỷ nguyên Công nghiệp 4.0, đặc biệt nhấn mạnh vai trò ngày càng mở rộng của trí tuệ nhân tạo trong thúc đẩy đổi mới số và nâng cao năng suất tổ chức.\nBài học rút ra: Việc tích hợp phương pháp AI-Driven Lifecycle (AI-DLC) vào quy trình dự án giúp nâng cao hiệu quả và khả năng ra quyết định. Bên cạnh đó, Generative AI là công cụ mạnh mẽ hỗ trợ nghiên cứu, tiếp thu kiến thức và phát triển kỹ năng liên tục.\nSự kiện 2 Tên sự kiện: AWS Cloud Mastery Series #1 – AI/ML/GenAI on AWS Workshop\nThời gian: 8:30, ngày 15 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, 02 đường Hải Triều, phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Người tham dự\nHoạt động chính: Khám phá các ứng dụng thực tiễn của trí tuệ nhân tạo và prompt engineering trong môi trường làm việc và đời sống. Đồng thời tiếp cận nhiều dịch vụ máy học của AWS như nhận diện hình ảnh, chuyển văn bản thành giọng nói, tìm kiếm ngữ nghĩa, và công cụ cá nhân hóa.\nBài học rút ra: AI và prompt engineering không chỉ đơn thuần là tự động hóa; chúng còn nâng cao năng suất, hỗ trợ ra quyết định chính xác hơn và tối ưu hóa các tác vụ lặp lại. Các dịch vụ ML của AWS cho thấy hệ thống thông minh có thể mang lại insight nhanh hơn, cải thiện trải nghiệm người dùng và tăng độ tin cậy thông qua quy trình có tính cấu trúc và khả năng mở rộng.\nSự kiện 3 Tên sự kiện: AWS Cloud Mastery Series #2 – DevOps on AWS\nThời gian: 8:30, ngày 17 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, 02 đường Hải Triều, phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Người tham dự\nHoạt động chính: Tìm hiểu các kiến thức nền tảng và nâng cao trong DevOps, bao gồm tự động hóa CI/CD, Infrastructure as Code (IaC) với CloudFormation và AWS CDK, triển khai container bằng ECS, EKS và App Runner, và các phương pháp quan sát hệ thống sử dụng CloudWatch.\nBài học rút ra: DevOps hiện đại đề cao sự hợp tác, cải tiến liên tục và khả năng điều phối hạ tầng đáng tin cậy. Việc áp dụng IaC và các dịch vụ container của AWS giúp xây dựng hệ thống có khả năng tái tạo, mở rộng và ổn định cao; trong khi các công cụ quan sát giúp chủ động giám sát và đạt hiệu quả vận hành tốt hơn.\nSự kiện 4 Tên sự kiện: CloudThinker – Xây dựng Agentic AI \u0026amp; Tối ưu hóa Ngữ cảnh với Amazon Bedrock\nThời gian: 9:00, ngày 05 tháng 12 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, 02 đường Hải Triều, phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Người tham dự\nHoạt động chính: Tham dự seminar kỹ thuật do CloudThinker và AWS tổ chức, tập trung vào kiến trúc, mô hình phát triển và chiến lược tối ưu hóa cho hệ thống Agentic AI xây dựng trên Amazon Bedrock.\nBài học rút ra: Phiên chia sẻ nhấn mạnh sự phát triển của DevSecOps, cho thấy rằng các phương pháp hiện đại vượt xa phạm vi tự động hóa pipeline CI/CD. Bảo mật cần được tích hợp xuyên suốt vòng đời phát triển phần mềm, và AI—đặc biệt là các hệ thống agentic—đóng vai trò quan trọng trong phát hiện lỗ hổng sớm, tự động hóa kiểm thử và phản ứng nhanh với sự cố.\n"},{"uri":"https://github.com/leduc121/fcj_report/vi/5-workshop/5.4-frontback-end/5.4.1-frontend-architecture/","title":"Kiến Trúc Frontend","tags":[],"description":"","content":"Kiến trúc Frontend – Ứng dụng Web Dự báo Bão Tổng quan Dưới đây là tài liệu chi tiết về quá trình phát triển front-end của nhóm: Một ứng dụng web xây dựng bằng React và TypeScript dùng để theo dõi và dự đoán quỹ đạo bão\nKiến trúc dịch vụ AWS ┌─────────────────────────────────────────────────────────────┐ │ TRÌNH DUYỆT NGƯỜI DÙNG │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ CloudFront CDN │ │ - Distribution: d3lj47ilp0fgxy.cloudfront.net │ │ - SSL/TLS: HTTPS │ │ - Cache: Tài nguyên tĩnh + dữ liệu JSON │ │ - Truy cập Origin: OAI/OAC (bảo mật) │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ S3 Bucket (Riêng tư) │ │ - Bucket: storm-frontend-hosting-duc-2025 │ │ - Static Website Hosting: TẮT │ │ - Quyền truy cập: Chỉ CloudFront được phép qua REST API │ │ - Nội dung: HTML, CSS, JS, hình ảnh, recent_storms.json │ └─────────────────────────────────────────────────────────────┘ ┌─────────────────────────────────────────────────────────────┐ │ Các hàm Lambda │ │ ┌─────────────────────────────────────────────────────┐ │ │ │ Lambda #1: Dự báo bão │ │ │ │ - URL: vill3povlzqxdyxm7ubldizobu0kdgbi... │ │ │ │ - Phương thức: POST /predict │ │ │ │ - Xác thực: KHÔNG (công khai) │ │ │ │ - Container: ECR (Docker) │ │ │ │ - Mô hình: LSTM + TCN │ │ │ └─────────────────────────────────────────────────────┘ │ │ ┌─────────────────────────────────────────────────────┐ │ │ │ Lambda #2: Thu thập dữ liệu bão (mới) │ │ │ │ - Kích hoạt: EventBridge (hàng tuần) │ │ │ │ - Chức năng: Thu thập dữ liệu IBTrACS │ │ │ │ - Đầu ra: recent_storms.json → S3 │ │ │ └─────────────────────────────────────────────────────┘ │ └─────────────────────────────────────────────────────────────┘ ┌─────────────────────────────────────────────────────────────┐ │ EventBridge │ │ - Rule: storm-data-crawler-weekly-trigger │ │ - Lịch chạy: Mỗi Chủ nhật 00:00 UTC (07:00 giờ Việt Nam) │ │ - Đích: Lambda #2 (Thu thập dữ liệu bão) │ └─────────────────────────────────────────────────────────────┘ Cấu trúc thư mục Frontend frontend/ ├── src/ │ ├── components/ # Các component React │ │ ├── ui/ # Component từ shadcn/ui (button, card, input, ...) │ │ ├── storm/ # Component chuyên cho nghiệp vụ bão │ │ ├── timeline/ # Điều khiển timeline │ │ ├── wind/ # Trực quan hóa gió │ │ ├── StormPredictionForm.tsx # Form nhập tọa độ bão │ │ ├── WeatherMap.tsx # Bản đồ Leaflet chính │ │ ├── StormTracker.tsx # Danh sách bão │ │ ├── StormInfo.tsx # Thông tin chi tiết bão │ │ ├── StormAnimation.tsx # Marker hoạt ảnh │ │ ├── WeatherOverlay.tsx # Lớp phủ Nhiệt độ/Gió │ │ ├── WeatherLayerControl.tsx # Lớp Satellite/Radar │ │ ├── WeatherLayerControlPanel.tsx # UI bảng điều khiển lớp dữ liệu │ │ ├── WeatherValueTooltip.tsx # Tooltip khi rê chuột │ │ ├── WindyLayer.tsx # Tích hợp Windy.com │ │ ├── ProvinceLayer.tsx # Lớp ranh giới tỉnh/thành Việt Nam │ │ ├── OptimizedTemperatureLayer.tsx │ │ ├── TemperatureHeatMapLayer.tsx │ │ ├── ThemeToggle.tsx # Chế độ Sáng/Tối │ │ ├── PreferencesModal.tsx # Tùy chọn người dùng │ │ ├── RightSidebar.tsx # Panel bên phải │ │ └── WeeklyForecast.tsx # Dự báo 7 ngày │ │ │ ├── pages/ │ │ ├── Index.tsx # Trang chính │ │ └── NotFound.tsx # Trang 404 │ │ │ ├── lib/ # Logic nghiệp vụ \u0026amp; tiện ích │ │ ├── api/ # Client gọi API │ │ ├── __tests__/ # Unit test │ │ ├── stormData.ts # Kiểu dữ liệu \u0026amp; interface │ │ ├── stormAnimations.ts # Logic hoạt ảnh │ │ ├── stormIntensityChanges.ts │ │ ├── stormPerformance.ts │ │ ├── stormValidation.ts │ │ ├── windData.ts │ │ ├── windStrengthCalculations.ts │ │ ├── windyStatePersistence.ts │ │ ├── windyUrlState.ts │ │ ├── mapUtils.ts # Tiện ích hỗ trợ bản đồ │ │ ├── openWeatherMapClient.ts │ │ ├── dataWorker.ts # Web Worker │ │ ├── utils.ts │ │ └── colorInterpolation.ts │ │ │ ├── hooks/ # Custom React hooks │ │ ├── use-toast.ts │ │ ├── use-theme.tsx │ │ ├── use-mobile.tsx │ │ ├── useTimelineState.ts │ │ ├── useWindyStateSync.ts │ │ └── useSimplifiedTooltip.ts │ │ │ ├── contexts/ # React Context │ │ └── WindyStateContext.tsx │ │ │ ├── api/ │ │ └── weatherApi.ts # Các hàm gọi API │ │ │ ├── utils/ │ │ └── colorInterpolation.ts │ │ │ ├── styles/ │ │ └── accessibility.css # Style tuân thủ WCAG │ │ │ ├── test/ # Bộ test │ │ ├── accessibility.test.ts │ │ ├── accessibility-audit.test.ts │ │ ├── wcag-compliance.test.ts │ │ ├── performance.test.ts │ │ ├── cross-browser.test.ts │ │ └── setup.ts │ │ │ ├── assets/ # Ảnh, icon │ ├── App.tsx │ ├── main.tsx │ └── index.css │ ├── public/ # Tài nguyên tĩnh ├── dist/ # Output sau khi build (npm run build) ├── .env.production # Cấu hình môi trường production ├── .env.example ├── package.json ├── vite.config.ts ├── vitest.config.ts # Cấu hình test ├── tailwind.config.ts ├── tsconfig.json └── components.json # Cấu hình shadcn/ui Biến môi trường .env.production # OpenWeather API VITE_OPENWEATHER_API_KEY=8ff7f009d2bd420c86845c6bcf6de4a9 # CloudFront URL - Dùng để lấy dữ liệu bão VITE_CLOUDFRONT_URL=https://d3lj47ilp0fgxy.cloudfront.net # Lambda Function URL - API dự đoán bão VITE_PREDICTION_API_URL=https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws Quy trình Build \u0026amp; Deploy 1. Build bản Production cd frontend npm run build Đầu ra: thư mục dist/ bao gồm:\nindex.html assets/index-[hash].js assets/index-[hash].css 2. Upload lên S3 aws s3 sync dist/ s3://storm-frontend-hosting-duc-2025/ --delete Important Notes:\nS3 bucket ở chế độ riêng tư (không public) CloudFront dùng REST API endpoint, không dùng website endpoint Origin: storm-frontend-hosting-duc-2025.s3.ap-southeast-1.amazonaws.com 3. Invalidate cache của CloudFront aws cloudfront create-invalidation \\ --distribution-id E1234567890ABC \\ --paths \u0026#34;/*\u0026#34; Luồng dữ liệu A. Tải dữ liệu bão (khi khởi động ứng dụng) Trình duyệt → CloudFront → S3 ↓ GET /recent_storms.json ↓ Parse JSON → Hiển thị lên bản đồ File: src/pages/Index.tsx (dòng ~40)\nconst CLOUDFRONT_URL = import.meta.env.VITE_CLOUDFRONT_URL; const FETCH_URL = `${CLOUDFRONT_URL}/recent_storms.json?t=${Date.now()}`; B. Dự báo bão (khi người dùng thao tác) Người dùng điền form → Nhấn \u0026#34;Run Prediction\u0026#34; ↓ POST /predict tới Lambda Function URL ↓ { \u0026#34;history\u0026#34;: [{lat, lng}, ...], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } ↓ Lambda xử lý → Trả về dự báo ↓ Hiển thị đường đi dự đoán lên bản đồ File: src/components/StormPredictionForm.tsx (dòng ~80)\nconst API_URL = `${import.meta.env.VITE_PREDICTION_API_URL}/predict`; const response = await fetch(API_URL, { method: \u0026#34;POST\u0026#34;, headers: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; }, body: JSON.stringify({ history, storm_name }) }); Các thành phần chính 1. Thành phần cốt lõi StormPredictionForm File: src/components/StormPredictionForm.tsx\nTính năng:\nForm nhập tọa độ bão (tối thiểu 9 điểm) Kiểm tra dữ liệu đầu vào (lat/lng hợp lệ) Gọi Lambda API để dự báo Hiển thị kết quả lên bản đồ Danh sách vị trí có thể cuộn, hỗ trợ thêm/xóa điểm thuộc tính truyền:\ninterface StormPredictionFormProps { onPredictionResult: (result: PredictionResult) =\u0026gt; void; setIsLoading: (isLoading: boolean) =\u0026gt; void; } WeatherMap File: src/components/WeatherMap.tsx\nTính năng:\nHiển thị bản đồ Leaflet Vẽ quỹ đạo bão (lịch sử + dự báo) Vẽ đường dự đoán (màu tím, nét đứt) Lớp phủ thời tiết (nhiệt độ, gió, radar) Hiển thị nhiều cơn bão cùng lúc Tự động zoom tới cơn bão đang được chọn Dùng các pane tùy chỉnh để quản lý thứ tự lớp (z-index) Props:\ninterface WeatherMapProps { storms: Storm[]; selectedStorm?: Storm; customPrediction?: PredictionResult | null; mapFocusBounds?: LatLngBounds | null; onMapFocusComplete?: () =\u0026gt; void; } Mục cần chụp màn hình:\nWeb UI → Bản đồ có quỹ đạo bão (xanh/đỏ) Web UI → Đường dự đoán tùy chỉnh (màu tím, nét đứt) Web UI → Lớp phủ thời tiết (nhiệt độ/gió) Index (Trang chính) File: src/pages/Index.tsx\nTính năng:\nBố cục chính với header/footer Quản lý state (storms, selectedStorm, customPrediction) Sidebar có tab (Current Storms / Predict Storm) Đồng bộ trạng thái timeline Xử lý loading và lỗi Skip link hỗ trợ truy cập (accessibility) 2. Các component về bão StormTracker File: src/components/StormTracker.tsx\nDanh sách các cơn bão hiện tại Lọc theo trạng thái (active/developing/dissipated) Bấm để chọn cơn bão StormInfo File: src/components/StormInfo.tsx\nThông tin chi tiết về bão Tốc độ gió, áp suất, phân loại Dữ liệu lịch sử Timeline dự báo StormAnimation File: src/components/StormAnimation.tsx\nMarker động cho các vị trí của bão Hiệu ứng nhấp nháy/pulsing Màu sắc theo cấp độ bão 3. Các component lớp thời tiết WeatherOverlay File: src/components/WeatherOverlay.tsx\nLớp phủ heatmap nhiệt độ Trực quan hóa tốc độ gió Dữ liệu thời gian thực từ OpenWeather API Rê chuột để xem giá trị WeatherLayerControl File: src/components/WeatherLayerControl.tsx\nLớp ảnh vệ tinh (satellite) Lớp radar Lớp nhiệt độ Quản lý các tile layer WeatherLayerControlPanel File: src/components/WeatherLayerControlPanel.tsx\nĐiều khiển UI cho các lớp thời tiết Thanh chỉnh độ trong suốt (opacity) Nút bật/tắt layer Bật/tắt animation cho nhiệt độ OptimizedTemperatureLayer \u0026amp; TemperatureHeatMapLayer Files: src/components/OptimizedTemperatureLayer.tsx, TemperatureHeatMapLayer.tsx\nRender nhiệt độ tối ưu hiệu năng Nội suy màu (color interpolation) Heatmap dạng lưới (grid-based) 4. Các component về gió WindyLayer File: src/components/WindyLayer.tsx\nTích hợp Windy.com bằng iframe Lớp phủ animation gió Đồng bộ trạng thái với bản đồ chính Context: src/contexts/WindyStateContext.tsx\nState toàn cục cho lớp Windy Lưu trạng thái vào URL Đồng bộ giữa các component 5. Component nâng cấp bản đồ ProvinceLayer File: src/components/ProvinceLayer.tsx\nRanh giới tỉnh/thành Việt Nam Render GeoJSON Nhãn tên tỉnh/thành WeatherValueTooltip File: src/components/WeatherValueTooltip.tsx\nTooltip hiển thị giá trị thời tiết khi rê chuột Nhiệt độ, tốc độ gió, áp suất Tooltip định vị theo vị trí con trỏ 6. Các component UI ThemeToggle File: src/components/ThemeToggle.tsx\nChuyển chế độ Sáng/Tối Lưu lại tùy chọn người dùng Tự nhận theme theo hệ thống PreferencesModal File: src/components/PreferencesModal.tsx\nThiết lập tùy chọn người dùng Tùy chọn bản đồ Tùy chọn hiển thị RightSidebar File: src/components/RightSidebar.tsx\nPanel thông tin bổ sung Sidebar có thể thu gọn WeeklyForecast File: src/components/WeeklyForecast.tsx\nDự báo thời tiết 7 ngày Xu hướng nhiệt độ Icon thời tiết 7. Các component timeline Thư mục: src/components/timeline/\nĐiều khiển timeline cho hoạt ảnh bão Chức năng Play/Pause Kéo để tua thời gian (scrubbing) Điều chỉnh tốc độ Kiểu dữ liệu PredictionResult File: src/lib/stormData.ts\nexport interface PredictionResult { storm_id: string; storm_name: string; prediction_time: string; totalDistance: number; // km actualDistance: number; // km lifespan: number; // giờ forecastHours: number; // giờ forecast: StormPoint[]; // Các điểm vị trí dự đoán path?: StormPoint[]; // Hỗ trợ tương thích (legacy) } StormPoint export interface StormPoint { timestamp: number; // Unix timestamp (ms) lat: number; lng: number; windSpeed: number; // km/h pressure: number; // hPa category: string; // \u0026#34;Typhoon\u0026#34;, \u0026#34;Super Typhoon\u0026#34;, ... } `md\nQuyền IAM/AWS cần thiết S3 Bucket Policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::storm-frontend-hosting-duc-2025/*\u0026#34; } ] } CloudFront Origin Access Origin: S3 bucket Origin Access: Public (hoặc OAI nếu dùng) Kiểm thử Local Development npm run dev # Mở http://localhost:5173 Kiểm thử bản build production npm run build npm run preview # Mở http://localhost:4173 Các lỗi thường gặp 1. Lỗi CORS khi gọi Lambda Đặc điểm: lỗi Access-Control-Allow-Origin\nCách xử lý: Lambda cần trả về header CORS:\nreturn { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps(result) } 2. CloudFront bị cache cũ Đặc điểm: Code mới không hiển thị\nCách xử lý: Invalidate cache\naws cloudfront create-invalidation --distribution-id E... --paths \u0026#34;/*\u0026#34; 3. Biến môi trường không được load Triệu chứng: undefined khi truy cập import.meta.env.VITE_*\nCách xử lý:\nĐảm bảo có file .env.production Build lại: npm run build Biến phải bắt đầu bằng VITE_ Checklist triển khai Cập nhật .env.production với đúng URL npm run build chạy thành công Upload dist/ lên S3 Invalidate CloudFront cache Test trên URL production Kiểm tra Lambda API hoạt động Kiểm tra dữ liệu bão tải được Test form dự đoán với 9+ điểm tọa độ API Endpoints 1. Lấy dữ liệu bão GET https://d3lj47ilp0fgxy.cloudfront.net/recent_storms.json Phản hồi: mảng các object Storm\n2. Dự đoán đường đi bão POST https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws/predict Body: { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, ... ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } Response: { \u0026#34;storm_id\u0026#34;: \u0026#34;unknown\u0026#34;, \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34;, \u0026#34;totalDistance\u0026#34;: 500.5, \u0026#34;lifespan\u0026#34;: 72, \u0026#34;forecast\u0026#34;: [...] } Tối ưu hiệu năng 1. Tối ưu mã nguồn Code Splitting: Vite tự động tách chunk theo routes Tree Shaking: Loại bỏ code không dùng Minification: Build production tự nén JS/CSS Lazy Loading: Component được tải khi cần 2. Tối ưu dữ liệu Web Workers: Tính toán nặng chạy trong worker (dataWorker.ts) Memoization: Dùng React.memo cho component tốn tài nguyên Debouncing: Debounce cho handler input Caching: Lưu cache tùy chọn bằng LocalStorage 3. Tối ưu render Virtual Scrolling: Danh sách lớn dùng virtual scrolling Optimized Layers: OptimizedTemperatureLayer tối ưu hiệu năng Canvas Rendering: Heatmap render bằng canvas thay vì DOM Pane Management: Tạo Leaflet pane riêng để tối ưu z-index 4. Tối ưu mạng CDN Caching: CloudFront cache tài nguyên tĩnh Image Optimization: WebP, lazy loading API Caching: Cache dữ liệu bão kèm timestamp Compression: Nén Gzip/Brotli 5. Tối ưu cho khả năng truy cập (Accessibility) Skip Links: Phím tắt điều hướng bằng bàn phím ARIA Labels: Dùng nhãn ARIA và HTML ngữ nghĩa đúng Focus Management: Quản lý focus, đảm bảo thứ tự tab hợp lý Screen Reader: Tối ưu để hoạt động tốt với trình đọc màn hình Thư viện \u0026amp; tiện ích Business Logic (lib/) Quản lý bão stormData.ts: Kiểu dữ liệu, interface, định nghĩa Storm/StormPoint stormAnimations.ts: Logic animation cho marker bão stormIntensityChanges.ts: Tính toán thay đổi cường độ bão stormPerformance.ts: Tối ưu hiệu năng render stormValidation.ts: Kiểm tra/validate dữ liệu bão Hệ thống gió windData.ts: Cấu trúc dữ liệu gió windStrengthCalculations.ts: Tính toán cường độ gió windyStatePersistence.ts: Lưu trạng thái lớp Windy windyUrlState.ts: Quản lý trạng thái theo URL cho Windy Bản đồ \u0026amp; thời tiết mapUtils.ts: Tiện ích bản đồ (center, zoom, tính bounds) openWeatherMapClient.ts: Client gọi OpenWeather API colorInterpolation.ts: Tính toán gradient/nội suy màu Hiệu năng dataWorker.ts: Web Worker cho tác vụ tính toán nặng utils.ts: Tiện ích dùng chung Custom Hooks (hooks/) use-toast.ts: Hệ thống thông báo toast use-theme.tsx: Quản lý theme sáng/tối use-mobile.tsx: Nhận diện thiết bị mobile useTimelineState.ts: Đồng bộ trạng thái timeline useWindyStateSync.ts: Đồng bộ trạng thái lớp Windy useSimplifiedTooltip.ts: Logic tooltip rút gọn Context (contexts/) WindyStateContext.tsx: State toàn cục cho tích hợp lớp Windy Testing (test/) accessibility.test.ts: Kiểm thử accessibility accessibility-audit.test.ts: Audit theo WCAG wcag-compliance.test.ts: Kiểm thử tuân thủ WCAG 2.1 performance.test.ts: Benchmark hiệu năng cross-browser.test.ts: Kiểm thử tương thích đa trình duyệt setup.ts: Thiết lập môi trường test Dependencies Core React 18 TypeScript Vite (công cụ build) Vitest (framework test) UI Framework Tailwind CSS shadcn/ui (thư viện component) Lucide Icons Radix UI (primitives) Map \u0026amp; Visualization Leaflet React-Leaflet Hỗ trợ GeoJSON API \u0026amp; Data Fetch API (native) OpenWeather API AWS Lambda Function URL Quản lý state React Context API State theo URL (query params) Lưu trạng thái bằng LocalStorage Hiệu năng Web Workers Code splitting (Vite) Lazy loading Ảnh chụp tài liệu CloudFront Phân phối (Distribution) Hình 1 Cài đặt Origin (Origin Settings) Hình 1 Invalidations Hình 2 storm-frontend-hosting-duc-2025 Hình 3 Phân quyền (Permissions) Hình 4 storm-ai-models-2025 Hình 5 storm-data-store-2025 Hình 6 Trang chính (Main Page) Hình 7 Tính năng theo dõi bão (Storm Tracking Features) Hình 8 Chi tiết cơn bão (Storm Details) Hình 9 Tính năng dự đoán (Predict Feature) Hình 10 Hình 11 Hình 12 "},{"uri":"https://github.com/leduc121/fcj_report/vi/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/","title":"Kiến trúc Lambda","tags":[],"description":"","content":"Kiến trúc Lambda - Dịch vụ AI Dự báo Bão Tổng quan Hàm Lambda là một thành phần quan trọng trong kiến trúc serverless. Chúng đặc biệt hữu ích nhờ chi phí vận hành thấp và khả năng triển khai dễ dàng—những yếu tố rất phù hợp với nền tảng dự đoán bão của nhóm.\nPhần này trình bày chi tiết cách chúng tôi thiết kế và xây dựng kiến trúc Lambda.\nCác hàm Lambda của chúng em chạy mô hình PyTorch để dự đoán quỹ đạo bão và được triển khai thông qua Docker container image.\nKiến trúc các dịch vụ AWS ┌─────────────────────────────────────────────────────────────┐ │ Frontend (Trình duyệt) │ └────────────────────────┬────────────────────────────────────┘ │ POST /predict ▼ ┌─────────────────────────────────────────────────────────────┐ │ Lambda Function URL (Công khai) │ │ URL: https://vill3povlzqxdyxm7ubldizobu0kdgbi... │ │ Auth: NONE (không xác thực) │ │ Method: POST │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ Lambda Function │ │ Tên: storm-prediction │ │ Runtime: Python 3.10 (Container) │ │ Bộ nhớ: 3008 MB │ │ Timeout: 120 giây │ │ Kiến trúc: x86_64 │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ ECR Repository │ │ Account: 339570693867 │ │ Region: ap-southeast-1 │ │ Repo: storm-prediction │ │ Image: latest │ │ Size: ~2 GB │ └────────────────────────┬────────────────────────────────────┘ ┌─────────────────────────────────────────────────────────────┐ │ S3 Buckets │ │ 1. storm-frontend-hosting-duc-2025 │ │ - models/lstm_totald_256_4.pt (tùy chọn) │ │ - predictions/[storm_id]_[timestamp].json │ │ │ │ 2. storm-ai-models (khuyến nghị) │ │ - models/lstm_totald_256_4.pt │ │ - models/tcn_model.pth (backup) │ └─────────────────────────────────────────────────────────────┘ Cấu trúc thư mục storm_prediction/ storm_prediction/ ├── app.py # Lambda handler (mã chính) ├── Dockerfile # Định nghĩa container ├── requirements.txt # Thư viện Python phụ thuộc ├── cropping_storm_7304_2l.pth # Mô hình TCN (đóng kèm trong image) │ ├── DEPLOY_NOW.md # Hướng dẫn deploy nhanh ├── DEPLOY_CONSOLE_STEP_BY_STEP.md # Hướng dẫn AWS Console từng bước ├── LAMBDA_DEPLOYMENT_GUIDE.md # Hướng dẫn triển khai chi tiết ├── AWS_CONSOLE_DEPLOYMENT_GUIDE.md ├── FIX_ECR_PUSH_ERROR.md # Tài liệu xử lý lỗi ECR ├── FIX_UNICODE_ERROR.md # Sửa lỗi UnicodeDecodeError ├── FIX_UNICODE_ERROR_SOLUTION.md # Chi tiết giải pháp └── REBUILD_AND_DEPLOY.sh # Script tự động build \u0026amp; deploy Cấu trúc Docker Image Dockerfile FROM public.ecr.aws/lambda/python:3.10 # Cài đặt dependencies COPY requirements.txt . RUN pip3 install -r requirements.txt \\ --target \u0026#34;${LAMBDA_TASK_ROOT}\u0026#34; \\ --extra-index-url https://download.pytorch.org/whl/cpu # Copy Lambda handler COPY app.py ${LAMBDA_TASK_ROOT} # Copy mô hình TCN vào thư mục con (tránh nhầm file .pth) RUN mkdir -p ${LAMBDA_TASK_ROOT}/models COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/models/ # Đặt handler CMD [ \u0026#34;app.handler\u0026#34; ] Các lớp (Image Layers) Layer 1: AWS Lambda Python 3.10 base (~500 MB) Layer 2: PyTorch CPU + dependencies (~1.2 GB) Layer 3: app.py + mô hình TCN (~300 MB) ───────────────────────────────────────────── Tổng dung lượng: ~2 GB Các mô hình AI 1. Mô hình TCN (Dự đoán quỹ đạo) File: cropping_storm_7304_2l.pth\nVị trí: Bên trong Docker image tại /var/task/models/\nDung lượng: ~300 MB\nMục đích: Dự đoán bước tiếp theo (lat, lng) của quỹ đạo bão\nKiến trúc:\nclass StormTCN(nn.Module): def __init__(self, input_dim=4, hidden_units=1024, num_layers=2): self.tcn = TCN(...) self.head_latlon = nn.Linear(hidden_units, 2) # Dự đoán lat, lng self.head_aux = nn.Linear(hidden_units, 2) # Dự đoán đặc trưng phụ Input: [batch, sequence, 4] - (lat, lng, distance, bearing)\nOutput:\npred_latlon: (lat, lng) kế tiếp pred_aux: đặc trưng phụ 2. Mô hình LSTM (Dự đoán tổng quãng đường) File: lstm_totald_256_4.pt\nVị trí: S3 bucket (tải về ở lần chạy đầu tiên)\nDung lượng: ~50 MB\nMục đích: Dự đoán tổng quãng đường bão sẽ di chuyển\nKiến trúc:\nclass StormLSTM(nn.Module): def __init__(self, input_size=4, hidden_size=256, num_layers=2): self.lstm = nn.LSTM(...) self.fc = nn.Sequential( nn.Linear(hidden_size, hidden_size // 2), nn.ReLU(), nn.Linear(hidden_size // 2, 1) # Dự đoán tổng quãng đường ) Input: Tổng hợp theo ngày [batch, days, 4] - (day, daily_dist, avg_speed, motion_type)\nOutput: Tổng quãng đường (km)\nLuồng xử lý request 1. Nhận request POST /predict Content-Type: application/json { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, ... // Tối thiểu 9 điểm ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34;, \u0026#34;storm_id\u0026#34;: \u0026#34;TEST001\u0026#34; // Tùy chọn } 2. Tải mô hình (chỉ lần gọi đầu tiên) def load_models(): global LSTM_MODEL, TCN_MODEL # Tải LSTM từ S3 (nếu có) if not os.path.exists(\u0026#39;/tmp/lstm_model.pt\u0026#39;): s3_client.download_file( MODEL_BUCKET, \u0026#39;models/lstm_totald_256_4.pt\u0026#39;, \u0026#39;/tmp/lstm_model.pt\u0026#39; ) LSTM_MODEL = StormLSTM(...) LSTM_MODEL.load_state_dict(torch.load(\u0026#39;/tmp/lstm_model.pt\u0026#39;)) # Tải TCN từ local (đã có sẵn trong image) TCN_MODEL = StormTCN(...) TCN_MODEL.load_state_dict( torch.load(\u0026#39;/var/task/models/cropping_storm_7304_2l.pth\u0026#39;) ) 4. Dự đoán tổng quãng đường (LSTM) def predict_total_distance(record_tensor): if LSTM_MODEL is None: # Dự phòng (fallback): avg_distance * 24 bước return fallback_distance # Gom theo ngày (9 điểm/ngày) # Chạy dự đoán bằng LSTM with torch.no_grad(): pred = LSTM_MODEL(summary_tensor, lengths) return pred.item() # km 5. Dự đoán đường đi (TCN) def predict_storm_path(record_tensor, total_distance, history): seq = record_tensor.clone() gone_distance = 0 predicted_points = [] while gone_distance \u0026lt; total_distance: # Dự đoán vị trí tiếp theo pred_latlon, pred_aux = TCN_MODEL(seq) new_lat = pred_latlon[0, -1, 0].item() new_lng = pred_latlon[0, -1, 1].item() # Tính khoảng cách \u0026amp; hướng di chuyển step_distance = haversine(last_lat, last_lng, new_lat, new_lng) # Ước lượng tốc độ gió (giảm dần theo thời gian) estimated_wind = max(avg_wind * (0.98 ** step), 30) predicted_points.append({ \u0026#39;lat\u0026#39;: new_lat, \u0026#39;lng\u0026#39;: new_lng, \u0026#39;timestamp\u0026#39;: base_timestamp + (step * 3 * 3600 * 1000), \u0026#39;windSpeed\u0026#39;: estimated_wind, \u0026#39;pressure\u0026#39;: 980.0, \u0026#39;category\u0026#39;: calculate_category(estimated_wind) }) # Cập nhật chuỗi (sliding window) seq = torch.cat([seq[:, 1:, :], next_point.unsqueeze(1)], dim=1) gone_distance += step_distance step += 1 return predicted_points 6. Trả về response result = { \u0026#39;storm_id\u0026#39;: storm_id, \u0026#39;storm_name\u0026#39;: storm_name, \u0026#39;prediction_time\u0026#39;: datetime.now().isoformat(), \u0026#39;totalDistance\u0026#39;: 500.5, \u0026#39;actualDistance\u0026#39;: 520.3, \u0026#39;lifespan\u0026#39;: 72, \u0026#39;forecastHours\u0026#39;: 72, \u0026#39;forecast\u0026#39;: [ { \u0026#39;lat\u0026#39;: 15.1, \u0026#39;lng\u0026#39;: 106.99, \u0026#39;timestamp\u0026#39;: 1765015351626, \u0026#39;windSpeed\u0026#39;: 65, \u0026#39;pressure\u0026#39;: 980, \u0026#39;category\u0026#39;: \u0026#39;Typhoon\u0026#39; }, ... ] } return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps(result) } Quy trình Build \u0026amp; Deploy Bước 1: Build Docker Image cd storm_prediction docker build \\ --provenance=false \\ --platform linux/amd64 \\ -t storm-prediction-model . Giải thích flags:\n--provenance=false: Giảm kích thước image (không kèm metadata build) --platform linux/amd64: Lambda chỉ hỗ trợ x86_64 -t storm-prediction-model: Tên tag của image Bước 2: Tag để push lên ECR docker tag storm-prediction-model:latest \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Bước 3: Đăng nhập ECR aws ecr get-login-password --region ap-southeast-1 | \\ docker login --username AWS --password-stdin \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com Bước 4: Push image lên ECR docker push \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Thời gian: ~5–10 phút (upload ~2GB)\nBước 5: Cập nhật Lambda Function Trên AWS Console:\nLambda → storm-prediction Tab Image → Deploy new image Chọn image latest Nhấn Save Cấu hình Lambda Thiết lập Function Name: storm-prediction Runtime: Container image Architecture: x86_64 Memory: 3008 MB Timeout: 120 seconds Ephemeral storage: 512 MB Biến môi trường MODEL_BUCKET=storm-frontend-hosting-duc-2025 DATA_BUCKET=storm-frontend-hosting-duc-2025 Function URL URL: https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws Auth type: NONE CORS: Enabled - Allow origins: * - Allow methods: POST, OPTIONS - Allow headers: Content-Type Quyền IAM Role { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::storm-frontend-hosting-duc-2025/*\u0026#34;, \u0026#34;arn:aws:s3:::storm-ai-models/*\u0026#34; ] } ] } Giám sát \u0026amp; Logs CloudWatch Logs Log Group: /aws/lambda/storm-prediction\nCác log quan trọng:\nLoading LSTM model... Downloaded LSTM from S3 LSTM loaded successfully Loading TCN model... Checking: /var/task/models/cropping_storm_7304_2l.pth Found TCN at /var/task/models/cropping_storm_7304_2l.pth TCN loaded successfully Processing: Test Storm (TEST001) Input points: 9 Predicted total distance: 500.50 km Generated 24 predictions (72 hours) Saved to S3: predictions/TEST001_1733486400.json Metrics CloudWatch Metrics:\nInvocations Duration (trung bình ~5–10 giây) Errors Throttles Memory used (~500–800 MB) Lỗi thường gặp \u0026amp; cách xử lý 1. UnicodeDecodeError: \u0026lsquo;utf-8\u0026rsquo; codec can\u0026rsquo;t decode byte 0x80 Triệu chứng:\nUnicodeDecodeError: \u0026#39;utf-8\u0026#39; codec can\u0026#39;t decode byte 0x80 in position 64 Nguyên nhân: file model .pth ở thư mục gốc bị Lambda hiểu nhầm như file cấu hình Python\nCách xử lý: chuyển model vào thư mục con\nRUN mkdir -p ${LAMBDA_TASK_ROOT}/models COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/models/ 2. 502 Bad Gateway Triệu chứng: Frontend nhận lỗi 502\nNguyên nhân có thể:\nLambda timeout (quá 120s) Lambda crash (hết bộ nhớ) Load model thất bại Cách xử lý:\nKiểm tra CloudWatch Logs Tăng memory nếu cần Tăng timeout nếu cần 3. LSTM Fallback Đặc điểm: log có \u0026quot; Using fallback distance\u0026quot;\nNguyên nhân: chưa có model LSTM trên S3\nCách xử lý: upload lstm_totald_256_4.pt lên S3\naws s3 cp lstm_totald_256_4.pt \\ s3://storm-frontend-hosting-duc-2025/models/ 4. ECR Push 403 Forbidden Đặc điểm: 403 Forbidden khi push image\nNguyên nhân có thể:\nHết hạn đăng nhập ECR Sai account ID Repo chưa tồn tại Cách xử lý:\n# Đăng nhập lại aws ecr get-login-password --region ap-southeast-1 | \\ docker login --username AWS --password-stdin \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com # Tạo repository nếu cần aws ecr create-repository \\ --repository-name storm-prediction \\ --region ap-southeast-1 Kiểm thử Test local (nếu có thể) # Chạy local python app.py # Test event test_event = { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, ... ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } result = handler(test_event, None) print(result) Test trực tiếp trên Lambda Trên AWS Console:\nLambda → tab Test Tạo test event: { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, {\u0026#34;lat\u0026#34;: 15.2, \u0026#34;lng\u0026#34;: 120.2}, {\u0026#34;lat\u0026#34;: 15.3, \u0026#34;lng\u0026#34;: 120.3}, {\u0026#34;lat\u0026#34;: 15.4, \u0026#34;lng\u0026#34;: 120.4}, {\u0026#34;lat\u0026#34;: 15.5, \u0026#34;lng\u0026#34;: 120.5}, {\u0026#34;lat\u0026#34;: 15.6, \u0026#34;lng\u0026#34;: 120.6}, {\u0026#34;lat\u0026#34;: 15.7, \u0026#34;lng\u0026#34;: 120.7}, {\u0026#34;lat\u0026#34;: 15.8, \u0026#34;lng\u0026#34;: 120.8} ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } Nhấn Test Kiểm tra response Test bằng cURL bash curl -X POST \\ \u0026quot;https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws/predict\u0026quot; \\ -H \u0026quot;Content-Type: application/json\u0026quot; \\ -d '{ \u0026quot;history\u0026quot;: [ {\u0026quot;lat\u0026quot;: 15.0, \u0026quot;lng\u0026quot;: 120.0}, {\u0026quot;lat\u0026quot;: 15.1, \u0026quot;lng\u0026quot;: 120.1}, {\u0026quot;lat\u0026quot;: 15.2, \u0026quot;lng\u0026quot;: 120.2}, {\u0026quot;lat\u0026quot;: 15.3, \u0026quot;lng\u0026quot;: 120.3}, {\u0026quot;lat\u0026quot;: 15.4, \u0026quot;lng\u0026quot;: 120.4}, {\u0026quot;lat\u0026quot;: 15.5, \u0026quot;lng\u0026quot;: 120.5}, {\u0026quot;lat\u0026quot;: 15.6, \u0026quot;lng\u0026quot;: 120.6}, {\u0026quot;lat\u0026quot;: 15.7, \u0026quot;lng\u0026quot;: 120.7}, {\u0026quot;lat\u0026quot;: 15.8, \u0026quot;lng\u0026quot;: 120.8} ], \u0026quot;storm_name\u0026quot;: \u0026quot;Test Storm\u0026quot; }' Checklist triển khai File model cropping_storm_7304_2l.pth tồn tại (Tùy chọn) Upload model LSTM lên S3 Build Docker image thành công Tag image đúng account ID (339570693867) Login ECR thành công Push image lên ECR Update Lambda function với image mới Kiểm tra cấu hình Lambda (memory, timeout) Test Lambda với test event Test qua Function URL bằng cURL Test từ frontend Kiểm tra CloudWatch Logs Xác nhận kết quả dự đoán hiển thị trên bản đồ Ảnh chụp Hình 1 Cấu hình (Configuration) Hình 2 Biến môi trường (Environment Variables) Hình 3 ECR Kho lưu trữ (Repository) Hình 4 Hình 5 "},{"uri":"https://github.com/leduc121/fcj_report/vi/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/5.4.2.2-fix-unicode-error-solution/","title":"Sửa lỗi Unicode","tags":[],"description":"","content":"Giải quyết lỗi UnicodeDecodeError trong Lambda Đây là một lỗi quan trọng mà nhóm gặp phải trong quá trình xây dựng nền tảng và tích hợp model nên dành riêng một mục để nói về nó. Chi tiết xe ở bên dưới.\nVấn đề UnicodeDecodeError: \u0026#39;utf-8\u0026#39; codec can\u0026#39;t decode byte 0x80 in position 64: invalid start byte Nguyên nhân Model PyTorch có extension .pth (binary file) Python runtime cũng sử dụng .pth files cho path configuration (text files) Khi đặt model .pth trực tiếp trong LAMBDA_TASK_ROOT, Python cố đọc nó như text → lỗi Giải pháp đã áp dụng 1. Sửa Dockerfile Di chuyển model vào thư mục con models/:\nRUN mkdir -p ${LAMBDA_TASK_ROOT}/models COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/models/ 2. Sửa app.py Update đường dẫn tìm model:\npossible_paths = [ \u0026#39;/var/task/models/cropping_storm_7304_2l.pth\u0026#39;, \u0026#39;models/cropping_storm_7304_2l.pth\u0026#39;, tcn_path ] Các bước rebuild và deploy Bước 1: Build Docker image cd storm_prediction docker build --provenance=false --platform linux/amd64 -t storm-prediction-model . Lưu ý: --provenance=false giúp giảm kích thước image để push lên ECR\nBước 2: Tag image docker tag storm-prediction-model:latest 211125445874.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Bước 3: Login ECR aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin 211125445874.dkr.ecr.ap-southeast-1.amazonaws.com Bước 4: Push to ECR docker push 211125445874.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Bước 5: Update Lambda Vào AWS Console → Lambda → storm-prediction Click tab Image Click Deploy new image Chọn image mới nhất Click Save Bước 6: Test curl -X POST \u0026#34;https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws/predict\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 14.5, \u0026#34;lng\u0026#34;: 121.0}, {\u0026#34;lat\u0026#34;: 14.6, \u0026#34;lng\u0026#34;: 121.1}, {\u0026#34;lat\u0026#34;: 14.7, \u0026#34;lng\u0026#34;: 121.2}, {\u0026#34;lat\u0026#34;: 14.8, \u0026#34;lng\u0026#34;: 121.3}, {\u0026#34;lat\u0026#34;: 14.9, \u0026#34;lng\u0026#34;: 121.4}, {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 121.5}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 121.6}, {\u0026#34;lat\u0026#34;: 15.2, \u0026#34;lng\u0026#34;: 121.7}, {\u0026#34;lat\u0026#34;: 15.3, \u0026#34;lng\u0026#34;: 121.8} ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; }\u0026#39; Kiểm tra logs sau khi deploy aws logs tail /aws/lambda/storm-prediction --region ap-southeast-1 --follow Tóm tắt Trước: Model .pth ở root → Python nhầm là config file → UnicodeDecodeError Sau: Model .pth ở models/ → Python bỏ qua → Lambda hoạt động ✅ "},{"uri":"https://github.com/leduc121/fcj_report/vi/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/5.4.2.1-ai-model-integration/","title":"Tích Hợp AI","tags":[],"description":"","content":"Tiến hành tích hợp AI Model từ Lambda Tổng quan Dưới đây xin trình bày về cách mà nhóm đã tích hợp mô hình AI dự đoán bão từ lambda để dùng theo từng bước.\nCác file đang dùng Mock Data 1. WeatherOverlay.tsx (QUAN TRỌNG) Vị trí: frontend/src/components/WeatherOverlay.tsx Mock data: Temperature và Wind overlay data Function: generateWeatherData() Cần sửa: Thay thế bằng API call đến Lambda 2. WeeklyForecast.tsx Vị trí: frontend/src/components/WeeklyForecast.tsx Mock data: mockForecast array Cần sửa: Fetch từ backend API 3. windData.ts Vị trí: frontend/src/lib/windData.ts Mock data: mockWindData Cần sửa: Fetch từ OpenWeatherMap hoặc Lambda 4. WindFieldManager.ts Vị trí: frontend/src/components/wind/WindFieldManager.ts Mock data: Fallback khi không có API key Đã OK: Có logic fetch từ OpenWeatherMap, chỉ cần config API key Cách tích hợp AI Model từ Lambda Bước 1: Thêm API endpoint cho Storm Prediction Trong file frontend/src/api/weatherApi.ts, thêm:\nexport interface StormPrediction { stormId: string; name: string; nameVi: string; currentPosition: { lat: number; lng: number; timestamp: number; windSpeed: number; pressure: number; category: string; }; historicalTrack: Array\u0026lt;{ lat: number; lng: number; timestamp: number; windSpeed: number; pressure: number; category: string; }\u0026gt;; forecastTrack: Array\u0026lt;{ lat: number; lng: number; timestamp: number; windSpeed: number; pressure: number; category: string; confidence?: number; // Độ tin cậy từ AI model }\u0026gt;; } export const weatherApi = { // ... existing methods ... // Lấy dự đoán bão từ Lambda AI model getStormPredictions: async (): Promise\u0026lt;StormPrediction[]\u0026gt; =\u0026gt; { const response = await api.get\u0026lt;StormPrediction[]\u0026gt;(\u0026#39;/storms/predictions\u0026#39;); return response.data; }, // Lấy chi tiết một cơn bão cụ thể getStormById: async (stormId: string): Promise\u0026lt;StormPrediction\u0026gt; =\u0026gt; { const response = await api.get\u0026lt;StormPrediction\u0026gt;(`/storms/${stormId}`); return response.data; }, }; Bước 2: Cập nhật Backend để gọi Lambda Trong backend C# (backend/Controllers/WeatherController.cs), thêm endpoint:\n[HttpGet(\u0026#34;storms/predictions\u0026#34;)] public async Task\u0026lt;IActionResult\u0026gt; GetStormPredictions() { try { // Gọi Lambda function var lambdaClient = new AmazonLambdaClient(); var request = new InvokeRequest { FunctionName = \u0026#34;storm-prediction-function\u0026#34;, InvocationType = InvocationType.RequestResponse, Payload = \u0026#34;{}\u0026#34; // Hoặc parameters nếu cần }; var response = await lambdaClient.InvokeAsync(request); using var reader = new StreamReader(response.Payload); var result = await reader.ReadToEndAsync(); return Ok(JsonSerializer.Deserialize\u0026lt;List\u0026lt;StormPrediction\u0026gt;\u0026gt;(result)); } catch (Exception ex) { return StatusCode(500, new { error = ex.Message }); } } Bước 3: Cập nhật Frontend để dùng API thật Trong frontend/src/pages/Index.tsx hoặc nơi fetch storm data:\nimport { weatherApi } from \u0026#39;../api/weatherApi\u0026#39;; import { useQuery } from \u0026#39;@tanstack/react-query\u0026#39;; // Thay vì dùng mock data const { data: storms, isLoading } = useQuery({ queryKey: [\u0026#39;storms\u0026#39;], queryFn: () =\u0026gt; weatherApi.getStormPredictions(), refetchInterval: 5 * 60 * 1000, // Refresh mỗi 5 phút }); Bước 4: Cấu hình Environment Variables Frontend (.env.production):\nVITE_API_BASE_URL=https://your-backend-api.com/api/weather Backend (appsettings.json):\n{ \u0026#34;AWS\u0026#34;: { \u0026#34;Region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;LambdaFunctionName\u0026#34;: \u0026#34;storm-prediction-function\u0026#34; } } Checklist Deploy Deploy AI model lên Lambda Test Lambda function với sample input Thêm API endpoint trong backend C# Test backend endpoint Cập nhật weatherApi.ts với endpoints mới Thay thế mock data bằng API calls Test frontend với data thật Cập nhật .env.production với URL production Build và deploy frontend Monitor logs và errors Files không cần sửa (chỉ là examples) Các file này chỉ là demo/example, không ảnh hưởng production:\n*.example.tsx */__tests__/* */GUIDE.md "},{"uri":"https://github.com/leduc121/fcj_report/vi/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/5.4.2.3-lambda-deployment/","title":"Triển Khai Lamda","tags":[],"description":"","content":"Các bước Deploy PyTorch Model dự đoán bão lên AWS Lambda Việc triển khai Lambda là một phần quan trọng trong quy trình phát triển website của nhóm. Mục sau đây sẽ giải thích các bước chúng em đã thực hiện để hoàn thành quy trình này.\nChuẩn bị Code 1.1. Sửa app.py\nimport json import torch import numpy as np from typing import List, Dict # Load model khi Lambda khởi động (reuse across invocations) MODEL_PATH = \u0026#34;model.pth\u0026#34; device = torch.device(\u0026#34;cpu\u0026#34;) # Lambda không có GPU model = None def load_model(): global model if model is None: print(f\u0026#34;Loading model from {MODEL_PATH}...\u0026#34;) model = torch.load(MODEL_PATH, map_location=device) model.eval() print(\u0026#34;Model loaded successfully!\u0026#34;) return model def prepare_features(history: List[Dict]) -\u0026gt; torch.Tensor: \u0026#34;\u0026#34;\u0026#34; Chuyển đổi history thành tensor cho model history: [{\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 107.0}, ...] \u0026#34;\u0026#34;\u0026#34; # TODO: Implement feature engineering theo model của bạn lats = [p[\u0026#34;lat\u0026#34;] for p in history] lngs = [p[\u0026#34;lng\u0026#34;] for p in history] # Ví dụ: normalize và reshape features = np.array([lats + lngs]) # Shape: (1, 18) return torch.tensor(features, dtype=torch.float32) def format_predictions(predictions: torch.Tensor, storm_name: str) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34; Format output theo cấu trúc frontend cần \u0026#34;\u0026#34;\u0026#34; # TODO: Implement theo output của model pred_array = predictions.detach().cpu().numpy()[0] # Giả sử model predict 10 điểm tiếp theo (lat, lng) forecast = [] base_timestamp = int(time.time() * 1000) for i in range(0, len(pred_array), 2): if i + 1 \u0026lt; len(pred_array): forecast.append({ \u0026#34;lat\u0026#34;: float(pred_array[i]), \u0026#34;lng\u0026#34;: float(pred_array[i + 1]), \u0026#34;timestamp\u0026#34;: base_timestamp + (i // 2) * 3600000, # +1 hour each \u0026#34;windSpeed\u0026#34;: 120.0, # TODO: Predict từ model \u0026#34;pressure\u0026#34;: 980.0, # TODO: Predict từ model \u0026#34;category\u0026#34;: \u0026#34;Category 3\u0026#34;, # TODO: Classify từ windSpeed \u0026#34;confidence\u0026#34;: 0.85 }) return { \u0026#34;storm_name\u0026#34;: storm_name, \u0026#34;forecast\u0026#34;: forecast } def handler(event, context): \u0026#34;\u0026#34;\u0026#34; Lambda handler function \u0026#34;\u0026#34;\u0026#34; try: # Parse input body = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) history = body.get(\u0026#39;history\u0026#39;, []) storm_name = body.get(\u0026#39;storm_name\u0026#39;, \u0026#39;Unknown Storm\u0026#39;) # Validate input if len(history) \u0026lt; 9: return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;error\u0026#39;: f\u0026#39;Need at least 9 positions, got {len(history)}\u0026#39; }) } # Load model model = load_model() # Prepare features X = prepare_features(history) # Predict with torch.no_grad(): predictions = model(X) # Format output result = format_predictions(predictions, storm_name) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps(result) } except Exception as e: print(f\u0026#34;Error: {str(e)}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 500, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;error\u0026#39;: str(e) }) } 1.2. Sửa Dockerfile\nFROM public.ecr.aws/lambda/python:3.11 # Copy requirements và install COPY requirements.txt ${LAMBDA_TASK_ROOT} RUN pip install --no-cache-dir -r requirements.txt # Copy model (đổi tên thành model.pth) COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/model.pth # Copy code COPY app.py ${LAMBDA_TASK_ROOT} # Set handler CMD [\u0026#34;app.handler\u0026#34;] 1.3. Kiểm tra requirements.txt\ntorch==2.1.0 numpy==1.24.3 Bước 2: Build Docker Image cd storm_prediction # Build image docker build -t storm-prediction-model . # Test local (optional) docker run -p 9000:8080 storm-prediction-model # Test với curl curl -X POST \u0026#34;http://localhost:9000/2015-03-31/functions/function/invocations\u0026#34; \\ -d \u0026#39;{ \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;history\\\u0026#34;: [{\\\u0026#34;lat\\\u0026#34;: 15.0, \\\u0026#34;lng\\\u0026#34;: 107.0}, {\\\u0026#34;lat\\\u0026#34;: 15.1, \\\u0026#34;lng\\\u0026#34;: 107.1}, {\\\u0026#34;lat\\\u0026#34;: 15.2, \\\u0026#34;lng\\\u0026#34;: 107.2}, {\\\u0026#34;lat\\\u0026#34;: 15.3, \\\u0026#34;lng\\\u0026#34;: 107.3}, {\\\u0026#34;lat\\\u0026#34;: 15.4, \\\u0026#34;lng\\\u0026#34;: 107.4}, {\\\u0026#34;lat\\\u0026#34;: 15.5, \\\u0026#34;lng\\\u0026#34;: 107.5}, {\\\u0026#34;lat\\\u0026#34;: 15.6, \\\u0026#34;lng\\\u0026#34;: 107.6}, {\\\u0026#34;lat\\\u0026#34;: 15.7, \\\u0026#34;lng\\\u0026#34;: 107.7}, {\\\u0026#34;lat\\\u0026#34;: 15.8, \\\u0026#34;lng\\\u0026#34;: 107.8}], \\\u0026#34;storm_name\\\u0026#34;: \\\u0026#34;Test Storm\\\u0026#34;}\u0026#34; }\u0026#39; Bước 3: Upload lên AWS ECR # 1. Tạo ECR repository aws ecr create-repository \\ --repository-name storm-prediction-model \\ --region ap-southeast-1 # 2. Đăng nhập Docker vào ECR aws ecr get-login-password --region ap-southeast-1 | \\ docker login --username AWS --password-stdin \\ \u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com # 3. Tag image docker tag storm-prediction-model:latest \\ \u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction-model:latest # 4. Push image docker push \u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction-model:latest Lưu ý: Thay \u0026lt;account-id\u0026gt; bằng AWS Account ID của bạn.\nBước 4: Tạo Lambda Function 4.1. Tạo Lambda từ Console\nVào AWS Lambda Console Click \u0026ldquo;Create function\u0026rdquo; Chọn \u0026ldquo;Container image\u0026rdquo; Function name: storm-prediction Container image URI: Chọn image vừa push lên ECR Architecture: x86_64 Click \u0026ldquo;Create function\u0026rdquo; 4.2. Cấu hình Lambda\n# Hoặc dùng AWS CLI aws lambda create-function \\ --function-name storm-prediction \\ --package-type Image \\ --code ImageUri=\u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction-model:latest \\ --role arn:aws:iam::\u0026lt;account-id\u0026gt;:role/lambda-execution-role \\ --timeout 60 \\ --memory-size 3008 \\ --region ap-southeast-1 Cấu hình quan trọng:\nMemory: 3008 MB (PyTorch model cần nhiều RAM) Timeout: 60 seconds (model inference có thể mất 10-30s) Ephemeral storage: 512 MB (default, tăng nếu cần) 4.3. Tạo IAM Role\nLambda cần role với permissions:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ecr:GetDownloadUrlForLayer\u0026#34;, \u0026#34;ecr:BatchGetImage\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Bước 5: Tạo API Gateway # 1. Tạo REST API aws apigateway create-rest-api \\ --name storm-prediction-api \\ --region ap-southeast-1 # 2. Lấy API ID và Root Resource ID API_ID=\u0026lt;your-api-id\u0026gt; ROOT_ID=\u0026lt;your-root-resource-id\u0026gt; # 3. Tạo resource /predict aws apigateway create-resource \\ --rest-api-id $API_ID \\ --parent-id $ROOT_ID \\ --path-part predict # 4. Tạo POST method RESOURCE_ID=\u0026lt;predict-resource-id\u0026gt; aws apigateway put-method \\ --rest-api-id $API_ID \\ --resource-id $RESOURCE_ID \\ --http-method POST \\ --authorization-type NONE # 5. Integrate với Lambda aws apigateway put-integration \\ --rest-api-id $API_ID \\ --resource-id $RESOURCE_ID \\ --http-method POST \\ --type AWS_PROXY \\ --integration-http-method POST \\ --uri arn:aws:apigateway:ap-southeast-1:lambda:path/2015-03-31/functions/arn:aws:lambda:ap-southeast-1:\u0026lt;account-id\u0026gt;:function:storm-prediction/invocations # 6. Deploy API aws apigateway create-deployment \\ --rest-api-id $API_ID \\ --stage-name prod API URL: https://\u0026lt;api-id\u0026gt;.execute-api.ap-southeast-1.amazonaws.com/prod/predict\nBước 6: Cập nhật Frontend 6.1. Cập nhật .env.production\nVITE_PREDICTION_API_URL=https://\u0026lt;api-id\u0026gt;.execute-api.ap-southeast-1.amazonaws.com/prod 6.2. Build và deploy frontend\ncd frontend npm run build # Deploy dist/ lên S3/CloudFront Tối ưu hóa 1. Giảm Cold Start Provisioned Concurrency:\naws lambda put-provisioned-concurrency-config \\ --function-name storm-prediction \\ --provisioned-concurrent-executions 1 \\ --qualifier $LATEST 2. Giảm kích thước Image Dùng PyTorch CPU-only:\n# requirements.txt torch==2.1.0+cpu --extra-index-url https://download.pytorch.org/whl/cpu numpy==1.24.3 Multi-stage build:\n# Stage 1: Build FROM python:3.11-slim as builder COPY requirements.txt . RUN pip install --target /packages -r requirements.txt # Stage 2: Runtime FROM public.ecr.aws/lambda/python:3.11 COPY --from=builder /packages ${LAMBDA_RUNTIME_DIR} COPY model.pth ${LAMBDA_TASK_ROOT}/ COPY app.py ${LAMBDA_TASK_ROOT}/ CMD [\u0026#34;app.handler\u0026#34;] 3. Cache Model trong /tmp import os MODEL_PATH = \u0026#34;/tmp/model.pth\u0026#34; if os.path.exists(\u0026#34;/tmp/model.pth\u0026#34;) else \u0026#34;model.pth\u0026#34; def load_model(): global model if model is None: # Copy to /tmp for faster access if not os.path.exists(\u0026#34;/tmp/model.pth\u0026#34;): import shutil shutil.copy(\u0026#34;model.pth\u0026#34;, \u0026#34;/tmp/model.pth\u0026#34;) model = torch.load(\u0026#34;/tmp/model.pth\u0026#34;, map_location=device) model.eval() return model Monitoring CloudWatch Logs # Xem logs aws logs tail /aws/lambda/storm-prediction --follow CloudWatch Metrics Invocations: Số lần gọi Duration: Thời gian chạy Errors: Số lỗi Throttles: Số lần bị throttle Alerts # Tạo alarm cho errors aws cloudwatch put-metric-alarm \\ --alarm-name storm-prediction-errors \\ --alarm-description \u0026#34;Alert when Lambda has errors\u0026#34; \\ --metric-name Errors \\ --namespace AWS/Lambda \\ --statistic Sum \\ --period 300 \\ --threshold 5 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=FunctionName,Value=storm-prediction Troubleshooting Lỗi: \u0026ldquo;Task timed out after 3.00 seconds\u0026rdquo; Giải pháp: Tăng timeout lên 60s\nLỗi: \u0026ldquo;Runtime exited with error: signal: killed\u0026rdquo; Giải pháp: Tăng memory lên 3008 MB\nLỗi: \u0026ldquo;No module named \u0026rsquo;torch'\u0026rdquo; Giải pháp: Kiểm tra requirements.txt và rebuild image\nLỗi: Model không load được Giải pháp: Kiểm tra tên file model trong Dockerfile và app.py\nChi phí ước tính Lambda:\nFree tier: 1M requests/month, 400,000 GB-seconds Sau đó: $0.20 per 1M requests + $0.0000166667 per GB-second Ví dụ: 10,000 requests/month, mỗi request 10s, 3GB RAM\nCompute: 10,000 × 10s × 3GB × $0.0000166667 = $5/month Requests: 10,000 × $0.20/1M = $0.002/month Total: ~$5/month API Gateway:\n$3.50 per million requests 10,000 requests = $0.035/month ECR:\n$0.10 per GB/month storage Image ~2GB = $0.20/month Total ước tính: ~$5.25/month cho 10,000 predictions\nChecklist cuối cùng Sửa tên file model trong app.py hoặc Dockerfile Test Docker image locally Push image lên ECR Tạo Lambda function với memory 3008MB, timeout 60s Tạo API Gateway và integrate với Lambda Test API với Postman/curl Cập nhật VITE_PREDICTION_API_URL trong frontend Build và deploy frontend Test form prediction trên web Setup CloudWatch alerts Monitor logs và performance "},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Học về dịch vụ VM Import/Export trong AWS Hiểu về Amazon RDS (Relational Database Service) Thực hành quản lý database trong AWS Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Học về AWS VM Import/Export: + Các định dạng được hỗ trợ (OVA, VMDK, VHD) + Yêu cầu và IAM roles + Use cases cho migration 29/09/2024 29/09/2024 https://000014.awsstudygroup.com/ 2 - Tiếp tục VM Import/Export: + Chuẩn bị VM để import + Upload lên S3 - Thực hành: Import VM image lên AWS 30/09/2024 30/09/2024 https://000014.awsstudygroup.com/ 3 - Học Amazon RDS cơ bản: + Database engines (MySQL, PostgreSQL, MariaDB, Oracle, SQL Server) + DB instances và instance classes + Storage types 01/10/2024 01/10/2024 https://000005.awsstudygroup.com/ 4 - Tiếp tục học RDS: + Multi-AZ deployments + Read replicas + Backup và restore + Security groups cho RDS 02/10/2024 02/10/2024 https://000005.awsstudygroup.com/ 5 - Thực hành RDS: + Tạo RDS instance + Kết nối đến database + Cấu hình backups + Test Multi-AZ failover 03/10/2024 04/10/2024 https://000005.awsstudygroup.com/ Kết quả đạt được tuần 4: Kiến thức VM Import/Export:\nHiểu quy trình di chuyển máy ảo lên AWS Học về các định dạng VM được hỗ trợ và yêu cầu chuyển đổi Nắm vững cấu hình IAM role cho VM import Import thành công VM images từ on-premises lên AWS Hiểu use cases cho các kịch bản hybrid cloud Chuyên môn Amazon RDS:\nHiểu sâu về dịch vụ RDS và các database engines được hỗ trợ Học về các DB instance classes khác nhau và trường hợp sử dụng Hiểu các storage types (General Purpose SSD, Provisioned IOPS, Magnetic) Nắm vững Multi-AZ deployments cho high availability Học về Read Replicas để scale read operations Quản lý Database:\nTạo và cấu hình thành công RDS instances Kết nối đến databases sử dụng nhiều clients khác nhau Cấu hình automated backups và manual snapshots Hiểu point-in-time recovery Triển khai security best practices với security groups và encryption High Availability và Disaster Recovery:\nHiểu kiến trúc Multi-AZ và automatic failover Học về backup retention và restoration procedures Test các failover scenarios Hiểu các khái niệm RTO và RPO "},{"uri":"https://github.com/leduc121/fcj_report/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"NỀN TẢNG THEO DÕI VÀ DỰ ĐOÁN BÃO Tổng Quan Bão là một trong những thảm họa thiên nhiên nguy hiểm nhất, có thể gây thiệt hại nghiêm trọng đến cơ sở hạ tầng và đe dọa tính mạng con người. Việc phát hiện sớm và đưa ra cảnh báo kịp thời là vô cùng quan trọng để người dân trong khu vực bị ảnh hưởng có đủ thời gian chuẩn bị và sơ tán an toàn.\nĐể đáp ứng nhu cầu này, dự án của chúng tôi hướng đến việc xây dựng một nền tảng trực tuyến cho phép người dùng truy cập miễn phí vào thông tin về những cơn bão mới nhất ở khu vực Tây Thái Bình Dương, sử dụng dữ liệu từ NOAA (Cơ quan Quản lý Khí quyển và Đại dương Quốc gia Hoa Kỳ) — một nguồn dữ liệu đáng tin cậy. Bên cạnh đó, sinh viên, nhà khí tượng hoặc bất kỳ ai quan tâm đến động lực học của bão đều có thể tương tác với hệ thống bằng cách cung cấp quỹ đạo đầu vào của riêng họ và nhận về dự đoán được tạo bởi mô hình học máy của chúng tôi.\nWorkshop này trình bày toàn bộ quy trình xây dựng mô hình dự báo bão, bao gồm nhiều kỹ thuật chuỗi thời gian mới — Stepwise Temporal Fading và Plausible Geodesic-Aware Augmentation — cùng với phần giải thích chi tiết từng bước về cách chúng tôi xây dựng và triển khai nền tảng từ con số 0.\nVới sự hỗ trợ của các dịch vụ AWS như Amazon S3, AWS Lambda, API Gateway và CloudFront, chúng tôi xây dựng một kiến trúc hoàn toàn serverless. Giải pháp này mang lại sự đơn giản, khả năng mở rộng linh hoạt và hiệu quả chi phí dài hạn, đồng thời đảm bảo hiệu suất ổn định và phản hồi nhanh.\nKiến trúc Nền tảng Nền tảng cuối cùng cung cấp hai chức năng cốt lõi:\nXem Thông Tin Bão Người dùng có thể khám phá thông tin mới nhất về các cơn bão ở Tây Thái Bình Dương, bao gồm quỹ đạo lịch sử, tốc độ gió, nhiệt độ và các thông số liên quan khác.\nDự Đoán Quỹ Đạo Bão Người dùng có thể nhập quỹ đạo một phần của cơn bão và nhận về dự đoán quãng đường tiếp theo được tạo bởi mô hình đã huấn luyện.\nNội dung Tổng quan về workshop Chuẩn bị dữ liệu Kiến tạo mô hình ML Kiến trúc Front\u0026amp;Back-end API "},{"uri":"https://github.com/leduc121/fcj_report/vi/5-workshop/5.5-platform-api/","title":"Nền tảng API","tags":[],"description":"","content":"MÔ TẢ CHI TIẾT BACK-END API Mục lục Giới thiệu Kiến trúc hệ thống Tính năng cốt lõi Công nghệ sử dụng Cấu trúc dự án API Endpoints 1. Giới thiệu Weather Backend API là một dịch vụ RESTful cung cấp thông tin thời tiết bằng cách tích hợp với OpenWeatherMap API. Backend hoạt động như lớp trung gian giữa ứng dụng frontend và các nguồn dữ liệu thời tiết bên ngoài.\nHình 1 2. Kiến trúc hệ thống Kiến trúc ┌─────────────────────────────────────────────────────────────┐ │ Ứng dụng Frontend │ │ (React, Mobile, Web Clients) │ └─────────────────────────────────────────────────────────────┘ │ │ HTTPS / REST API ▼ ┌─────────────────────────────────────────────────────────────┐ │ Weather Backend API │ │ (.NET 9.0 - ASP.NET Core) │ ├─────────────────────────────────────────────────────────────┤ │ ┌────────────────┐ ┌────────────────┐ ┌────────────────┐ │ │ Bộ điều khiển │ │ Dịch vụ │ │ Program.cs │ │ │ │ │ │ │ - Khởi động app│ │ │ - WeatherCtrl │ │ - WeatherSvc │ │ - Ghi log │ │ │ - ForecastCtrl │ │ - Lớp cache │ │ - Thiết lập DI │ │ └────────────────┘ └────────────────┘ └────────────────┘ └─────────────────────────────────────────────────────────────┘ │ │ HTTPS / REST API (Bên ngoài) ▼ ┌─────────────────────────────────────────────────────────────┐ │ Dịch vụ thời tiết bên ngoài │ ├─────────────────────────────────────────────────────────────┤ │ • OpenWeatherMap API │ │ • Redis Caching Layer │ │ • Giới hạn tốc độ \u0026amp; Giám sát │ └─────────────────────────────────────────────────────────────┘ 3. Tính năng cốt lõi Mô tả: Lấy dữ liệu thời tiết hiện tại của bất kỳ thành phố nào trên thế giới.\nTính năng:\nTìm kiếm theo tên thành phố (ví dụ: \u0026ldquo;Hà Nội\u0026rdquo;, \u0026ldquo;TP Hồ Chí Minh\u0026rdquo;) Tùy chọn mã quốc gia để xác định vị trí chính xác Hỗ trợ nhiều hệ thống đơn vị (metric, imperial, standard) Hỗ trợ đa ngôn ngữ cho phần mô tả thời tiết Phản hồi được lưu cache để tăng hiệu suất Tham số API:\ncityName (bắt buộc): Tên thành phố countryCode (tùy chọn): Mã quốc gia ISO 3166 units (tùy chọn): metric, imperial, standard language (tùy chọn): en, vi, fr, \u0026hellip; Ví dụ phản hồi:\nResponse body Download { \u0026#34;localDate\u0026#34;: \u0026#34;2025-12-06 19:57:02\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Hà Nội\u0026#34;, \u0026#34;coord\u0026#34;: { \u0026#34;lon\u0026#34;: 105.8412, \u0026#34;lat\u0026#34;: 21.0245 }, \u0026#34;weather\u0026#34;: [ { \u0026#34;id\u0026#34;: 804, \u0026#34;main\u0026#34;: \u0026#34;Clouds\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;mây đen u ám\u0026#34;, \u0026#34;icon\u0026#34;: \u0026#34;04n\u0026#34; } ], \u0026#34;main\u0026#34;: { \u0026#34;temp\u0026#34;: 22, \u0026#34;feels_like\u0026#34;: 22.11, \u0026#34;temp_min\u0026#34;: 22, \u0026#34;temp_max\u0026#34;: 22, \u0026#34;pressure\u0026#34;: 1018, \u0026#34;humidity\u0026#34;: 71, \u0026#34;sea_level\u0026#34;: 1018, \u0026#34;grnd_level\u0026#34;: 1017 }, \u0026#34;wind\u0026#34;: { \u0026#34;speed\u0026#34;: 4.14, \u0026#34;deg\u0026#34;: 136, \u0026#34;gust\u0026#34;: 6.84 }, \u0026#34;sys\u0026#34;: { \u0026#34;type\u0026#34;: 1, \u0026#34;id\u0026#34;: 9308, \u0026#34;country\u0026#34;: \u0026#34;VN\u0026#34;, \u0026#34;sunrise\u0026#34;: 1764976827, \u0026#34;sunset\u0026#34;: 1765016103 } } Hình 2 4. Công nghệ sử dụng Backend Framework .NET 9.0 – Runtime .NET mới nhất ASP.NET Core – Framework xây dựng Web API C# 12 – Ngôn ngữ lập trình chính Tích hợp API HttpClientFactory – Quản lý sử dụng HTTP client Polly – Chính sách thử lại \u0026amp; xử lý lỗi tạm thời Newtonsoft.Json / System.Text.Json – Tuần tự hóa JSON Cache \u0026amp; Hiệu năng MemoryCache – Cache trong bộ nhớ Redis (tùy chọn) – Cache phân tán ResponseCompression – Nén Gzip / Brotli Công cụ phát triển Visual Studio 2022 / VS Code - IDE / Trình soạn thảo mã Swagger / OpenAPI – Tài liệu API Git – Kiểm soát phiên bản Docker – Container hóa 5. Cấu trúc dự án WeatherBackend/ │ ├── WeatherBackend.csproj # Tập tin dự án ├── Program.cs # Điểm vào ứng dụng ├── WeatherBackend.http # Tập tin kiểm tra yêu cầu HTTP │ ├── appsettings.json # Cài đặt cấu hình │ ├── Controllers/ # Bộ điều khiển API │ └── WeatherController.cs # Điểm cuối thời tiết chính │ ├── Services/ # Dịch vụ logic nghiệp vụ │ └── WeatherService/ # Hợp đồng \u0026amp; triển khai dịch vụ 6. API Endpoints Base URL https://localhost:7042/swagger/index.html 6.1 GET /api/weather/current Mô tả:\nLấy dữ liệu thời tiết hiện tại theo tên thành phố.\nVí dụ CURL:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather?city=hanoi\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; URL yêu cầu:\nhttps://localhost:7042/api/Weather?city=hanoi 6.2 GET /api/weather/forecast Mô tả: Lấy dự báo thời tiết 5 ngày cho một thành phố được chọn.\nVí dụ CURL:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather/forecast?city=hochiminh\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; URL yêu cầu:\nhttps://localhost:7042/api/Weather/forecast?city=hochiminh 6.3 GET /api/weather/coordinates Mô tả: Lấy thông tin thời tiết bằng vĩ độ và kinh độ.\nVí dụ CURL:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather/by-coord?lat=21.0245\u0026amp;lon=105.8412\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; URL yêu cầu:\nhttps://localhost:7042/api/Weather/by-coord?lat=21.0245\u0026amp;lon=105.8412 6.4 GET /api/weather/location Mô tả: Lấy thông tin thời tiết theo vị trí của người dùng (yêu cầu thiết bị người dùng gửi tọa độ).\nVí dụ CURL:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather/global\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; URL yêu cầu:\nhttps://localhost:7042/api/Weather/global Hình 3 Cập nhập lần cuối: 2025-12-09\nPhiên bản: 1.0.0\nBảo trì bởi: SKYNET\n"},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Học về AWS Savings Plans để tối ưu chi phí Hiểu các mô hình pricing khác nhau và chiến lược quản lý chi phí Khám phá các best practices về tối ưu chi phí Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Học về các mô hình pricing AWS: + On-Demand pricing + Reserved Instances + Spot Instances + Savings Plans 06/10/2024 06/10/2024 https://000042.awsstudygroup.com/ 2 - Tìm hiểu sâu về Savings Plans: + Compute Savings Plans + EC2 Instance Savings Plans + Commitment terms (1-year, 3-year) + Payment options 07/10/2024 07/10/2024 https://000042.awsstudygroup.com/ 3 - Học các chiến lược tối ưu chi phí: + Right-sizing instances + Sử dụng storage classes phù hợp + Lifecycle policies + Cost allocation tags 08/10/2024 08/10/2024 https://000042.awsstudygroup.com/ 4 - Thực hành: + Phân tích AWS usage hiện tại + Tính toán tiết kiệm tiềm năng + So sánh các pricing models + Tạo cost reports 09/10/2024 09/10/2024 https://000042.awsstudygroup.com/ 5 - Học AWS Cost Explorer và Budgets: + Cost visualization + Usage reports + Budget alerts - Ôn tập kiến thức tuần 10/10/2024 11/10/2024 Tài liệu AWS Cost Management Kết quả đạt được tuần 5: Mô hình Pricing AWS:\nHiểu các mô hình pricing khác nhau và trường hợp sử dụng Học khi nào dùng On-Demand vs Reserved Instances vs Spot Instances Nắm vững khái niệm và lợi ích của Savings Plans Hiểu commitment terms và payment options Chuyên môn Savings Plans:\nHọc về Compute Savings Plans (tiết kiệm đến 66%) Hiểu EC2 Instance Savings Plans (tiết kiệm đến 72%) So sánh Savings Plans với Reserved Instances Học cách chọn Savings Plan phù hợp cho workloads Tối ưu Chi phí:\nNắm vững chiến lược right-sizing cho EC2 instances Hiểu tối ưu S3 storage class Học về lifecycle policies cho automated cost savings Triển khai cost allocation tags để tracking tốt hơn Công cụ Quản lý Chi phí:\nSử dụng AWS Cost Explorer để phân tích spending patterns Tạo custom cost reports Thiết lập budget alerts và notifications Hiểu cost anomaly detection Best Practices:\nHọc cách xác định unused resources Hiểu tầm quan trọng của regular cost reviews Triển khai tagging strategies cho cost allocation Phát triển kỹ năng thiết kế kiến trúc cost-conscious "},{"uri":"https://github.com/leduc121/fcj_report/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Từ ngày 08/09/2025, quãng thời gian thực tập của tôi thực tập tại AWS đã bắt đầu. Xuyên suốt 4 tháng tiếp đó xảy ra như một câu chuyện phiêu lưu khám phá vùng chân trời mới lạ. Bởi đây không chỉ là nơi để lên văn phòng ngồi, điểm danh rồi đi về cho đủ buổi. Đây là miền khai phá của kinh nghiệm và kiến thức mà tôi có thể học được từ cả mentor và những bài lab thú vị.\nĐược may mắn tham nhập vào dự án Online Platform for Tracking and Predicting Hurricane Tracjectory của nhóm SKYNET với vai trò backend engineer, chúng tôi đã chung tay nhau tạo nên một nền tảng cung cấp kịp thời các thông tin quan trọng về bão cho người dùng internet, nếu mở rộng - nâng cấp và được sử dụng rộng rãi, chắc chắn sẽ phòng tránh được rất nhiều thiệt hại về người và của mỗi khi thiên tai xảy ra.\nNhờ vào quá trình đặc biệt này, tôi đã trau dồi được các kỹ năng:\nXây dựng website vững chắc Lập kế hoạch cho các tính huống fall out - back up khi có sự cố Ứng dụng dịch vụ của aws cloud vào hạ tầng nền tảng Học hỏi thêm nhiều kinh nghiệm về DevSecOps cho bản thân. Tôi rất vui vì được tham gia vào nhóm và cùng tạo nên sản phẩm hoàn thiện với những người bạn tuyệt vời.\nChi tiết hơn, tôi dùng bảng đánh giá sau đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ☐ ✅ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ☐ ✅ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Sử dụng tốt hơn các dịch vụ cloud để tiết kiệm tiền, tạo ra kiến trức hoạt động tốt và hiệu quả Sự cởi mở của bản thân vì tôi còn hơi ít nói và hướng nội "},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Học quản lý truy cập EC2 sử dụng resource tags thông qua IAM Hiểu tối ưu chi phí với Lambda automation Triển khai automated resource management Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Học về resource tagging: + Tag best practices + Tag policies + Cost allocation tags + Tag-based access control 13/10/2024 13/10/2024 https://000028.awsstudygroup.com/ 2 - Học IAM policies với tags: + Condition keys cho tags + Tag-based permissions + Resource-level permissions - Thực hành: Tạo tag-based IAM policies 14/10/2024 14/10/2024 https://000028.awsstudygroup.com/ 3 - Thực hành: Quản lý EC2 access với tags: + Tag EC2 instances + Tạo IAM policies dựa trên tags + Test access control + Verify permissions 15/10/2024 15/10/2024 https://000028.awsstudygroup.com/ 4 - Học Lambda cho cost optimization: + Lambda cơ bản + Event-driven automation + CloudWatch Events/EventBridge + Lambda với EC2 API 16/10/2024 16/10/2024 Tài liệu AWS Lambda 5 - Thực hành: Tối ưu EC2 costs với Lambda: + Tạo Lambda function để stop idle instances + Schedule Lambda với EventBridge + Monitor và test automation + Tính toán cost savings 17/10/2024 18/10/2024 Tài liệu AWS Lambda Kết quả đạt được tuần 6: Resource Tagging:\nNắm vững AWS tagging best practices Hiểu tag naming conventions và strategies Học về mandatory tags và tag policies Triển khai cost allocation tags cho billing Tạo comprehensive tagging strategy cho tổ chức IAM Tag-Based Access Control:\nHọc sử dụng condition keys trong IAM policies (aws:RequestTag, aws:ResourceTag) Tạo policies cấp quyền truy cập dựa trên resource tags Triển khai attribute-based access control (ABAC) Quản lý thành công EC2 access sử dụng resource tags Test và verify tag-based permissions Lambda Automation:\nHiểu về AWS Lambda serverless computing Học event-driven architecture patterns Nắm vững Lambda function creation và deployment Hiểu Lambda execution roles và permissions Tối ưu Chi phí với Lambda:\nTạo Lambda functions để identify và stop idle EC2 instances Triển khai automated scheduling với EventBridge Thiết lập notifications cho automated actions Monitor Lambda execution và costs Tính toán actual cost savings từ automation Automation Best Practices:\nHọc triển khai safe automation với proper error handling Hiểu tầm quan trọng của testing automation trong non-production Triển khai logging và monitoring cho automated tasks Tạo documentation cho automated processes "},{"uri":"https://github.com/leduc121/fcj_report/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc chỗ làm sạch sẽ, thoáng mát và rộng rãi.\n2. Sự hỗ trợ của mentor / team admin\nCác mentor rất tốt, nhiệt tình và tận tâm trong việc hướng dẫn cũng như hỗ trợ sinh viên thực tập. Mọi thắc mắc của em đều được các anh giải đáp nhanh chóng và chi tiết. Các mentor cũng thường xuyên kiểm tra tiến độ công việc và đưa ra những lời khuyên hữu ích để em có thể hoàn thành nhiệm vụ một cách tốt nhất.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nDo chuyên ngành kĩ thuật phần mềm của trường là về web và ứng dụng nên AWS là một lựa chon khá tốt và đúng với chuyên ngành. Có thê hỗ trợ nhiều cho sự nghiệp thăng tiến tương lai của em. Hy vọng em có thể apply vào và trở thành nhân viên chính thức của aws vào 1 ngày nào đó.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nem được học về cách tạo kiến trúc với dịch vụ aws, triển khai cơ sở hạ tầng và làm việc với nó để biến nền tảng từ kế hoạch trở thành sản phẩm hoạt động được tốt. Rất đáng để tự hào và khen ngợi bản thân, tất nhiên thì cũng cần cải thiện nhiều và đây chưa phải là điểm dừng cuối cùng trên Cloud Journey.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty ổn và tốt. Nhưng cũng có trường hợp cần nhấn mạnh: Nghĩ kĩ thì các anh mentor không nên nói mỉa mai các bạn thực tập xin nghỉ vì lý do nào đó trước thềm event. Vì rất có thể lời các bạn nói là thật, ta có quyền tự đặt giả định nhưng đừng phát biểu các giả định đó ngoài thực tế nếu không có chứng cứ. Chúng ta đề cao tinh thần học hỏi và làm việc lâu dài cùng nhau, không phải cách nói mỉa mai xỉa xói người khác. Ở đây em không nói cụ thể tới bất cứ ai và cũng không gộp tất cả vào, bản thân em cũng không phải người xin nghỉ bất cứ event nào nhưng vẫn muốn nói ra cho một cộng đồng tốt hơn.\n6. Chính sách / phúc lợi cho thực tập sinh\nPhúc lợi có lẽ là được học hỏi và qua kỳ thực tập. Bản thân em đi thực tập thì không quá mong đợi gì vào điều này, bởi vì ngày nay đề cao mối quan hệ trao đổi bằng giá hơn là cho đi mà không hy vọng nhận lại. em cũng chưa làm gì mang đến lợi nhuận cho aws nên không mong đợi nhận được lương hay gì hơn, được đến và trải nghiệm môi trường làm việc ở đây là vui rồi.\nMột số câu hỏi khác Nói về ấn tượng có lẽ là được làm nhóm cùng những người đồng đội tuyệt vời chăng?\nSẽ cân nhắc đề xuất cho sinh viên SE của trường đi thực tập tại AWS.\nĐề xuất \u0026amp; mong muốn Có lẽ sẽ ở lại để lấy chứng chỉ thực tập và tích lũy kinh nghiệm để 1 ngày nào đó ứng tuyển vào làm. "},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Học về các gói AWS Support và dịch vụ Hiểu cách yêu cầu và quản lý support cases Khám phá AWS Trusted Advisor và best practices Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Học về các gói AWS Support: + Basic Support + Developer Support + Business Support + Enterprise Support + So sánh và pricing 20/10/2024 20/10/2024 https://000009.awsstudygroup.com/ 2 - Học các tính năng AWS Support: + Các loại support case + Response times và SLAs + Technical Account Manager (TAM) + AWS Health Dashboard 21/10/2024 21/10/2024 https://000009.awsstudygroup.com/ 3 - Thực hành: Yêu cầu support: + Tạo support case + Cung cấp thông tin cần thiết + Theo dõi trạng thái case + Giao tiếp với support team 22/10/2024 22/10/2024 https://000009.awsstudygroup.com/ 4 - Học AWS Trusted Advisor: + Cost optimization checks + Performance recommendations + Security best practices + Fault tolerance checks + Service limits 23/10/2024 23/10/2024 Tài liệu AWS Trusted Advisor 5 - Thực hành: Sử dụng Trusted Advisor: + Review recommendations + Triển khai các cải tiến được đề xuất + Thiết lập notifications - Ôn tập kiến thức tuần 24/10/2024 25/10/2024 Tài liệu AWS Trusted Advisor Kết quả đạt được tuần 7: Gói AWS Support:\nHiểu các tiers khác nhau của AWS Support plan và tính năng Học về mô hình pricing cho mỗi support plan So sánh support response times và SLAs Hiểu khi nào nên nâng cấp support plans dựa trên nhu cầu business Học về lợi ích của Technical Account Manager (TAM) Quản lý Support Case:\nTạo và quản lý thành công support cases Học best practices để cung cấp thông tin cho support Hiểu các mức độ nghiêm trọng của case và ảnh hưởng đến response times Thực hành giao tiếp hiệu quả với AWS support team Theo dõi case resolution và follow-up procedures AWS Health Dashboard:\nHọc giám sát AWS service health Hiểu personal health dashboard cho account-specific events Thiết lập notifications cho service disruptions Học cách diễn giải health events và thực hiện hành động phù hợp AWS Trusted Advisor:\nNắm vững năm categories của Trusted Advisor checks Review cost optimization recommendations Triển khai security best practices được đề xuất bởi Trusted Advisor Hiểu các cơ hội cải thiện performance Học về fault tolerance và service limit checks Operational Excellence:\nTriển khai các cải tiến security được đề xuất Tối ưu costs dựa trên Trusted Advisor suggestions Cải thiện architecture cho fault tolerance tốt hơn Thiết lập automated notifications cho Trusted Advisor checks Phát triển thói quen monitoring và optimization chủ động "},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Học React Native cho phát triển mobile app Xây dựng wallet app sử dụng Expo Hoàn thiện website dự án Nghiên cứu AWS Security Hub Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Bắt đầu học React Native: + React Native cơ bản + Expo setup và configuration + Mobile development basics + Navigation patterns 27/10/2024 27/10/2024 https://www.youtube.com/watch?v=vk13GJi4Vd0\u0026t=13571s 2 - Tiếp tục React Native: + Components và styling + State management + API integration - Thực hành: Xây dựng wallet app features 28/10/2024 28/10/2024 https://github.com/leduc121/rn-wallet-app 3 - Hoàn thiện wallet app: + Transaction management + UI/UX improvements + Testing trên devices - Làm việc trên project website 29/10/2024 29/10/2024 https://github.com/leduc121/storm_tracker_fe 4 - Hoàn thiện project website: + Frontend improvements + Responsive design + Deployment preparation - Học AWS Security Hub cơ bản 30/10/2024 30/10/2024 https://000018.awsstudygroup.com/ 5 - Tìm hiểu sâu AWS Security Hub: + Security standards + Findings và insights + Compliance checks + Integration với các services khác - Thực hành: Cấu hình Security Hub 31/10/2024 01/11/2024 https://000018.awsstudygroup.com/ Kết quả đạt được tuần 8: Phát triển React Native:\nHọc React Native cơ bản và khái niệm mobile development Nắm vững Expo framework cho rapid mobile app development Hiểu mobile-specific components và styling Học navigation patterns (Stack, Tab, Drawer navigation) Xây dựng responsive mobile UI components Dự án Wallet App:\nXây dựng thành công wallet app functional sử dụng React Native và Expo Triển khai transaction management features Tạo giao diện người dùng trực quan cho financial operations Tích hợp state management cho app data Test app trên nhiều devices và platforms Publish code lên GitHub repository Phát triển Project Website:\nHoàn thành storm tracker frontend project Triển khai responsive design cho nhiều screen sizes Cải thiện user experience và interface Chuẩn bị application cho deployment Tài liệu hóa project features và setup AWS Security Hub:\nHiểu toàn diện về AWS Security Hub Học về security standards (AWS Foundational Security Best Practices, CIS, PCI DSS) Hiểu security findings và severity levels Học aggregate findings từ nhiều AWS services Cấu hình Security Hub cho account monitoring Security Best Practices:\nTriển khai automated security checks Học về compliance frameworks Hiểu integration với GuardDuty, Inspector, và Macie Thiết lập automated remediation workflows Phát triển security monitoring và response procedures "},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Học về Amazon Lightsail cho simplified cloud computing Tiếp tục phát triển React Native với dự án mới Xây dựng ứng dụng mobile thực tế Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Học Amazon Lightsail: + Lightsail overview và use cases + Instances và pricing + So sánh với EC2 + Khi nào dùng Lightsail 03/11/2024 03/11/2024 https://000045.awsstudygroup.com/ 2 - Tiếp tục học Lightsail: + Databases trong Lightsail + Load balancers + Storage và snapshots - Thực hành: Tạo Lightsail instance 04/11/2024 04/11/2024 https://000045.awsstudygroup.com/ 3 - Thực hành: Deploy application trên Lightsail: + Cấu hình instance + Deploy web application + Thiết lập domain và SSL + Monitor performance 05/11/2024 05/11/2024 https://000045.awsstudygroup.com/ 4 - Bắt đầu dự án React Native mới: + Project planning và setup + UI/UX design + Component architecture + State management setup 06/11/2024 06/11/2024 https://www.youtube.com/watch?v=o3IqOrXtxm8\u0026t=1214s 5 - Tiếp tục React Native project: + Triển khai core features + API integration + Testing và debugging - Review tiến độ tuần 07/11/2024 08/11/2024 Tài liệu React Native Kết quả đạt được tuần 9: Amazon Lightsail:\nHiểu toàn diện về dịch vụ Amazon Lightsail Học khi nào dùng Lightsail vs EC2 cho các scenarios khác nhau Hiểu mô hình pricing của Lightsail và cost predictability Nắm vững Lightsail instance types và configurations Học về Lightsail databases (MySQL, PostgreSQL) Lightsail Deployment:\nTạo và cấu hình thành công Lightsail instances Deploy web applications trên Lightsail Cấu hình static IP addresses Thiết lập domain names và SSL certificates Triển khai load balancing cho high availability Tạo snapshots cho backup và disaster recovery Lightsail vs EC2:\nHiểu simplified management của Lightsail Học về fixed pricing vs variable EC2 pricing Xác định use cases mà Lightsail phù hợp hơn Hiểu migration paths giữa Lightsail và EC2 Phát triển React Native Project:\nBắt đầu dự án React Native mới với architecture phù hợp Thiết kế user interface và user experience Triển khai component-based architecture Thiết lập state management solution Tích hợp với backend APIs Tuân theo React Native best practices Kỹ năng Mobile Development:\nCải thiện React Native coding proficiency Học advanced mobile UI patterns Triển khai responsive designs cho các screen sizes khác nhau Debug mobile-specific issues Tối ưu app performance "},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Học về AWS Cloud9 IDE Nghiên cứu AWS networking concepts thông qua workshops Hiểu advanced networking architectures Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Học AWS Cloud9: + Cloud9 overview và features + IDE setup và configuration + Collaboration features + Integration với AWS services 10/11/2024 10/11/2024 https://000049.awsstudygroup.com/ 2 - Tiếp tục học Cloud9: + Development environment setup + Code editing và debugging + Terminal và AWS CLI integration - Thực hành: Tạo Cloud9 environment 11/11/2024 11/11/2024 https://000049.awsstudygroup.com/ 3 - Thực hành: Develop với Cloud9: + Build sample application + Sử dụng AWS SDK + Deploy từ Cloud9 + Collaborate với team members 12/11/2024 12/11/2024 https://000049.awsstudygroup.com/ 4 - Học AWS Networking workshop: + VPC advanced concepts + Transit Gateway + VPC Peering + PrivateLink + Network architecture patterns 13/11/2024 13/11/2024 https://000092.awsstudygroup.com/ 5 - Tiếp tục networking workshop: + Hybrid connectivity (VPN, Direct Connect) + Network security + Traffic monitoring - Thực hành: Xây dựng network architecture 14/11/2024 15/11/2024 https://000092.awsstudygroup.com/ Kết quả đạt được tuần 10: AWS Cloud9:\nHiểu toàn diện về AWS Cloud9 IDE Học về cloud-based development environments Nắm vững Cloud9 setup và configuration Hiểu collaboration features cho team development Học integration với AWS services và SDKs Cloud9 Development:\nTạo và cấu hình thành công Cloud9 environments Phát triển applications sử dụng Cloud9 IDE Sử dụng integrated terminal và AWS CLI Debug code trong cloud environment Deploy applications trực tiếp từ Cloud9 Collaborate với team members real-time Advanced Networking Concepts:\nHọc về AWS Transit Gateway cho network hub architecture Hiểu VPC Peering để kết nối VPCs Nắm vững AWS PrivateLink cho private connectivity Học về VPC endpoints (Gateway và Interface) Hiểu network segmentation và isolation Hybrid Connectivity:\nHọc về AWS Site-to-Site VPN Hiểu AWS Direct Connect cho dedicated connections Nắm vững hybrid cloud networking patterns Học về VPN redundancy và failover Network Security:\nTriển khai network ACLs và security groups Học về AWS Network Firewall Hiểu traffic inspection và filtering Triển khai network monitoring với VPC Flow Logs Học về DDoS protection với AWS Shield Network Architecture:\nThiết kế multi-tier network architectures Triển khai hub-and-spoke network topology Tạo secure và scalable network designs Hiểu cost optimization cho networking Tài liệu hóa network architecture decisions "},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Ôn tập và củng cố toàn bộ kiến thức AWS đã học Hoàn thiện tài liệu và báo cáo thực tập Chuẩn bị bài thuyết trình cuối kỳ Suy ngẫm về hành trình học tập Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 1 - Ôn tập tuần 1-5: + IAM và security + VPC và networking + EC2 và compute + S3 và storage + Cost optimization 17/11/2024 17/11/2024 Tài liệu các tuần trước 2 - Ôn tập tuần 6-10: + Database services + Automation với Lambda + Security Hub + Lightsail + Advanced networking 18/11/2024 18/11/2024 Tài liệu các tuần trước 3 - Hoàn thiện tài liệu thực tập: + Finalize worklog + Technical documentation + Project summaries + Cleanup code repositories 19/11/2024 19/11/2024 Hướng dẫn thực tập 4 - Chuẩn bị bài thuyết trình cuối: + Tạo presentation slides + Highlight key learnings + Showcase projects + Practice presentation 20/11/2024 20/11/2024 Presentation templates 5 - Final review và reflection: + Self-evaluation + Feedback collection + Future learning plans + Hoàn thành thực tập 21/11/2024 22/11/2024 Self-evaluation forms Kết quả đạt được tuần 11: Củng cố Kiến thức:\nÔn tập tất cả AWS services đã học trong thực tập Củng cố hiểu biết về core AWS concepts Xác định điểm mạnh và cần cải thiện Tạo knowledge map toàn diện về AWS services Tài liệu hóa best practices và lessons learned Hoàn thiện Tài liệu:\nFinalize tất cả weekly worklogs với thông tin chi tiết Hoàn thành technical documentation cho projects Tổ chức code repositories với README files phù hợp Tạo architecture diagrams và documentation Chuẩn bị báo cáo thực tập toàn diện Showcase Dự án:\nTài liệu hóa wallet app project (React Native + Expo) Showcase storm tracker frontend project Highlight các AWS infrastructure projects Tạo portfolio của công việc đã hoàn thành Chuẩn bị demo materials cho presentation Đánh giá Kỹ năng:\nĐánh giá AWS technical skills đã đạt được Assess hiểu biết về cloud architecture Review development skills (React, React Native) Xác định areas cho continued learning Tạo personal development plan Chuẩn bị Thuyết trình:\nTạo presentation toàn diện về internship journey Highlight các AWS services chính đã học Showcase practical projects và implementations Chuẩn bị cho Q\u0026amp;A session Practice presentation delivery Suy ngẫm Thực tập:\nSuy ngẫm về hành trình học tập 11 tuần Xác định những learnings có giá trị nhất Nhận ra sự phát triển cá nhân và chuyên môn Thu thập feedback từ mentors và peers Lên kế hoạch next steps trong AWS learning path Key Takeaways:\nCó nền tảng vững chắc về AWS cloud services Phát triển practical cloud architecture skills Học cost optimization strategies Hiểu security best practices Xây dựng real-world applications sử dụng AWS services Phát triển mobile applications với React Native Cải thiện problem-solving và troubleshooting skills Nâng cao khả năng documentation và communication "},{"uri":"https://github.com/leduc121/fcj_report/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu Tuần 12: 🎯 Hiểu rõ và ứng dụng dịch vụ Amazon CloudFront để phân phối nội dung (CDN). Nắm vững quy trình Đóng gói ứng dụng (Containerization) với Docker và triển khai Docker Image. Triển khai thành công trang web chính thức lên môi trường Production sử dụng CloudFront. Các công việc thực hiện trong tuần: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 1-2 - Nghiên cứu \u0026amp; Học tập về Amazon CloudFront + Khái niệm, cơ chế hoạt động, và lợi ích của CDN. + CloudFront Distribution (Web/RTMP), Origin, Cache Behavior. + Cấu hình Tên miền và Chứng chỉ SSL cho CloudFront. 25/11/2025 26/11/2025 https://000094.awsstudygroup.com/ 3-4 - Chuẩn bị và Triển khai Docker Image + Học về Dockerfile và quy trình xây dựng Docker Image. + Thực hành tạo Image cho ứng dụng web. + Đẩy Image lên Amazon ECR hoặc Docker Hub (chuẩn bị cho triển khai). 27/11/2025 28/11/2025 https://000015.awsstudygroup.com/6-docker-image/ 5-7 - Triển khai Trang web Chính thức qua CloudFront + Cấu hình Origin (ví dụ: S3 Bucket, EC2/ALB) cho CloudFront Distribution. + Thực hiện Triển khai hoàn chỉnh (Full Deployment) của trang web chính thức. + Kiểm tra và xác minh hoạt động của trang web tại d3lj47ilp0fgxy.cloudfront.net. 29/11/2025 01/12/2025 https://d3lj47ilp0fgxy.cloudfront.net (Mục tiêu triển khai) Thành tựu Tuần 12: ✅ Đã nghiên cứu chuyên sâu và hiểu rõ về Amazon CloudFront và vai trò của nó như một Mạng lưới Phân phối Nội dung (CDN). Nắm được các thành phần cốt lõi của CloudFront Distribution như Origin và Cache Behavior. Thành công trong việc học và thực hành quy trình Đóng gói ứng dụng bằng Docker. Đã xây dựng thành công Docker Image cho ứng dụng web theo tài liệu tham khảo. Hoàn thành việc triển khai (Deployment) trang web chính thức lên môi trường Production, có thể truy cập qua: d3lj47ilp0fgxy.cloudfront.net. Tích lũy kinh nghiệm trong việc phối hợp giữa các dịch vụ AWS (ví dụ: S3/EC2/Load Balancer) và CloudFront để tối ưu hóa hiệu suất và bảo mật. "},{"uri":"https://github.com/leduc121/fcj_report/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://github.com/leduc121/fcj_report/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]